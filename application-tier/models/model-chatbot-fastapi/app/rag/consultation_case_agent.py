"""
FastAPIìš© ìƒë‹´ ì‚¬ë¡€ ì „ë¬¸ ì—ì´ì „íŠ¸
ê¸°ì¡´ model-chatbotì˜ ConsultationCaseAgentë¥¼ ë¹„ë™ê¸° ë²„ì „ìœ¼ë¡œ í¬íŒ…
consultation_case ë°ì´í„°ì— íŠ¹í™”ëœ ì „ìš© ì—ì´ì „íŠ¸
"""

import asyncio
import logging
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import json

# OpenAI í´ë¼ì´ì–¸íŠ¸ import
try:
    from openai import AsyncOpenAI
except ImportError:
    AsyncOpenAI = None

# ë¡œì»¬ ëª¨ë“ˆë“¤ import
from .trade_info_retriever import TradeInfoRetriever

logger = logging.getLogger(__name__)


class AsyncConsultationCaseMemory:
    """
    ìƒë‹´ ì‚¬ë¡€ ì „ìš© ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ í´ë˜ìŠ¤ (ë¹„ë™ê¸° í˜¸í™˜)
    
    ì‹¤ë¬´ ìƒë‹´ì— íŠ¹í™”ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬:
    - ë” ê¸´ ëŒ€í™” ê¸°ë¡ ìœ ì§€ (ìƒë‹´ì‚¬ë¡€ëŠ” ë§¥ë½ì´ ì¤‘ìš”)
    - ì‚¬ìš©ì ì§ˆë¬¸ íŒ¨í„´ ë¶„ì„ ë° í•™ìŠµ
    - ì°¸ì¡°ëœ ìƒë‹´ ì‚¬ë¡€ ì¶”ì 
    - ê²€ìƒ‰ ê¸°ë¡ì„ í†µí•œ ì—°ì† ì§ˆë¬¸ ì§€ì›
    
    ì£¼ìš” íŠ¹ì§•:
    - ì¼ë°˜ ëŒ€í™”ë³´ë‹¤ ê¸´ ê¸°ë¡ ìœ ì§€ (ê¸°ë³¸ 12í„´)
    - ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„ìœ¼ë¡œ ê°œì¸í™” ìƒë‹´ ì œê³µ
    - ìƒë‹´ ì‚¬ë¡€ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
    """
    
    def __init__(self, max_history: int = 12):
        """
        ìƒë‹´ ì‚¬ë¡€ ì „ìš© ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        
        Args:
            max_history: ìµœëŒ€ ëŒ€í™” ê¸°ë¡ ìˆ˜ (ìƒë‹´ì‚¬ë¡€ëŠ” ë§¥ë½ì´ ì¤‘ìš”í•˜ë¯€ë¡œ ê¸¸ê²Œ)
        """
        self.max_history = max_history
        self.messages = []
        self.case_context = []  # ì°¸ì¡°ëœ ìƒë‹´ ì‚¬ë¡€ë“¤
        self.search_history = []  # ìƒë‹´ ê²€ìƒ‰ ê¸°ë¡
        self.user_patterns = {}  # ì‚¬ìš©ì ì§ˆë¬¸ íŒ¨í„´ ë¶„ì„
        
    async def add_user_message(self, message: str, search_context: Optional[Dict] = None) -> None:
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ (ë¹„ë™ê¸°)"""
        message_data = {
            "role": "user",
            "content": message,
            "timestamp": datetime.now().isoformat()
        }
        
        if search_context:
            message_data["search_context"] = search_context
            self.search_history.append(search_context)
            
            # ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„
            await self._analyze_user_patterns(message)
        
        self.messages.append(message_data)
        await self._trim_history()
    
    async def add_assistant_message(self, 
                                   message: str, 
                                   source_cases: Optional[List[Dict]] = None) -> None:
        """ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€ (ë¹„ë™ê¸°)"""
        self.messages.append({
            "role": "assistant", 
            "content": message,
            "timestamp": datetime.now().isoformat(),
            "source_cases": source_cases or []
        })
        
        # ì°¸ì¡°ëœ ìƒë‹´ ì‚¬ë¡€ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
        if source_cases:
            for case in source_cases:
                if case not in self.case_context:
                    self.case_context.append(case)
        
        await self._trim_history()
    
    def get_conversation_history(self, include_timestamps: bool = False) -> List[Dict]:
        """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
        if include_timestamps:
            return self.messages.copy()
        else:
            return [{"role": msg["role"], "content": msg["content"]} for msg in self.messages]
    
    def get_recent_context(self, num_turns: int = 3) -> List[Dict]:
        """ìµœê·¼ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ (ìƒë‹´ì‚¬ë¡€ëŠ” ë§¥ë½ì´ ì¤‘ìš”)"""
        recent_messages = self.messages[-num_turns*2:] if self.messages else []
        return [{"role": msg["role"], "content": msg["content"]} for msg in recent_messages]
    
    def get_user_patterns(self) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì§ˆë¬¸ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ë°˜í™˜"""
        return self.user_patterns.copy()
    
    async def clear_history(self) -> None:
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (ë¹„ë™ê¸°)"""
        self.messages.clear()
        self.case_context.clear()
        self.search_history.clear()
        self.user_patterns.clear()
    
    async def _analyze_user_patterns(self, message: str) -> None:
        """ì‚¬ìš©ì ì§ˆë¬¸ íŒ¨í„´ ë¶„ì„ (ë¹„ë™ê¸°)"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ íŒ¨í„´ ë¶„ì„
        keywords = {
            "í†µê´€": ["í†µê´€", "ì‹ ê³ ", "ì‹ ê³ ì„œ", "ì„¸ê´€"],
            "ê´€ì„¸": ["ê´€ì„¸", "ì„¸ê¸ˆ", "ë©´ì„¸", "ê°ë©´"],
            "ì ˆì°¨": ["ì ˆì°¨", "ë°©ë²•", "ì–´ë–»ê²Œ", "í•´ì•¼"],
            "ì„œë¥˜": ["ì„œë¥˜", "ë¬¸ì„œ", "ì¦ëª…ì„œ", "í—ˆê°€ì„œ"],
            "FTA": ["FTA", "ì›ì‚°ì§€", "íŠ¹í˜œê´€ì„¸"],
            "ê²€ì—­": ["ê²€ì—­", "ê²€ì‚¬", "ìŠ¹ì¸"]
        }
        
        for category, words in keywords.items():
            for word in words:
                if word in message:
                    self.user_patterns[category] = self.user_patterns.get(category, 0) + 1
    
    async def _trim_history(self) -> None:
        """ëŒ€í™” ê¸°ë¡ í¬ê¸° ì œí•œ (ë¹„ë™ê¸°)"""
        if len(self.messages) > self.max_history:
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ìœ ì§€í•˜ê³  ì˜¤ë˜ëœ ëŒ€í™”ë§Œ ì œê±°
            system_messages = [msg for msg in self.messages if msg["role"] == "system"]
            other_messages = [msg for msg in self.messages if msg["role"] != "system"]
            
            # ìµœê·¼ ëŒ€í™”ë§Œ ìœ ì§€
            trimmed_other = other_messages[-(self.max_history - len(system_messages)):]
            self.messages = system_messages + trimmed_other


class AsyncConsultationCaseAgent:
    """
    FastAPIìš© ë¹„ë™ê¸° ìƒë‹´ ì‚¬ë¡€ ì „ë¬¸ ì—ì´ì „íŠ¸
    
    ì‹¤ì œ ë¯¼ì›ìƒë‹´ ì‚¬ë¡€(consultation_case)ì— íŠ¹í™”ëœ RAG ì—ì´ì „íŠ¸:
    - ì‹¤ë¬´ ì ˆì°¨ ì•ˆë‚´ ë° ê°€ì´ë“œ
    - ì„œë¥˜ ì‘ì„± ë° ì‹ ì²­ ë°©ë²•
    - ë¹„ìš© ë° ì²˜ë¦¬ ê¸°ê°„ ì •ë³´
    - ì‹¤ì œ ìƒë‹´ ì‚¬ë¡€ ê¸°ë°˜ í•´ê²°ì±… ì œì‹œ
    
    ê¸°ì¡´ ConsultationCaseAgentì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ë¹„ë™ê¸°ë¡œ êµ¬í˜„í•˜ë©´ì„œ
    FastAPI í™˜ê²½ì— ìµœì í™”í•˜ê³  ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„ ê¸°ëŠ¥ ì¶”ê°€
    """
    
    def __init__(self,
                 retriever: Optional['TradeInfoRetriever'] = None,
                 model_name: str = "gpt-4.1-mini",
                 temperature: float = 0.4,  # ìƒë‹´ì‚¬ë¡€ëŠ” ì•½ê°„ ë” ìœ ì—°í•˜ê²Œ
                 max_context_docs: int = 8,  # ìƒë‹´ì‚¬ë¡€ëŠ” ì ë‹¹í•œ ìˆ˜ë¡œ
                 similarity_threshold: float = 0.0,
                 openai_api_key: Optional[str] = None):
        """
        ë¹„ë™ê¸° ìƒë‹´ ì‚¬ë¡€ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        
        Args:
            retriever: ë¬´ì—­ ì •ë³´ ê²€ìƒ‰ ì—”ì§„ (Noneì´ë©´ ë‚˜ì¤‘ì— ì´ˆê¸°í™”)
            model_name: OpenAI ëª¨ë¸ëª…
            temperature: ìƒì„± ì˜¨ë„ (ìƒë‹´ì‚¬ë¡€ëŠ” ì•½ê°„ ë†’ê²Œ ì„¤ì •)
            max_context_docs: ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ ìˆ˜
            similarity_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’
            openai_api_key: OpenAI API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
        """
        self.retriever = retriever
        self.model_name = model_name
        self.temperature = temperature
        self.max_context_docs = max_context_docs
        self.similarity_threshold = similarity_threshold
        
        # OpenAI ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if AsyncOpenAI:
            self.client = AsyncOpenAI(api_key=openai_api_key)
        else:
            self.client = None
            logger.warning("AsyncOpenAI not available, using synchronous fallback")
        
        # ìƒë‹´ ì‚¬ë¡€ ì „ìš© ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        self.memory = AsyncConsultationCaseMemory()
        
        self.is_initialized = False
        logger.info("AsyncConsultationCaseAgent initialized")
    
    async def initialize(self) -> None:
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (retriever ìƒì„± ë“±)"""
        if self.is_initialized:
            return
            
        try:
            # retrieverê°€ ì—†ìœ¼ë©´ ìƒì„±
            if not self.retriever:
                await self._create_retriever()
            
            self.is_initialized = True
            logger.info("âœ… AsyncConsultationCaseAgent fully initialized")
            
        except Exception as e:
            logger.error(f"âŒ Failed to initialize AsyncConsultationCaseAgent: {e}")
            raise
    
    async def _create_retriever(self) -> None:
        """ë¬´ì—­ ì •ë³´ ê²€ìƒ‰ ì—”ì§„ ìƒì„±"""
        try:
            # ê¸°ì¡´ model-chatbot ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ retriever ìƒì„±
            # ë™ê¸° ë°©ì‹ì´ë¯€ë¡œ executorì—ì„œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            self.retriever = await loop.run_in_executor(None, self._create_retriever_sync)
            
            logger.info("âœ… Trade info retriever created successfully")
            
        except Exception as e:
            logger.warning(f"Could not create trade info retriever: {e}")
            self.retriever = None
    
    def _create_retriever_sync(self) -> 'TradeInfoRetriever':
        """ë™ê¸°ì  retriever ìƒì„± (executorì—ì„œ ì‹¤í–‰)"""
        from ..utils.config import get_trade_agent_config
        from .embeddings import LangChainEmbedder
        from .vector_store import LangChainVectorStore
        from .query_normalizer import TradeQueryNormalizer
        
        config = get_trade_agent_config()
        
        embedder = LangChainEmbedder()
        vector_store = LangChainVectorStore(
            collection_name=config["collection_name"]
        )
        query_normalizer = TradeQueryNormalizer()
        
        return TradeInfoRetriever(
            embedder=embedder,
            vector_store=vector_store,
            query_normalizer=query_normalizer
        )
    
    async def query_consultation(self, 
                                user_input: str, 
                                search_filters: Optional[Dict[str, Any]] = None) -> Tuple[str, List[Dict]]:
        """
        ìƒë‹´ ì‚¬ë¡€ ì§ˆì˜ ì²˜ë¦¬ (consultation_case ë°ì´í„°ë§Œ)
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            search_filters: ê²€ìƒ‰ í•„í„°
            
        Returns:
            Tuple[str, List[Dict]]: (ì‘ë‹µ í…ìŠ¤íŠ¸, ì°¸ì¡° ìƒë‹´ ì‚¬ë¡€ ë¦¬ìŠ¤íŠ¸)
        """
        if not self.is_initialized:
            await self.initialize()
        
        try:
            # 1. ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            search_context = {
                "query": user_input,
                "filters": search_filters,
                "data_type": "consultation_case",  # ìƒë‹´ ì‚¬ë¡€ë§Œ
                "timestamp": datetime.now().isoformat()
            }
            
            # 2. consultation_case ë°ì´í„°ì—ì„œë§Œ ê²€ìƒ‰
            if not search_filters:
                search_filters = {}
            search_filters["data_type"] = "consultation_case"  # í•„í„° ê°•ì œ ì„¤ì •
            
            # 3. ìƒë‹´ ì‚¬ë¡€ ì „ìš© ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            consultation_context = await self._create_consultation_search_context(user_input)
            
            # 4. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            retrieved_docs = await self._search_consultation_documents(
                user_input, search_filters, consultation_context
            )
            
            # 5. ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë©”ëª¨ë¦¬ì— ì¶”ê°€
            await self.memory.add_user_message(user_input, search_context)
            
            # 6. AI ì‘ë‹µ ìƒì„±
            response_text = await self._generate_consultation_response(user_input, retrieved_docs)
            
            # 7. ì‘ë‹µì„ ë©”ëª¨ë¦¬ì— ì¶”ê°€
            await self.memory.add_assistant_message(response_text, retrieved_docs)
            
            logger.info(f"âœ… Consultation case query completed: {user_input[:50]}...")
            
            return response_text, retrieved_docs
            
        except Exception as e:
            logger.error(f"âŒ Consultation case query failed: {e}")
            error_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ìƒë‹´ ì‚¬ë¡€ ì •ë³´ë¥¼ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            return error_response, []
    
    async def get_similar_cases(self, category: str, top_k: int = 5) -> List[Dict]:
        """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ìœ ì‚¬í•œ ìƒë‹´ ì‚¬ë¡€ ì¡°íšŒ"""
        if not self.is_initialized:
            await self.initialize()
        
        try:
            search_filters = {
                "data_type": "consultation_case",
                "category": category
            }
            
            retrieved_docs = await self._search_consultation_documents(
                f"{category} ìƒë‹´ ì‚¬ë¡€",
                search_filters
            )
            
            return retrieved_docs[:top_k]
            
        except Exception as e:
            logger.error(f"Similar cases search failed: {e}")
            return []
    
    async def get_conversation_summary(self) -> str:
        """í˜„ì¬ ìƒë‹´ ëŒ€í™”ì˜ ìš”ì•½ ìƒì„±"""
        if not self.is_initialized:
            await self.initialize()
        
        try:
            if not self.memory.messages:
                return "ìƒë‹´ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
            
            # ëŒ€í™” ê¸°ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            conversation_text = ""
            for msg in self.memory.messages:
                role = "ìƒë‹´ì" if msg["role"] == "user" else "ìƒë‹´ì›"
                conversation_text += f"{role}: {msg['content']}\n\n"
            
            # ì‚¬ìš©ì íŒ¨í„´ ì •ë³´ ì¶”ê°€
            user_patterns = self.memory.get_user_patterns()
            
            # GPTë¥¼ ì‚¬ìš©í•œ ìƒë‹´ ìš”ì•½ ìƒì„±
            summary_prompt = f"""ë‹¤ìŒ ë¬´ì—­ ì—…ë¬´ ìƒë‹´ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{conversation_text}

ìƒë‹´ ì£¼ì œ ë¶„í¬: {user_patterns}

ìƒë‹´ ìš”ì•½:"""
            
            if self.client:
                response = await self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[{"role": "user", "content": summary_prompt}],
                    temperature=0.2,
                    max_tokens=400
                )
                
                return response.choices[0].message.content.strip()
            else:
                # Fallback for synchronous client
                import openai
                response = openai.chat.completions.create(
                    model=self.model_name,
                    messages=[{"role": "user", "content": summary_prompt}],
                    temperature=0.2,
                    max_tokens=400
                )
                
                return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"Conversation summary generation failed: {e}")
            return "ìƒë‹´ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def reset_conversation(self) -> None:
        """ëŒ€í™” ì´ˆê¸°í™”"""
        await self.memory.clear_history()
        logger.info("Consultation case conversation history reset")
    
    def get_conversation_history(self) -> List[Dict]:
        """í˜„ì¬ ëŒ€í™” ê¸°ë¡ ë°˜í™˜"""
        return self.memory.get_conversation_history(include_timestamps=True)
    
    def get_user_patterns(self) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì§ˆë¬¸ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ë°˜í™˜"""
        return self.memory.get_user_patterns()
    
    async def _create_consultation_search_context(self, user_input: str) -> Dict[str, Any]:
        """ìƒë‹´ ì‚¬ë¡€ ì „ìš© ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ë¹„ë™ê¸°)"""
        search_context = {
            "agent_type": "consultation_agent",
            "domain_hints": ["consultation_case", "ì‹¤ë¬´", "ì ˆì°¨", "ë°©ë²•", "ê²½í—˜", "ì‚¬ë¡€"],
            "boost_keywords": ["ì ˆì°¨", "ë°©ë²•", "ì‹¤ë¬´", "ê²½í—˜", "ì‚¬ë¡€", "ì‹ ê³ ", "ì‹ ì²­", "ìŠ¹ì¸", "ì²˜ë¦¬", "ì„œë¥˜", "ë¹„ìš©", "ê¸°ê°„", "í†µê´€", "ì„¸ê´€", "ê´€ì„¸"],
            "priority_data_sources": ["ìƒë‹´ì‚¬ë¡€DB", "ì‹¤ë¬´ê°€ì´ë“œ", "ë¯¼ì›ì²˜ë¦¬ì‚¬ë¡€"]
        }
        
        logger.debug(f"ğŸ¯ ìƒë‹´ì‚¬ë¡€ ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸: {search_context}")
        return search_context
    
    async def _search_consultation_documents(self, 
                                            query: str, 
                                            search_filters: Optional[Dict[str, Any]] = None,
                                            search_context: Optional[Dict[str, Any]] = None) -> List[Dict]:
        """ìƒë‹´ ì‚¬ë¡€ ë¬¸ì„œ ê²€ìƒ‰ (ë¹„ë™ê¸°)"""
        if not self.retriever:
            logger.warning("Retriever not available, returning empty results")
            return []
        
        try:
            # ë™ê¸° retrieverë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            docs = await loop.run_in_executor(
                None,
                lambda: self.retriever.search_trade_info(
                    raw_query=query,
                    top_k=self.max_context_docs,
                    include_related=True,
                    expand_with_synonyms=True,
                    similarity_threshold=self.similarity_threshold,
                    filter_by=search_filters,
                    search_context=search_context
                )
            )
            
            logger.info(f"Retrieved {len(docs)} consultation case documents")
            return docs
            
        except Exception as e:
            logger.error(f"Consultation case document search failed: {e}")
            return []
    
    async def _generate_consultation_response(self, query: str, documents: List[Dict]) -> str:
        """ìƒë‹´ ì‚¬ë¡€ ì‘ë‹µ ìƒì„± (ë¹„ë™ê¸°)"""
        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = self._get_consultation_system_prompt()
            
            # ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ í¬ë§·íŒ…
            context = self._format_consultation_cases(documents)
            
            # ëŒ€í™” ê¸°ë¡
            chat_history = self._format_chat_history()
            
            # ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„
            user_patterns = self.memory.get_user_patterns()
            pattern_info = f"ì‚¬ìš©ì ê´€ì‹¬ ë¶„ì•¼: {', '.join(user_patterns.keys())}" if user_patterns else ""
            
            # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            user_prompt = f"""[ëŒ€í™” ê¸°ë¡]
{chat_history}

[ìƒë‹´ ì‚¬ë¡€ ì •ë³´]
{context}

[ì‚¬ìš©ì ë¶„ì„]
{pattern_info}

[í˜„ì¬ ì§ˆë¬¸]
{query}

ìœ„ì˜ ìƒë‹´ ì‚¬ë¡€ë¥¼ ì°¸ê³ í•˜ì—¬ ì‹¤ìš©ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."""
            
            # OpenAI API í˜¸ì¶œ
            if self.client:
                response = await self.client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=self.temperature,
                    max_tokens=1000
                )
                
                return response.choices[0].message.content.strip()
            else:
                # Fallback for synchronous client
                import openai
                response = openai.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=self.temperature,
                    max_tokens=1000
                )
                
                return response.choices[0].message.content.strip()
                
        except Exception as e:
            logger.error(f"Consultation response generation failed: {e}")
            return f"ìƒë‹´ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _get_consultation_system_prompt(self) -> str:
        """ìƒë‹´ ì‚¬ë¡€ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
        return """ë‹¹ì‹ ì€ í•œêµ­ ë¬´ì—­ ì—…ë¬´ ì‹¤ë¬´ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹¤ì œ ë¯¼ì›ìƒë‹´ ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.

**í•µì‹¬ ì›ì¹™:**
1. **ì‹¤ìš©ì„± ìµœìš°ì„ **: ì‹¤ì œ ì—…ë¬´ì— ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
2. **ê²½í—˜ ê¸°ë°˜**: ì œê³µëœ ìƒë‹´ ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²€ì¦ëœ í•´ê²°ë°©ë²•ê³¼ ì ˆì°¨ë¥¼ ì•ˆë‚´í•˜ì„¸ìš”.
3. **ë‹¨ê³„ë³„ ì•ˆë‚´**: ë³µì¡í•œ ì ˆì°¨ëŠ” ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
4. **ì˜ˆì™¸ìƒí™© ê³ ë ¤**: ì¼ë°˜ì ì¸ ê²½ìš°ë¿ë§Œ ì•„ë‹ˆë¼ ì˜ˆì™¸ìƒí™©ê³¼ íŠ¹ìˆ˜í•œ ê²½ìš°ë„ í•¨ê»˜ ì•ˆë‚´í•˜ì„¸ìš”.
5. **ê´€ë ¨ ê¸°ê´€ ì—°ê³„**: í•„ìš”ì‹œ ë‹´ë‹¹ ê¸°ê´€ê³¼ ì—°ë½ì²˜ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.

**ìƒë‹´ ì ‘ê·¼ë²•:**
- **ë¬¸ì œ íŒŒì•…**: ì‚¬ìš©ìì˜ êµ¬ì²´ì ì¸ ìƒí™©ê³¼ ëª©ì ì„ ì´í•´
- **ì‚¬ë¡€ ë§¤ì¹­**: ìœ ì‚¬í•œ ìƒë‹´ ì‚¬ë¡€ì—ì„œ ê²€ì¦ëœ í•´ê²°ì±… ì°¾ê¸°
- **ì ˆì°¨ ì•ˆë‚´**: ë‹¨ê³„ë³„ ì‹¤í–‰ ë°©ë²•ê³¼ í•„ìš” ì„œë¥˜ ì•ˆë‚´
- **ì£¼ì˜ì‚¬í•­**: í”í•œ ì‹¤ìˆ˜ì™€ ì£¼ì˜í•  ì  ë¯¸ë¦¬ ì•ˆë‚´
- **ëŒ€ì•ˆ ì œì‹œ**: ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì´ ìˆë‹¤ë©´ ì¥ë‹¨ì ê³¼ í•¨ê»˜ ì œì‹œ

**ë‹µë³€ êµ¬ì¡°:**
### í•µì‹¬ í•´ê²°ë°©ë²•
- ê°€ì¥ ì¼ë°˜ì ì´ê³  íš¨ê³¼ì ì¸ ë°©ë²•

### ë‹¨ê³„ë³„ ì ˆì°¨
1. ì²« ë²ˆì§¸ ë‹¨ê³„ (í•„ìš” ì„œë¥˜, ë‹´ë‹¹ ê¸°ê´€)
2. ë‘ ë²ˆì§¸ ë‹¨ê³„ (ì£¼ì˜ì‚¬í•­, ì†Œìš”ì‹œê°„)
3. ì™„ë£Œ ë‹¨ê³„ (í™•ì¸ì‚¬í•­)

### ì£¼ì˜ì‚¬í•­ ë° íŒ
- ì‹¤ë¬´ì—ì„œ ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì 
- íš¨ìœ¨ì ì¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒ

### ê´€ë ¨ ê¸°ê´€ ë° ë¬¸ì˜ì²˜
- ë‹´ë‹¹ ê¸°ê´€, ì—°ë½ì²˜, ì˜¨ë¼ì¸ ì„œë¹„ìŠ¤

**ìƒë‹´ ìŠ¤íƒ€ì¼:**
- ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…
- ì „ë¬¸ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
- ì‹¤ì œ ì‚¬ë¡€ì™€ ê²½í—˜ì„ í™œìš©í•œ êµ¬ì²´ì  ì¡°ì–¸
- ì‚¬ìš©ìì˜ ìƒí™©ì— ë§ëŠ” ë§ì¶¤í˜• ë‹µë³€

**ì¤‘ìš” ì•ˆë‚´:**
- ìƒë‹´ ì‚¬ë¡€ëŠ” ì°¸ê³ ìš©ì´ë©°, ì‹¤ì œ ì ìš© ì‹œ ê´€ë ¨ ê¸°ê´€ì— ìµœì¢… í™•ì¸ í•„ìš”
- ë²•ë ¹ì´ë‚˜ ê·œì •ì´ ë³€ê²½ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìµœì‹  ì •ë³´ í™•ì¸ ê¶Œì¥
- ë³µì¡í•œ ì‚¬ì•ˆì€ ì „ë¬¸ê°€ë‚˜ ë‹´ë‹¹ ê¸°ê´€ì— ì§ì ‘ ë¬¸ì˜ ê¶Œì¥"""
    
    def _format_consultation_cases(self, documents: List[Dict]) -> str:
        """ìƒë‹´ ì‚¬ë¡€ë“¤ì„ í¬ë§·íŒ…"""
        if not documents:
            return "ê´€ë ¨ ìƒë‹´ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        formatted_docs = []
        for i, doc in enumerate(documents, 1):
            metadata = doc.get("metadata", {})
            
            # ê¸°ë³¸ ì •ë³´
            doc_info = f"[ìƒë‹´ ì‚¬ë¡€ {i}]"
            
            # ì¹´í…Œê³ ë¦¬ ë° ë¶„ë¥˜
            category = metadata.get("category", "")
            sub_category = metadata.get("sub_category", "")
            
            if category:
                doc_info += f" ë¶„ì•¼: {category}"
            if sub_category:
                doc_info += f" > {sub_category}"
            
            # ì‚¬ë¡€ ë²ˆí˜¸ë‚˜ ê´€ë¦¬ë²ˆí˜¸
            case_number = metadata.get("management_number", "") or metadata.get("index", "")
            if case_number:
                doc_info += f" (ì‚¬ë¡€ë²ˆí˜¸: {case_number})"
            
            # ë‚´ìš© (ìƒë‹´ì‚¬ë¡€ëŠ” ì¡°ê¸ˆ ë” ê¸¸ê²Œ)
            content = doc.get("content", "")[:600]  # ìµœëŒ€ 600ì
            if len(doc.get("content", "")) > 600:
                content += "..."
            
            # ì œëª©ì´ë‚˜ í‚¤ì›Œë“œê°€ ìˆë‹¤ë©´ ì¶”ê°€
            title = doc.get("title", "") or metadata.get("sub_title", "")
            if title:
                doc_info += f"\nì œëª©: {title}"
            
            # í‚¤ì›Œë“œê°€ ìˆë‹¤ë©´ ì¶”ê°€
            keywords = metadata.get("keywords", [])
            if keywords:
                if isinstance(keywords, list):
                    keyword_str = ", ".join(keywords)
                else:
                    keyword_str = str(keywords)
                doc_info += f"\nê´€ë ¨í‚¤ì›Œë“œ: {keyword_str}"
            
            formatted_doc = f"{doc_info}\n{content}"
            formatted_docs.append(formatted_doc)
        
        return "\n\n".join(formatted_docs)
    
    def _format_chat_history(self) -> str:
        """ëŒ€í™” ê¸°ë¡ í¬ë§·íŒ…"""
        if not self.memory.messages:
            return "ì´ì „ ìƒë‹´ ì—†ìŒ"
        
        # ìµœê·¼ 3í„´ì˜ ëŒ€í™” í¬í•¨ (ìƒë‹´ì‚¬ë¡€ëŠ” ë§¥ë½ì´ ì¤‘ìš”)
        recent_messages = self.memory.get_recent_context(num_turns=3)
        
        formatted_history = []
        for msg in recent_messages:
            role = "ìƒë‹´ì" if msg["role"] == "user" else "ìƒë‹´ì›"
            content = msg["content"][:200]  # ìµœëŒ€ 200ìë¡œ ì œí•œ
            if len(msg["content"]) > 200:
                content += "..."
            formatted_history.append(f"{role}: {content}")
        
        return "\n".join(formatted_history) if formatted_history else "ì´ì „ ìƒë‹´ ì—†ìŒ"


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬ë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
_consultation_case_agent_instance: Optional[AsyncConsultationCaseAgent] = None


async def get_consultation_case_agent() -> AsyncConsultationCaseAgent:
    """
    ìƒë‹´ ì‚¬ë¡€ ì—ì´ì „íŠ¸ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    FastAPI dependency injectionìš©
    """
    global _consultation_case_agent_instance
    
    if _consultation_case_agent_instance is None:
        _consultation_case_agent_instance = AsyncConsultationCaseAgent()
        await _consultation_case_agent_instance.initialize()
    
    return _consultation_case_agent_instance


async def create_consultation_case_agent(**kwargs) -> AsyncConsultationCaseAgent:
    """
    ìƒˆë¡œìš´ ìƒë‹´ ì‚¬ë¡€ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    
    Args:
        **kwargs: AsyncConsultationCaseAgent ìƒì„±ì íŒŒë¼ë¯¸í„°
        
    Returns:
        ì´ˆê¸°í™”ëœ AsyncConsultationCaseAgent ì¸ìŠ¤í„´ìŠ¤
    """
    agent = AsyncConsultationCaseAgent(**kwargs)
    await agent.initialize()
    return agent