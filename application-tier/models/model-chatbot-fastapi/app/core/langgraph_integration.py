"""
LangGraph Integration Module for FastAPI
ê¸°ì¡´ model-chatbotì˜ LangGraph ì‹œìŠ¤í…œì„ FastAPIìš© ë¹„ë™ê¸° ë²„ì „ìœ¼ë¡œ í¬íŒ…
"""

import asyncio
import logging
import os
import sys
from typing import Optional, Dict, Any, List, Union, Tuple
from pathlib import Path
from contextlib import asynccontextmanager

# ë¡œì»¬ ëª¨ë“ˆë“¤ import
try:
    from ..rag.langgraph_orchestrator import LangGraphOrchestrator
    from ..rag.langgraph_factory import LangGraphAgentFactory
    from ..rag.law_agent import AsyncConversationAgent
    from ..rag.trade_regulation_agent import AsyncTradeRegulationAgent
    from ..rag.consultation_case_agent import AsyncConsultationCaseAgent
    from ..utils.config import get_trade_agent_config, get_chromadb_config
except ImportError as e:
    logging.error(f"Failed to import local modules: {e}")
    # ê°œë°œ ì¤‘ì—ëŠ” ì„í¬íŠ¸ ì—ëŸ¬ë¥¼ ë¬´ì‹œí•˜ê³  ê¸°ë³¸ í´ë˜ìŠ¤ë“¤ ì •ì˜
    pass

logger = logging.getLogger(__name__)


class LangGraphManager:
    """
    FastAPIìš© ë¹„ë™ê¸° LangGraph ë§¤ë‹ˆì €
    
    ê¸°ì¡´ model-chatbotì˜ LangGraph ì‹œìŠ¤í…œì„ FastAPI í™˜ê²½ì—ì„œ
    ë¹„ë™ê¸°ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë˜í•‘í•˜ëŠ” ë§¤ë‹ˆì € í´ë˜ìŠ¤
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ë¹„ë™ê¸° ë©”ì‹œì§€ ì²˜ë¦¬
    - ì—ì´ì „íŠ¸ë³„ ë¼ìš°íŒ… ê´€ë¦¬
    - ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
    - ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬
    """
    
    def __init__(self):
        self.orchestrator: Optional[LangGraphOrchestrator] = None
        self.factory: Optional[LangGraphAgentFactory] = None
        self.is_initialized = False
        self._initialization_lock = asyncio.Lock()
        
        # ì„±ëŠ¥ ì„¤ì •
        self.default_model = "gpt-4.1-mini"
        self.default_temperature = 0.1
        self.max_retries = 3
        self.timeout_seconds = 60
        
        logger.info("LangGraphManager created")
    
    async def initialize(self, 
                        model_name: Optional[str] = None,
                        temperature: Optional[float] = None,
                        force_rebuild: bool = False) -> None:
        """
        LangGraph ì‹œìŠ¤í…œ ë¹„ë™ê¸° ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  ì–¸ì–´ ëª¨ë¸ (ê¸°ë³¸ê°’: gpt-4.1-mini)
            temperature: ëª¨ë¸ ì˜¨ë„ ì„¤ì • (ê¸°ë³¸ê°’: 0.1)
            force_rebuild: ê°•ì œ ì¬ì´ˆê¸°í™” ì—¬ë¶€
        """
        async with self._initialization_lock:
            if self.is_initialized and not force_rebuild:
                logger.info("LangGraph system already initialized")
                return
            
            try:
                logger.info("ğŸš€ Initializing LangGraph system...")
                
                # í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
                await self._validate_environment()
                
                # íŒ©í† ë¦¬ ìƒì„± (ë™ê¸°ì ìœ¼ë¡œ)
                self.factory = LangGraphAgentFactory()
                
                # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„± (ë™ê¸°ì ìœ¼ë¡œ)
                model = model_name or self.default_model
                temp = temperature if temperature is not None else self.default_temperature
                
                self.orchestrator = self.factory.create_orchestrated_system(
                    model_name=model,
                    temperature=temp,
                    force_rebuild=force_rebuild
                )
                
                self.is_initialized = True
                logger.info("âœ… LangGraph system initialized successfully")
                
            except Exception as e:
                logger.error(f"âŒ Failed to initialize LangGraph system: {e}")
                self.is_initialized = False
                raise RuntimeError(f"LangGraph initialization failed: {str(e)}")
    
    async def process_message(self, 
                            user_message: str,
                            conversation_history: Optional[List[Dict[str, Any]]] = None,
                            include_routing_info: bool = True) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
        
        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            conversation_history: ì´ì „ ëŒ€í™” ê¸°ë¡ (ì„ íƒì )
            include_routing_info: ë¼ìš°íŒ… ì •ë³´ í¬í•¨ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            {
                "response": "AI ì‘ë‹µ",
                "agent_used": "ì‚¬ìš©ëœ ì—ì´ì „íŠ¸ëª…",
                "routing_info": {...},
                "references": [...],
                "metadata": {...}
            }
        """
        if not self.is_initialized:
            await self.initialize()
        
        if not self.orchestrator:
            raise RuntimeError("LangGraph orchestrator not available")
        
        try:
            logger.info(f"ğŸ§  Processing message with LangGraph: {user_message[:100]}...")
            
            # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í¬í•¨í•´ì„œ ì²˜ë¦¬
            enhanced_input = self._prepare_input_with_context(
                user_message, 
                conversation_history
            )
            
            # íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ë¹„ë™ê¸° ì‹¤í–‰
            result = await asyncio.wait_for(
                self._run_orchestrator_async(enhanced_input),
                timeout=self.timeout_seconds
            )
            
            # ê²°ê³¼ íŒŒì‹±
            parsed_result = self._parse_langgraph_result(result, include_routing_info)
            
            logger.info(f"âœ… Message processed successfully with agent: {parsed_result.get('agent_used', 'unknown')}")
            
            return parsed_result
            
        except asyncio.TimeoutError:
            logger.error("âŒ LangGraph processing timeout")
            return self._create_error_response("ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            
        except Exception as e:
            logger.error(f"âŒ LangGraph processing failed: {e}")
            return self._create_error_response(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    async def get_agent_stats(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´ ì¡°íšŒ"""
        if not self.is_initialized:
            return {
                "orchestrator_available": False,
                "agents": {},
                "error": "System not initialized"
            }
        
        try:
            stats = {
                "orchestrator_available": self.orchestrator is not None,
                "agents": {
                    "conversation_agent": self.factory.conversation_agent is not None,
                    "regulation_agent": self.factory.regulation_agent is not None,
                    "consultation_agent": self.factory.consultation_agent is not None,
                },
                "model_name": self.default_model,
                "temperature": self.default_temperature,
                "is_initialized": self.is_initialized
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"Failed to get agent stats: {e}")
            return {"error": str(e)}
    
    async def health_check(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬"""
        try:
            if not self.is_initialized:
                return {
                    "status": "unhealthy",
                    "error": "System not initialized"
                }
            
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
            test_result = await self.process_message(
                "ê´€ì„¸ë²• í…ŒìŠ¤íŠ¸", 
                include_routing_info=False
            )
            
            if "error" in test_result:
                return {
                    "status": "unhealthy",
                    "error": test_result["error"]
                }
            
            return {
                "status": "healthy",
                "orchestrator": "available",
                "test_response_length": len(test_result.get("response", ""))
            }
            
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e)
            }
    
    async def _validate_environment(self) -> None:
        """í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì • ê²€ì¦"""
        required_vars = ["OPENAI_API_KEY"]
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            raise ValueError(f"Missing required environment variables: {missing_vars}")
        
        logger.info("âœ… Environment variables validated")
    
    async def _run_orchestrator_async(self, enhanced_input: str) -> Dict[str, Any]:
        """
        LangGraph ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
        (ì‹¤ì œë¡œëŠ” ë™ê¸° í•¨ìˆ˜ë¥¼ thread poolì—ì„œ ì‹¤í–‰)
        """
        loop = asyncio.get_event_loop()
        
        # CPU-bound ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        result = await loop.run_in_executor(
            None,  # ê¸°ë³¸ executor ì‚¬ìš©
            self.orchestrator.invoke,
            enhanced_input
        )
        
        return result
    
    def _prepare_input_with_context(self, 
                                   current_message: str, 
                                   context_messages: Optional[List[Dict[str, Any]]]) -> str:
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì…ë ¥ ì¤€ë¹„"""
        if not context_messages:
            return current_message
        
        # ìµœê·¼ 5ê°œ ë©”ì‹œì§€ë§Œ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
        recent_messages = context_messages[-5:] if len(context_messages) > 5 else context_messages
        
        context_str = ""
        for msg in recent_messages:
            role = "ì‚¬ìš©ì" if msg.get("role") == "user" else "AI"
            content = msg.get("content", "")[:100]  # 100ìë¡œ ì œí•œ
            context_str += f"{role}: {content}...\n"
        
        if context_str:
            return f"[ì´ì „ ëŒ€í™”]\n{context_str}\n[í˜„ì¬ ì§ˆë¬¸]\n{current_message}"
        
        return current_message
    
    def _parse_langgraph_result(self, 
                               result: Dict[str, Any], 
                               include_routing_info: bool = True) -> Dict[str, Any]:
        """LangGraph ê²°ê³¼ë¥¼ FastAPI ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ íŒŒì‹±"""
        try:
            # ë©”ì‹œì§€ ì¶”ì¶œ
            messages = result.get("messages", [])
            ai_response = ""
            if messages:
                last_message = messages[-1]
                ai_response = getattr(last_message, 'content', str(last_message))
            
            parsed = {
                "response": ai_response or "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "agent_used": "unknown",
                "references": [],
                "metadata": {
                    "processing_time": result.get("processing_time", 0),
                    "total_messages": len(messages)
                }
            }
            
            # ë¼ìš°íŒ… ì •ë³´ ì¶”ì¶œ
            if include_routing_info:
                routing_history = result.get("routing_history", [])
                if routing_history:
                    latest_routing = routing_history[-1]
                    parsed["agent_used"] = latest_routing.get("selected_agent", "unknown")
                    parsed["routing_info"] = {
                        "selected_agent": latest_routing.get("selected_agent"),
                        "complexity": latest_routing.get("complexity", 0.0),
                        "reasoning": latest_routing.get("reasoning", ""),
                        "requires_multiple_agents": latest_routing.get("requires_multiple", False)
                    }
            
            # ì°¸ì¡° ë¬¸ì„œ ì¶”ì¶œ
            agent_responses = result.get("agent_responses", {})
            references = []
            for agent_name, agent_data in agent_responses.items():
                docs = agent_data.get("docs", [])
                for doc in docs[:3]:  # ìµœëŒ€ 3ê°œ
                    references.append({
                        "source": agent_name,
                        "title": doc.get("title", ""),
                        "similarity": doc.get("similarity", 0.0),
                        "metadata": doc.get("metadata", {})
                    })
            
            parsed["references"] = references
            
            return parsed
            
        except Exception as e:
            logger.error(f"Failed to parse LangGraph result: {e}")
            return self._create_error_response("ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
        return {
            "response": error_message,
            "agent_used": "error_handler",
            "references": [],
            "metadata": {"error": True},
            "error": error_message
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
_langgraph_manager: Optional[LangGraphManager] = None


async def get_langgraph_manager() -> LangGraphManager:
    """
    LangGraphManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    FastAPIì˜ Dependency Injectionì—ì„œ ì‚¬ìš©
    """
    global _langgraph_manager
    
    if _langgraph_manager is None:
        _langgraph_manager = LangGraphManager()
        await _langgraph_manager.initialize()
    
    return _langgraph_manager


async def initialize_langgraph_system() -> None:
    """ì‹œìŠ¤í…œ ì‹œì‘ ì‹œ LangGraph ì´ˆê¸°í™”"""
    try:
        logger.info("Initializing LangGraph system at startup...")
        manager = await get_langgraph_manager()
        await manager.initialize()
        logger.info("âœ… LangGraph system initialization completed")
    except Exception as e:
        logger.error(f"âŒ Failed to initialize LangGraph system: {e}")
        raise


async def cleanup_langgraph_system() -> None:
    """ì‹œìŠ¤í…œ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    global _langgraph_manager
    
    if _langgraph_manager:
        logger.info("Cleaning up LangGraph system...")
        # í•„ìš”ì‹œ ì •ë¦¬ ì‘ì—… ìˆ˜í–‰
        _langgraph_manager = None
        logger.info("âœ… LangGraph system cleanup completed")


# FastAPI ìƒëª…ì£¼ê¸° ê´€ë¦¬ìš© ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €
@asynccontextmanager
async def langgraph_lifespan():
    """FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸°ì—ì„œ LangGraph ê´€ë¦¬"""
    # ì‹œì‘
    try:
        await initialize_langgraph_system()
        yield
    finally:
        # ì¢…ë£Œ
        await cleanup_langgraph_system()