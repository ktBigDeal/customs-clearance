"""
Consultation Case Agent Module

consultation_case ë°ì´í„°ì— íŠ¹í™”ëœ ì „ìš© ì—ì´ì „íŠ¸
ì‹¤ì œ ë¯¼ì›ìƒë‹´ ì‚¬ë¡€ë¥¼ í†µí•œ ì‹¤ìš©ì ì´ê³  ê²½í—˜ì ì¸ ë¬´ì—­ ì—…ë¬´ ê°€ì´ë“œ ì œê³µ
"""

import logging
import openai
from typing import List, Dict, Any, Optional, Tuple
import json
import os
from datetime import datetime
from .trade_info_retriever import TradeInfoRetriever

logger = logging.getLogger(__name__)


class ConsultationCaseMemory:
    """ìƒë‹´ ì‚¬ë¡€ ì „ìš© ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, max_history: int = 12):
        """
        ì´ˆê¸°í™”
        
        Args:
            max_history (int): ìµœëŒ€ ëŒ€í™” ê¸°ë¡ ìˆ˜ (ìƒë‹´ì‚¬ë¡€ëŠ” ë§¥ë½ì´ ì¤‘ìš”)
        """
        self.max_history = max_history
        self.messages = []
        self.case_context = []  # ì°¸ì¡°ëœ ìƒë‹´ ì‚¬ë¡€ë“¤
        self.search_history = []  # ìƒë‹´ ê²€ìƒ‰ ê¸°ë¡
        self.user_patterns = {}  # ì‚¬ìš©ì ì§ˆë¬¸ íŒ¨í„´ ë¶„ì„
        
    def add_user_message(self, message: str, search_context: Optional[Dict] = None) -> None:
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€"""
        message_data = {
            "role": "user",
            "content": message,
            "timestamp": datetime.now().isoformat()
        }
        
        if search_context:
            message_data["search_context"] = search_context
            self.search_history.append(search_context)
            
            # ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„
            self._analyze_user_patterns(message)
        
        self.messages.append(message_data)
        self._trim_history()
    
    def add_assistant_message(self, message: str, source_cases: List[Dict] = None) -> None:
        """ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€"""
        self.messages.append({
            "role": "assistant", 
            "content": message,
            "timestamp": datetime.now().isoformat(),
            "source_cases": source_cases or []
        })
        
        # ì°¸ì¡°ëœ ìƒë‹´ ì‚¬ë¡€ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
        if source_cases:
            for case in source_cases:
                if case not in self.case_context:
                    self.case_context.append(case)
        
        self._trim_history()
    
    def get_conversation_history(self, include_timestamps: bool = False) -> List[Dict]:
        """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
        if include_timestamps:
            return self.messages.copy()
        else:
            return [{"role": msg["role"], "content": msg["content"]} for msg in self.messages]
    
    def get_recent_context(self, num_turns: int = 3) -> List[Dict]:
        """ìµœê·¼ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ (ìƒë‹´ì‚¬ë¡€ëŠ” ë§¥ë½ì´ ì¤‘ìš”)"""
        recent_messages = self.messages[-num_turns*2:] if self.messages else []
        return [{"role": msg["role"], "content": msg["content"]} for msg in recent_messages]
    
    def get_user_patterns(self) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì§ˆë¬¸ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ë°˜í™˜"""
        return self.user_patterns.copy()
    
    def clear_history(self) -> None:
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.messages.clear()
        self.case_context.clear()
        self.search_history.clear()
        self.user_patterns.clear()
    
    def _analyze_user_patterns(self, message: str) -> None:
        """ì‚¬ìš©ì ì§ˆë¬¸ íŒ¨í„´ ë¶„ì„"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ íŒ¨í„´ ë¶„ì„
        keywords = {
            "í†µê´€": ["í†µê´€", "ì‹ ê³ ", "ì‹ ê³ ì„œ", "ì„¸ê´€"],
            "ê´€ì„¸": ["ê´€ì„¸", "ì„¸ê¸ˆ", "ë©´ì„¸", "ê°ë©´"],
            "ì ˆì°¨": ["ì ˆì°¨", "ë°©ë²•", "ì–´ë–»ê²Œ", "í•´ì•¼"],
            "ì„œë¥˜": ["ì„œë¥˜", "ë¬¸ì„œ", "ì¦ëª…ì„œ", "í—ˆê°€ì„œ"],
            "FTA": ["FTA", "ì›ì‚°ì§€", "íŠ¹í˜œê´€ì„¸"],
            "ê²€ì—­": ["ê²€ì—­", "ê²€ì‚¬", "ìŠ¹ì¸"]
        }
        
        for category, words in keywords.items():
            for word in words:
                if word in message:
                    self.user_patterns[category] = self.user_patterns.get(category, 0) + 1
    
    def _trim_history(self) -> None:
        """ëŒ€í™” ê¸°ë¡ í¬ê¸° ì œí•œ"""
        if len(self.messages) > self.max_history:
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ìœ ì§€í•˜ê³  ì˜¤ë˜ëœ ëŒ€í™”ë§Œ ì œê±°
            system_messages = [msg for msg in self.messages if msg["role"] == "system"]
            other_messages = [msg for msg in self.messages if msg["role"] != "system"]
            
            # ìµœê·¼ ëŒ€í™”ë§Œ ìœ ì§€
            trimmed_other = other_messages[-(self.max_history - len(system_messages)):]
            self.messages = system_messages + trimmed_other


class ConsultationCaseAgent:
    """ìƒë‹´ ì‚¬ë¡€ ì „ìš© ì—ì´ì „íŠ¸ - consultation_case ë°ì´í„°ë§Œ ì²˜ë¦¬"""
    
    def __init__(self,
                 retriever: TradeInfoRetriever,
                 model_name: str = "gpt-4.1-mini",
                 temperature: float = 0.4,  # ìƒë‹´ì‚¬ë¡€ëŠ” ì•½ê°„ ë” ìœ ì—°í•˜ê²Œ
                 max_context_docs: int = 8,  # ìƒë‹´ì‚¬ë¡€ëŠ” ì ë‹¹í•œ ìˆ˜ë¡œ
                 similarity_threshold: float = 0.0):
        """
        ì´ˆê¸°í™”
        
        Args:
            retriever (TradeInfoRetriever): ë¬´ì—­ ì •ë³´ ê²€ìƒ‰ê¸°
            model_name (str): ì‚¬ìš©í•  GPT ëª¨ë¸ëª…
            temperature (float): ìƒì„± ì˜¨ë„ (ìƒë‹´ì‚¬ë¡€ëŠ” ì•½ê°„ ë†’ê²Œ)
            max_context_docs (int): ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ ìˆ˜
            similarity_threshold (float): ìœ ì‚¬ë„ ì„ê³„ê°’
        """
        self.retriever = retriever
        self.model_name = model_name
        self.temperature = temperature
        self.max_context_docs = max_context_docs
        self.similarity_threshold = similarity_threshold
        
        # OpenAI API í‚¤ í™•ì¸
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError(
                "OPENAI_API_KEY environment variable is not set. "
                "Please check your .env file or set the environment variable directly."
            )
        
        self.client = openai.OpenAI(api_key=api_key)
        self.memory = ConsultationCaseMemory()
        
        logger.info(f"ConsultationCaseAgent initialized with model: {model_name}")
    
    def query_consultation(self, user_input: str, 
                          search_filters: Optional[Dict[str, Any]] = None) -> Tuple[str, List[Dict]]:
        """
        ìƒë‹´ ì‚¬ë¡€ ì§ˆì˜ ì²˜ë¦¬ (consultation_case ë°ì´í„°ë§Œ)
        
        Args:
            user_input (str): ì‚¬ìš©ì ì…ë ¥
            search_filters (Optional[Dict[str, Any]]): ê²€ìƒ‰ í•„í„°
            
        Returns:
            Tuple[str, List[Dict]]: (ì‘ë‹µ í…ìŠ¤íŠ¸, ì°¸ì¡° ìƒë‹´ ì‚¬ë¡€ ë¦¬ìŠ¤íŠ¸)
        """
        try:
            # 1. ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            search_context = {
                "query": user_input,
                "filters": search_filters,
                "data_type": "consultation_case",  # ìƒë‹´ ì‚¬ë¡€ë§Œ
                "timestamp": datetime.now().isoformat()
            }
            
            # 2. consultation_case ë°ì´í„°ì—ì„œë§Œ ê²€ìƒ‰
            if not search_filters:
                search_filters = {}
            search_filters["data_type"] = "consultation_case"  # í•„í„° ê°•ì œ ì„¤ì •
            
            # 3. ìƒë‹´ ì‚¬ë¡€ ì „ìš© ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            search_context = self._create_consultation_search_context(user_input)
            
            retrieved_docs = self.retriever.search_trade_info(
                raw_query=user_input,
                top_k=self.max_context_docs,
                include_related=True,
                expand_with_synonyms=True,
                similarity_threshold=self.similarity_threshold,
                filter_by=search_filters,
                search_context=search_context
            )
            
            # 3. ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            self.memory.add_user_message(user_input, search_context)
            
            # 4. ì‘ë‹µ ìƒì„±
            response_text = self._generate_consultation_response(user_input, retrieved_docs)
            
            # 5. ëŒ€í™” ê¸°ë¡ì— ì‘ë‹µ ì¶”ê°€
            self.memory.add_assistant_message(response_text, retrieved_docs)
            
            logger.info(f"ìƒë‹´ ì‚¬ë¡€ ì‘ë‹µ ìƒì„± ì™„ë£Œ (ì°¸ì¡° ì‚¬ë¡€: {len(retrieved_docs)}ê°œ)")
            return response_text, retrieved_docs
            
        except Exception as e:
            logger.error(f"ìƒë‹´ ì‚¬ë¡€ ì§ˆì˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            error_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ìƒë‹´ ì‚¬ë¡€ ì •ë³´ë¥¼ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            return error_response, []
    
    def get_similar_cases(self, category: str, top_k: int = 5) -> List[Dict]:
        """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ìœ ì‚¬í•œ ìƒë‹´ ì‚¬ë¡€ ì¡°íšŒ"""
        try:
            search_filters = {
                "data_type": "consultation_case",
                "category": category
            }
            
            retrieved_docs = self.retriever.search_trade_info(
                raw_query=f"{category} ìƒë‹´ ì‚¬ë¡€",
                top_k=top_k,
                filter_by=search_filters
            )
            
            return retrieved_docs
            
        except Exception as e:
            logger.error(f"ìœ ì‚¬ ì‚¬ë¡€ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_conversation_summary(self) -> str:
        """í˜„ì¬ ìƒë‹´ ëŒ€í™”ì˜ ìš”ì•½ ìƒì„±"""
        try:
            if not self.memory.messages:
                return "ìƒë‹´ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
            
            # ëŒ€í™” ê¸°ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            conversation_text = ""
            for msg in self.memory.messages:
                role = "ìƒë‹´ì" if msg["role"] == "user" else "ìƒë‹´ì›"
                conversation_text += f"{role}: {msg['content']}\\n\\n"
            
            # ì‚¬ìš©ì íŒ¨í„´ ì •ë³´ ì¶”ê°€
            user_patterns = self.memory.get_user_patterns()
            
            # GPTë¥¼ ì‚¬ìš©í•œ ìƒë‹´ ìš”ì•½ ìƒì„±
            summary_prompt = f"""ë‹¤ìŒ ë¬´ì—­ ì—…ë¬´ ìƒë‹´ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{conversation_text}

ìƒë‹´ ì£¼ì œ ë¶„í¬: {user_patterns}

ìƒë‹´ ìš”ì•½:"""
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": summary_prompt}],
                temperature=0.2,
                max_tokens=400
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"ìƒë‹´ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ìƒë‹´ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def reset_conversation(self) -> None:
        """ëŒ€í™” ì´ˆê¸°í™”"""
        self.memory.clear_history()
        logger.info("ìƒë‹´ ì‚¬ë¡€ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _create_consultation_search_context(self, user_input: str) -> Dict[str, Any]:
        """ìƒë‹´ ì‚¬ë¡€ ì „ìš© ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (LLM ê¸°ë°˜ ì§€ëŠ¥ì  í•„í„°ë§ í™œìš©)"""
        search_context = {
            "agent_type": "consultation_agent",
            "domain_hints": ["consultation_case", "ì‹¤ë¬´", "ì ˆì°¨", "ë°©ë²•", "ê²½í—˜", "ì‚¬ë¡€"],
            "boost_keywords": ["ì ˆì°¨", "ë°©ë²•", "ì‹¤ë¬´", "ê²½í—˜", "ì‚¬ë¡€", "ì‹ ê³ ", "ì‹ ì²­", "ìŠ¹ì¸", "ì²˜ë¦¬", "ì„œë¥˜", "ë¹„ìš©", "ê¸°ê°„", "í†µê´€", "ì„¸ê´€", "ê´€ì„¸"],
            "priority_data_sources": ["ê´€ì„¸í–‰ì •_ë¯¼ì›ìƒë‹´_ì‚¬ë¡€ì§‘"] # "ìƒë‹´ì‚¬ë¡€DB", "ì‹¤ë¬´ê°€ì´ë“œ", "ë¯¼ì›ì²˜ë¦¬ì‚¬ë¡€"
        }
        
        logger.debug(f"ğŸ¯ ìƒë‹´ì‚¬ë¡€ ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸: {search_context}")
        return search_context
    
    def _generate_consultation_response(self, user_input: str, retrieved_docs: List[Dict]) -> str:
        """
        ìƒë‹´ ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        
        Args:
            user_input (str): ì‚¬ìš©ì ì…ë ¥
            retrieved_docs (List[Dict]): ê²€ìƒ‰ëœ ìƒë‹´ ì‚¬ë¡€ë“¤
            
        Returns:
            str: ìƒì„±ëœ ì‘ë‹µ
        """
        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = self._get_consultation_system_prompt()
            
            # ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ í¬ë§·íŒ…
            context = self._format_consultation_cases(retrieved_docs)
            
            # ëŒ€í™” ê¸°ë¡
            chat_history = self._format_chat_history()
            
            # ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„
            user_patterns = self.memory.get_user_patterns()
            pattern_info = f"ì‚¬ìš©ì ê´€ì‹¬ ë¶„ì•¼: {', '.join(user_patterns.keys())}" if user_patterns else ""
            
            # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            user_prompt = f"""[ëŒ€í™” ê¸°ë¡]
{chat_history}

[ìƒë‹´ ì‚¬ë¡€ ì •ë³´]
{context}

[ì‚¬ìš©ì ë¶„ì„]
{pattern_info}

[í˜„ì¬ ì§ˆë¬¸]
{user_input}

ìœ„ì˜ ìƒë‹´ ì‚¬ë¡€ë¥¼ ì°¸ê³ í•˜ì—¬ ì‹¤ìš©ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."""
            
            # GPT ì‘ë‹µ ìƒì„±
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=self.temperature,
                max_tokens=1000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"ìƒë‹´ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ìƒë‹´ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _get_consultation_system_prompt(self) -> str:
        """ìƒë‹´ ì‚¬ë¡€ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
        return """ë‹¹ì‹ ì€ í•œêµ­ ë¬´ì—­ ì—…ë¬´ ì‹¤ë¬´ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹¤ì œ ë¯¼ì›ìƒë‹´ ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.

**í•µì‹¬ ì›ì¹™:**
1. **ì‹¤ìš©ì„± ìµœìš°ì„ **: ì‹¤ì œ ì—…ë¬´ì— ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
2. **ê²½í—˜ ê¸°ë°˜**: ì œê³µëœ ìƒë‹´ ì‚¬ë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²€ì¦ëœ í•´ê²°ë°©ë²•ê³¼ ì ˆì°¨ë¥¼ ì•ˆë‚´í•˜ì„¸ìš”.
3. **ë‹¨ê³„ë³„ ì•ˆë‚´**: ë³µì¡í•œ ì ˆì°¨ëŠ” ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
4. **ì˜ˆì™¸ìƒí™© ê³ ë ¤**: ì¼ë°˜ì ì¸ ê²½ìš°ë¿ë§Œ ì•„ë‹ˆë¼ ì˜ˆì™¸ìƒí™©ê³¼ íŠ¹ìˆ˜í•œ ê²½ìš°ë„ í•¨ê»˜ ì•ˆë‚´í•˜ì„¸ìš”.
5. **ê´€ë ¨ ê¸°ê´€ ì—°ê³„**: í•„ìš”ì‹œ ë‹´ë‹¹ ê¸°ê´€ê³¼ ì—°ë½ì²˜ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.

**ìƒë‹´ ì ‘ê·¼ë²•:**
- **ë¬¸ì œ íŒŒì•…**: ì‚¬ìš©ìì˜ êµ¬ì²´ì ì¸ ìƒí™©ê³¼ ëª©ì ì„ ì´í•´
- **ì‚¬ë¡€ ë§¤ì¹­**: ìœ ì‚¬í•œ ìƒë‹´ ì‚¬ë¡€ì—ì„œ ê²€ì¦ëœ í•´ê²°ì±… ì°¾ê¸°
- **ì ˆì°¨ ì•ˆë‚´**: ë‹¨ê³„ë³„ ì‹¤í–‰ ë°©ë²•ê³¼ í•„ìš” ì„œë¥˜ ì•ˆë‚´
- **ì£¼ì˜ì‚¬í•­**: í”í•œ ì‹¤ìˆ˜ì™€ ì£¼ì˜í•  ì  ë¯¸ë¦¬ ì•ˆë‚´
- **ëŒ€ì•ˆ ì œì‹œ**: ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì´ ìˆë‹¤ë©´ ì¥ë‹¨ì ê³¼ í•¨ê»˜ ì œì‹œ

**ë‹µë³€ êµ¬ì¡°:**
### í•µì‹¬ í•´ê²°ë°©ë²•
- ê°€ì¥ ì¼ë°˜ì ì´ê³  íš¨ê³¼ì ì¸ ë°©ë²•

### ë‹¨ê³„ë³„ ì ˆì°¨
1. ì²« ë²ˆì§¸ ë‹¨ê³„ (í•„ìš” ì„œë¥˜, ë‹´ë‹¹ ê¸°ê´€)
2. ë‘ ë²ˆì§¸ ë‹¨ê³„ (ì£¼ì˜ì‚¬í•­, ì†Œìš”ì‹œê°„)
3. ì™„ë£Œ ë‹¨ê³„ (í™•ì¸ì‚¬í•­)

### ì£¼ì˜ì‚¬í•­ ë° íŒ
- ì‹¤ë¬´ì—ì„œ ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì 
- íš¨ìœ¨ì ì¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒ

### ê´€ë ¨ ê¸°ê´€ ë° ë¬¸ì˜ì²˜
- ë‹´ë‹¹ ê¸°ê´€, ì—°ë½ì²˜, ì˜¨ë¼ì¸ ì„œë¹„ìŠ¤

**ìƒë‹´ ìŠ¤íƒ€ì¼:**
- ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…
- ì „ë¬¸ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
- ì‹¤ì œ ì‚¬ë¡€ì™€ ê²½í—˜ì„ í™œìš©í•œ êµ¬ì²´ì  ì¡°ì–¸
- ì‚¬ìš©ìì˜ ìƒí™©ì— ë§ëŠ” ë§ì¶¤í˜• ë‹µë³€

**ì¤‘ìš” ì•ˆë‚´:**
- ìƒë‹´ ì‚¬ë¡€ëŠ” ì°¸ê³ ìš©ì´ë©°, ì‹¤ì œ ì ìš© ì‹œ ê´€ë ¨ ê¸°ê´€ì— ìµœì¢… í™•ì¸ í•„ìš”
- ë²•ë ¹ì´ë‚˜ ê·œì •ì´ ë³€ê²½ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìµœì‹  ì •ë³´ í™•ì¸ ê¶Œì¥
- ë³µì¡í•œ ì‚¬ì•ˆì€ ì „ë¬¸ê°€ë‚˜ ë‹´ë‹¹ ê¸°ê´€ì— ì§ì ‘ ë¬¸ì˜ ê¶Œì¥"""
    
    def _format_consultation_cases(self, documents: List[Dict]) -> str:
        """ìƒë‹´ ì‚¬ë¡€ë“¤ì„ í¬ë§·íŒ…"""
        if not documents:
            return "ê´€ë ¨ ìƒë‹´ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        formatted_docs = []
        for i, doc in enumerate(documents, 1):
            metadata = doc.get("metadata", {})
            
            # ê¸°ë³¸ ì •ë³´
            doc_info = f"[ìƒë‹´ ì‚¬ë¡€ {i}]"
            
            # ì¹´í…Œê³ ë¦¬ ë° ë¶„ë¥˜
            category = metadata.get("category", "")
            sub_category = metadata.get("sub_category", "")
            
            if category:
                doc_info += f" ë¶„ì•¼: {category}"
            if sub_category:
                doc_info += f" > {sub_category}"
            
            # ì‚¬ë¡€ ë²ˆí˜¸ë‚˜ ê´€ë¦¬ë²ˆí˜¸
            case_number = metadata.get("management_number", "") or metadata.get("index", "")
            if case_number:
                doc_info += f" (ì‚¬ë¡€ë²ˆí˜¸: {case_number})"
            
            # ë‚´ìš© (ìƒë‹´ì‚¬ë¡€ëŠ” ì¡°ê¸ˆ ë” ê¸¸ê²Œ)
            content = doc.get("content", "")[:600]  # ìµœëŒ€ 600ì
            if len(doc.get("content", "")) > 600:
                content += "..."
            
            # ì œëª©ì´ë‚˜ í‚¤ì›Œë“œê°€ ìˆë‹¤ë©´ ì¶”ê°€
            title = doc.get("title", "") or metadata.get("sub_title", "")
            if title:
                doc_info += f"\\nì œëª©: {title}"
            
            # í‚¤ì›Œë“œê°€ ìˆë‹¤ë©´ ì¶”ê°€
            keywords = metadata.get("keywords", [])
            if keywords:
                if isinstance(keywords, list):
                    keyword_str = ", ".join(keywords)
                else:
                    keyword_str = str(keywords)
                doc_info += f"\\nê´€ë ¨í‚¤ì›Œë“œ: {keyword_str}"
            
            formatted_doc = f"{doc_info}\\n{content}"
            formatted_docs.append(formatted_doc)
        
        return "\\n\\n".join(formatted_docs)
    
    def _format_chat_history(self) -> str:
        """ëŒ€í™” ê¸°ë¡ í¬ë§·íŒ…"""
        if not self.memory.messages:
            return "ì´ì „ ìƒë‹´ ì—†ìŒ"
        
        # ìµœê·¼ 3í„´ì˜ ëŒ€í™” í¬í•¨ (ìƒë‹´ì‚¬ë¡€ëŠ” ë§¥ë½ì´ ì¤‘ìš”)
        recent_messages = self.memory.get_recent_context(num_turns=3)
        
        formatted_history = []
        for msg in recent_messages:
            role = "ìƒë‹´ì" if msg["role"] == "user" else "ìƒë‹´ì›"
            content = msg["content"][:200]  # ìµœëŒ€ 200ìë¡œ ì œí•œ
            if len(msg["content"]) > 200:
                content += "..."
            formatted_history.append(f"{role}: {content}")
        
        return "\\n".join(formatted_history) if formatted_history else "ì´ì „ ìƒë‹´ ì—†ìŒ"