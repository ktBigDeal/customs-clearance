#!/usr/bin/env python3
"""
ë²¡í„° DB ë°ì´í„° íƒ€ì… ë¶„í¬ ë° êµ¬ì¡° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ì˜ data_type, data_source ë¶„í¬ì™€ í’ˆì§ˆ ë¶„ì„
"""

import sys
from pathlib import Path
from collections import defaultdict, Counter

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.rag.vector_store import ChromaVectorStore
from src.rag.embeddings import OpenAIEmbedder
from src.utils.config import get_trade_agent_config, load_config

def analyze_data_distribution():
    """ë²¡í„° DB ë°ì´í„° ë¶„í¬ ë° êµ¬ì¡° ë¶„ì„"""
    print("ğŸ“Š ë²¡í„° DB ë°ì´í„° ë¶„í¬ ë¶„ì„ ì‹œì‘...")
    
    try:
        # í™˜ê²½ ì„¤ì • ë¡œë“œ
        config = load_config()
        trade_config = get_trade_agent_config()
        
        # ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
        vector_store = ChromaVectorStore(
            collection_name=trade_config["collection_name"],
            db_path="data/chroma_db"
        )
        
        print("âœ… ë²¡í„° DB ì—°ê²° ì™„ë£Œ")
        
        # === 1. ì „ì²´ ì»¬ë ‰ì…˜ í†µê³„ ===
        print(f"\nğŸ“ˆ ì „ì²´ ì»¬ë ‰ì…˜ í†µê³„...")
        stats = vector_store.get_collection_stats()
        print(f"  ì´ ë¬¸ì„œ ìˆ˜: {stats.get('total_documents', 0)}ê°œ")
        print(f"  ì»¬ë ‰ì…˜ ì´ë¦„: {stats.get('collection_name', 'N/A')}")
        
        # === 2. ëª¨ë“  ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ìƒ˜í”Œë§ ===
        print(f"\nğŸ” ì „ì²´ ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ìƒ˜í”Œë§...")
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (ìƒ˜í”Œ ê²€ìƒ‰ìš©)
        embedder = OpenAIEmbedder()
        
        # ë‹¤ì–‘í•œ í‚¤ì›Œë“œë¡œ ìƒ˜í”Œë§í•˜ì—¬ ì „ì²´ ë°ì´í„° êµ¬ì¡° íŒŒì•…
        sample_queries = [
            "ë¬´ì—­ ê·œì œ ìˆ˜ì… ìˆ˜ì¶œ",
            "ë™ì‹ë¬¼ ê²€ì—­ í—ˆìš© êµ­ê°€", 
            "ë¯¼ì› ìƒë‹´ ì‚¬ë¡€ í†µê´€",
            "HSì½”ë“œ í’ˆëª© ë¶„ë¥˜",
            "ê´€ì„¸ ë©´ì„¸ ê°ë©´"
        ]
        
        all_samples = []
        for query in sample_queries:
            query_embedding = embedder.embed_text(query)
            samples = vector_store.search_similar(
                query_embedding=query_embedding,
                top_k=100  # ê° ì¿¼ë¦¬ë‹¹ 100ê°œì”© ìƒ˜í”Œë§
            )
            all_samples.extend(samples)
        
        print(f"  ìƒ˜í”Œë§ëœ ë¬¸ì„œ ìˆ˜: {len(all_samples)}ê°œ")
        
        # === 3. ë©”íƒ€ë°ì´í„° í•„ë“œ ë¶„ì„ ===
        print(f"\nğŸ“‹ ë©”íƒ€ë°ì´í„° í•„ë“œ ë¶„ì„...")
        
        all_metadata_keys = set()
        data_type_counter = Counter()
        data_source_counter = Counter()
        regulation_type_counter = Counter()
        product_name_counter = Counter()
        category_counter = Counter()
        
        for sample in all_samples:
            metadata = sample.get('metadata', {})
            all_metadata_keys.update(metadata.keys())
            
            # data_type ë¶„í¬
            data_type = metadata.get('data_type', 'unknown')
            data_type_counter[data_type] += 1
            
            # data_source ë¶„í¬
            data_source = metadata.get('data_source', 'unknown')
            data_source_counter[data_source] += 1
            
            # regulation_type ë¶„í¬ (ìˆëŠ” ê²½ìš°)
            regulation_type = metadata.get('regulation_type', '')
            if regulation_type:
                regulation_type_counter[regulation_type] += 1
            
            # product_name ë¶„í¬ (ë™ì‹ë¬¼ ë°ì´í„°)
            product_name = metadata.get('product_name', '')
            if product_name and 'ë”¸ê¸°' in product_name:
                product_name_counter[product_name] += 1
            
            # category ë¶„í¬ (ìƒë‹´ì‚¬ë¡€ ë°ì´í„°)
            category = metadata.get('category', '')
            if category:
                category_counter[category] += 1
        
        print(f"  ë°œê²¬ëœ ë©”íƒ€ë°ì´í„° í•„ë“œ: {len(all_metadata_keys)}ê°œ")
        print(f"  í•„ë“œ ëª©ë¡: {sorted(all_metadata_keys)}")
        
        # === 4. data_type ë¶„í¬ ìƒì„¸ ë¶„ì„ ===
        print(f"\nğŸ“Š data_type ë¶„í¬ (ìƒ˜í”Œ ê¸°ì¤€):")
        total_samples = len(all_samples)
        for data_type, count in data_type_counter.most_common():
            percentage = (count / total_samples) * 100
            print(f"  {data_type}: {count}ê°œ ({percentage:.1f}%)")
        
        # === 5. data_source ë¶„í¬ ìƒì„¸ ë¶„ì„ ===
        print(f"\nğŸ“‹ data_source ë¶„í¬ (ìƒìœ„ 10ê°œ):")
        for data_source, count in data_source_counter.most_common(10):
            percentage = (count / total_samples) * 100
            print(f"  {data_source}: {count}ê°œ ({percentage:.1f}%)")
        
        # === 6. regulation_type ë¶„í¬ ===
        if regulation_type_counter:
            print(f"\nâš–ï¸ regulation_type ë¶„í¬:")
            for reg_type, count in regulation_type_counter.most_common():
                print(f"  {reg_type}: {count}ê°œ")
        
        # === 7. ë”¸ê¸° ê´€ë ¨ product_name ë¶„ì„ ===
        if product_name_counter:
            print(f"\nğŸ“ ë”¸ê¸° ê´€ë ¨ ì œí’ˆëª… ë¶„í¬:")
            for product, count in product_name_counter.most_common():
                print(f"  {product}: {count}ê°œ")
        
        # === 8. ìƒë‹´ì‚¬ë¡€ category ë¶„í¬ ===
        if category_counter:
            print(f"\nğŸ“ ìƒë‹´ì‚¬ë¡€ ì¹´í…Œê³ ë¦¬ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
            for category, count in category_counter.most_common(10):
                print(f"  {category}: {count}ê°œ")
        
        # === 9. íŠ¹ì • data_typeë³„ ìƒì„¸ ë¶„ì„ ===
        print(f"\nğŸ” data_typeë³„ ìƒì„¸ ë¶„ì„...")
        
        # trade_regulation ë°ì´í„° ë¶„ì„
        trade_reg_samples = [s for s in all_samples if s.get('metadata', {}).get('data_type') == 'trade_regulation']
        if trade_reg_samples:
            print(f"\nğŸ“‹ trade_regulation ë°ì´í„° ({len(trade_reg_samples)}ê°œ):")
            
            # data_source ë¶„í¬
            trade_reg_sources = Counter(s.get('metadata', {}).get('data_source', 'unknown') for s in trade_reg_samples)
            for source, count in trade_reg_sources.most_common():
                print(f"  {source}: {count}ê°œ")
            
            # ë™ì‹ë¬¼í—ˆìš©ê¸ˆì§€ì§€ì—­ ë°ì´í„°ì˜ ì œí’ˆëª… ë¶„ì„
            animal_plant_samples = [s for s in trade_reg_samples 
                                  if s.get('metadata', {}).get('data_source') == 'ë™ì‹ë¬¼í—ˆìš©ê¸ˆì§€ì§€ì—­']
            if animal_plant_samples:
                print(f"\nğŸ•ğŸŒ± ë™ì‹ë¬¼í—ˆìš©ê¸ˆì§€ì§€ì—­ ì œí’ˆ ë¶„ì„ (ìƒìœ„ 20ê°œ):")
                animal_products = Counter(s.get('metadata', {}).get('product_name', 'unknown') 
                                        for s in animal_plant_samples)
                for product, count in animal_products.most_common(20):
                    print(f"    {product}: {count}ê°œ")
        
        # consultation_case ë°ì´í„° ë¶„ì„
        consultation_samples = [s for s in all_samples if s.get('metadata', {}).get('data_type') == 'consultation_case']
        if consultation_samples:
            print(f"\nğŸ“ consultation_case ë°ì´í„° ({len(consultation_samples)}ê°œ):")
            
            # data_source ë¶„í¬
            consult_sources = Counter(s.get('metadata', {}).get('data_source', 'unknown') for s in consultation_samples)
            for source, count in consult_sources.most_common():
                print(f"  {source}: {count}ê°œ")
        
        # === 10. ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ===
        print(f"\nâœ… ë°ì´í„° í’ˆì§ˆ ë¶„ì„...")
        
        # í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ë¶„ì„
        missing_data_type = sum(1 for s in all_samples if not s.get('metadata', {}).get('data_type'))
        missing_data_source = sum(1 for s in all_samples if not s.get('metadata', {}).get('data_source'))
        
        print(f"  data_type ëˆ„ë½: {missing_data_type}ê°œ ({(missing_data_type/total_samples)*100:.1f}%)")
        print(f"  data_source ëˆ„ë½: {missing_data_source}ê°œ ({(missing_data_source/total_samples)*100:.1f}%)")
        
        # content ê¸¸ì´ ë¶„ì„
        content_lengths = [len(s.get('content', '')) for s in all_samples]
        avg_content_length = sum(content_lengths) / len(content_lengths) if content_lengths else 0
        
        print(f"  í‰ê·  content ê¸¸ì´: {avg_content_length:.0f}ì")
        print(f"  ìµœì†Œ content ê¸¸ì´: {min(content_lengths) if content_lengths else 0}ì")
        print(f"  ìµœëŒ€ content ê¸¸ì´: {max(content_lengths) if content_lengths else 0}ì")
        
        # === 11. ê¶Œì¥ì‚¬í•­ ì¶œë ¥ ===
        print(f"\n{'='*60}")
        print(f"ğŸ“‹ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë° ê¶Œì¥ì‚¬í•­")
        print(f"{'='*60}")
        
        if 'trade_regulation' in data_type_counter and 'consultation_case' in data_type_counter:
            print("âœ… data_type ë¶„ë¦¬ê°€ ì˜ ë˜ì–´ ìˆìŒ - ë“€ì–¼ ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ ì í•©")
        else:
            print("âš ï¸ data_type ë¶„ë¦¬ í™•ì¸ í•„ìš”")
        
        if 'ë™ì‹ë¬¼í—ˆìš©ê¸ˆì§€ì§€ì—­' in data_source_counter:
            print("âœ… ë™ì‹ë¬¼ ê·œì œ ë°ì´í„° ì¡´ì¬ - ì „ìš© ê²€ìƒ‰ ë¡œì§ í•„ìš”")
        else:
            print("âŒ ë™ì‹ë¬¼ ê·œì œ ë°ì´í„° ëˆ„ë½")
        
        trade_reg_ratio = data_type_counter.get('trade_regulation', 0) / total_samples
        consultation_ratio = data_type_counter.get('consultation_case', 0) / total_samples
        
        print(f"ğŸ“Š ë°ì´í„° ë¹„ìœ¨: trade_regulation {trade_reg_ratio:.1%}, consultation_case {consultation_ratio:.1%}")
        
        if trade_reg_ratio > 0.3 and consultation_ratio > 0.3:
            print("âœ… ê· í˜•ì¡íŒ ë°ì´í„° ë¶„í¬ - ë“€ì–¼ ì—ì´ì „íŠ¸ ê¶Œì¥")
        elif trade_reg_ratio > consultation_ratio * 2:
            print("âš ï¸ trade_regulation ë°ì´í„° ê³¼ë‹¤ - í•„í„°ë§ ê°•í™” í•„ìš”")
        elif consultation_ratio > trade_reg_ratio * 2:
            print("âš ï¸ consultation_case ë°ì´í„° ê³¼ë‹¤ - ê·œì œ ë°ì´í„° ë³´ê°• í•„ìš”")
        
        print("âœ… ë°ì´í„° ë¶„í¬ ë¶„ì„ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    analyze_data_distribution()