import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
import os
import sys
import re
import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import torch

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

class HSCodeStructureAnalyzer:
    """HS ì½”ë“œ êµ¬ì¡° ë¶„ì„ í´ë˜ìŠ¤"""
    
    @staticmethod
    def get_hs_components(hs_code: str) -> Dict[str, str]:
        """HS ì½”ë“œë¥¼ êµ¬ì„± ìš”ì†Œë³„ë¡œ ë¶„í•´"""
        hs_code = str(hs_code).strip()
        
        # HS ì½”ë“œ ê¸¸ì´ì— ë”°ë¥¸ ì˜¬ë°”ë¥¸ ì²˜ë¦¬
        if len(hs_code) <= 10:
            # ë’¤ìª½ì— 0ì„ ì±„ì›Œì„œ 10ìë¦¬ë¡œ ë§Œë“¦
            hs_code = hs_code.ljust(10, '0')
        else:
            # 10ìë¦¬ë¥¼ ì´ˆê³¼í•˜ë©´ ì• 10ìë¦¬ë§Œ ì‚¬ìš©
            hs_code = hs_code[:10]
        
        return {
            'full_code': hs_code,
            'chapter': hs_code[:2],
            'heading': hs_code[:4],
            'subheading': hs_code[:6],
            'detailed': hs_code[6:],
            'hs6': hs_code[:6],
            'hs4_national': hs_code[6:]
        }
    
    @staticmethod
    def is_valid_hs6_match(us_code: str, korea_code: str) -> bool:
        """HS 6ìë¦¬(êµ­ì œ ê³µí†µ) ë§¤ì¹­ ê²€ì¦"""
        us_hs6 = str(us_code).zfill(10)[:6]
        korea_hs6 = str(korea_code).zfill(10)[:6]
        return us_hs6 == korea_hs6
    
    @staticmethod
    def calculate_hs_similarity(us_code: str, korea_code: str) -> float:
        """HS êµ¬ì¡° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°"""
        us_comp = HSCodeStructureAnalyzer.get_hs_components(us_code)
        korea_comp = HSCodeStructureAnalyzer.get_hs_components(korea_code)
        
        if us_comp['hs6'] != korea_comp['hs6']:
            return 0.0
        
        similarity = 0.6
        if us_comp['heading'] == korea_comp['heading']:
            similarity += 0.2
        if us_comp['full_code'] == korea_comp['full_code']:
            similarity += 0.2
        
        return min(similarity, 1.0)

class HSCodeConverter:
    """HS ì²´ê³„ë¥¼ ë°˜ì˜í•œ ë¯¸êµ­â†’í•œêµ­ HSì½”ë“œ ë³€í™˜ ì‹œìŠ¤í…œ (í•µì‹¬ ëª¨ë“ˆ)"""
    
    def __init__(self, us_tariff_file: str = None, korea_recommender_system=None):
        self.us_tariff_file = us_tariff_file
        self.korea_recommender = korea_recommender_system
        
        # ë¯¸êµ­ ë°ì´í„°
        self.us_data = None
        self.us_hs6_index = {}
        
        # í•œêµ­ ë°ì´í„°
        self.korea_data = None
        self.korea_hs6_index = {}
        
        # HS 6ìë¦¬ ë¶„ë¥˜ ì„¤ëª… (ëŒ€ë¶„ë¥˜ ë§¥ë½ ì •ë³´)
        self.hs6_descriptions = {}
        
        # HS êµ¬ì¡° ë¶„ì„ê¸°
        self.hs_analyzer = HSCodeStructureAnalyzer()
        
        # ë³€í™˜ ìºì‹œ
        self.conversion_cache = {}
        
        # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì—”ì§„
        self.semantic_model = None
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸
        self.openai_client = None
        
        self.initialized = False
        print("HS ì½”ë“œ ë³€í™˜ ì‹œìŠ¤í…œ (í•µì‹¬ ëª¨ë“ˆ) ì´ˆê¸°í™”")
    
    def initialize_system(self, progress_callback=None):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            if progress_callback:
                progress_callback(0.1, "ì‹œë§¨í‹± ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            # ì‹œë§¨í‹± ëª¨ë¸ ë¡œë“œ
            print("ğŸ“¥ ì‹œë§¨í‹± ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.semantic_model = SentenceTransformer('jhgan/ko-sbert-nli')
            print("âœ… ì‹œë§¨í‹± ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            if progress_callback:
                progress_callback(0.3, "ë¯¸êµ­ ë°ì´í„° ë¡œë”© ì¤‘...")
            
            # ë¯¸êµ­ ë°ì´í„° ë¡œë“œ
            if self.us_tariff_file and os.path.exists(self.us_tariff_file):
                print("ğŸ“¥ ë¯¸êµ­ ê´€ì„¸ìœ¨í‘œ ë°ì´í„° ë¡œë”© ì¤‘...")
                if self.load_us_tariff_data():
                    print("âœ… ë¯¸êµ­ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                else:
                    print("âŒ ë¯¸êµ­ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            else:
                print("âš ï¸ ë¯¸êµ­ ê´€ì„¸ìœ¨í‘œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            if progress_callback:
                progress_callback(0.7, "í•œêµ­ ë°ì´í„° ë¡œë”© ì¤‘...")
            
            # í•œêµ­ ë°ì´í„° ë¡œë“œ ì‹œë„
            if self.korea_recommender:
                print("ğŸ“¥ í•œêµ­ HSK ë°ì´í„° ë¡œë”© ì¤‘...")
                if self.load_korea_data_from_recommender():
                    print("âœ… í•œêµ­ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                else:
                    print("âŒ í•œêµ­ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            else:
                print("âš ï¸ í•œêµ­ ì¶”ì²œ ì‹œìŠ¤í…œì´ ì œê³µë˜ì§€ ì•ŠìŒ")
            
            if progress_callback:
                progress_callback(1.0, "ì´ˆê¸°í™” ì™„ë£Œ!")
            
            self.initialized = True
            return True, "âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!"
            
        except Exception as e:
            error_msg = f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}"
            print(error_msg)
            return False, error_msg
    
    def load_us_tariff_data(self) -> bool:
        """ë¯¸êµ­ ê´€ì„¸ìœ¨í‘œ ë°ì´í„° ë¡œë“œ ë° HS 6ìë¦¬ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        try:
            self.us_data = pd.read_excel(self.us_tariff_file, sheet_name=0)
            print(f"ğŸ“Š ì›ë³¸ ë°ì´í„°: {len(self.us_data)}ê°œ í–‰")
            
            # ì»¬ëŸ¼ëª… í‘œì¤€í™”
            column_mapping = {
                'ì„¸ë²ˆ': 'hs_code',
                'ì˜ë¬¸í’ˆëª…': 'english_name',
                'í•œê¸€í’ˆëª…': 'korean_name'
            }
            self.us_data = self.us_data.rename(columns=column_mapping)
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            if 'hs_code' not in self.us_data.columns:
                print("âŒ HS ì½”ë“œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            if 'english_name' not in self.us_data.columns:
                print("âŒ ì˜ë¬¸ëª… ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            # ë°ì´í„° ì •ë¦¬
            initial_count = len(self.us_data)
            self.us_data = self.us_data.dropna(subset=['hs_code'])
            
            # HS ì½”ë“œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  ì •ë¦¬
            self.us_data['hs_code'] = self.us_data['hs_code'].astype(str).str.strip()
            self.us_data['hs_code'] = self.us_data['hs_code'].str.replace('.0', '', regex=False)
            self.us_data = self.us_data[self.us_data['hs_code'] != '']
            
            # ìˆ«ìë¡œë§Œ êµ¬ì„±ëœ ì½”ë“œë§Œ í•„í„°ë§
            numeric_mask = self.us_data['hs_code'].str.match(r'^\d+$', na=False)
            self.us_data = self.us_data[numeric_mask]
            
            # ì˜ë¬¸ëª…ì´ ìˆëŠ” ê²ƒë§Œ í•„í„°ë§
            name_mask = self.us_data['english_name'].notna() & (self.us_data['english_name'].str.strip() != '')
            self.us_data = self.us_data[name_mask]
            
            print(f"ğŸ“Š ì •ë¦¬ í›„ ë°ì´í„°: {len(self.us_data)}ê°œ í–‰")
            
            if len(self.us_data) == 0:
                print("âŒ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            # HS ì½”ë“œë¥¼ 10ìë¦¬ë¡œ í‘œì¤€í™”
            self.us_data['hs_code'] = self.us_data['hs_code'].str.ljust(10, '0')
            
            # HS êµ¬ì¡° ì •ë³´ ì¶”ê°€
            self.us_data['hs6'] = self.us_data['hs_code'].str[:6]
            self.us_data['chapter'] = self.us_data['hs_code'].str[:2]
            self.us_data['heading'] = self.us_data['hs_code'].str[:4]
            
            # í•œê¸€ëª…ì´ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¬¸ìì—´ë¡œ ì±„ì›€
            if 'korean_name' not in self.us_data.columns:
                self.us_data['korean_name'] = ''
            else:
                self.us_data['korean_name'] = self.us_data['korean_name'].fillna('')
            
            # í†µí•© í…ìŠ¤íŠ¸ ìƒì„±
            self.us_data['combined_text'] = (
                self.us_data['english_name'].fillna('') + ' ' +
                self.us_data['korean_name'].fillna('')
            ).str.strip()
            
            # HS 6ìë¦¬ë³„ ì¸ë±ìŠ¤ êµ¬ì¶•
            self._build_us_hs6_index()
            
            print(f"âœ… ë¯¸êµ­ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(self.us_data)}ê°œ í•­ëª©, HS 6ìë¦¬ {len(self.us_hs6_index)}ê°œ")
            return True
            
        except Exception as e:
            print(f"âŒ ë¯¸êµ­ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    def _build_us_hs6_index(self):
        """ë¯¸êµ­ ë°ì´í„°ì˜ HS 6ìë¦¬ë³„ ì¸ë±ìŠ¤ êµ¬ì¶• + HS6 ë¶„ë¥˜ ì„¤ëª… ì¶”ì¶œ"""
        self.us_hs6_index = {}
        self.hs6_descriptions = {}
        
        for hs6, group in self.us_data.groupby('hs6'):
            # ê¸°ë³¸ ì¸ë±ìŠ¤ ì •ë³´
            self.us_hs6_index[hs6] = {
                'count': len(group),
                'codes': group['hs_code'].tolist(),
                'names_en': group['english_name'].tolist(),
                'names_kr': group['korean_name'].tolist(),
                'combined_texts': group['combined_text'].tolist()
            }
            
            # HS6 ë¶„ë¥˜ ì„¤ëª… ì¶”ì¶œ (ëŒ€ë¶„ë¥˜ ë§¥ë½)
            hs6_description = self._extract_hs6_description(group)
            if hs6_description:
                self.hs6_descriptions[hs6] = hs6_description
    
    def _extract_hs6_description(self, hs6_group) -> str:
        """HS 6ìë¦¬ ë¶„ë¥˜ì˜ ëŒ€í‘œ ì„¤ëª… ì¶”ì¶œ"""
        # 1ìˆœìœ„: ê°€ì¥ ì¼ë°˜ì ì¸ ì„¤ëª… (ê¸°íƒ€ê°€ ì•„ë‹Œ ê²ƒ ì¤‘ì—ì„œ)
        non_other_names = []
        
        for _, row in hs6_group.iterrows():
            eng_name = str(row['english_name']).lower()
            kor_name = str(row['korean_name']).lower()
            
            # "ê¸°íƒ€", "other", "nesoi" ë“±ì´ ì•„ë‹Œ êµ¬ì²´ì ì¸ ì„¤ëª… ì°¾ê¸°
            if not any(word in eng_name for word in ['other', 'nesoi', 'not elsewhere']) and \
               not any(word in kor_name for word in ['ê¸°íƒ€', 'ê·¸ ë°–ì˜', 'ë”°ë¡œ ë¶„ë¥˜ë˜ì§€']):
                if len(eng_name) > 10:  # ì¶©ë¶„íˆ êµ¬ì²´ì ì¸ ì„¤ëª…
                    non_other_names.append({
                        'eng': row['english_name'],
                        'kor': row['korean_name'],
                        'length': len(eng_name)
                    })
        
        # ê°€ì¥ ì ì ˆí•œ ì„¤ëª… ì„ íƒ
        if non_other_names:
            # ê¸¸ì´ê°€ ì ë‹¹í•œ ê²ƒ ì¤‘ì—ì„œ ì„ íƒ (ë„ˆë¬´ ê¸¸ì§€ë„ ì§§ì§€ë„ ì•Šê²Œ)
            suitable_names = [n for n in non_other_names if 15 <= n['length'] <= 100]
            if suitable_names:
                best_name = suitable_names[0]
            else:
                best_name = non_other_names[0]
            
            # í•œê¸€ëª…ì´ ìˆìœ¼ë©´ í•œê¸€ëª… ìš°ì„ , ì—†ìœ¼ë©´ ì˜ë¬¸ëª…
            if best_name['kor'] and str(best_name['kor']).strip():
                return str(best_name['kor']).strip()
            else:
                return str(best_name['eng']).strip()
        
        # 2ìˆœìœ„: ì²« ë²ˆì§¸ í•­ëª©ì˜ ì´ë¦„ (ê¸°íƒ€ë¼ë„ ì‚¬ìš©)
        first_row = hs6_group.iloc[0]
        if first_row['korean_name'] and str(first_row['korean_name']).strip():
            return str(first_row['korean_name']).strip()
        else:
            return str(first_row['english_name']).strip()
    
    def load_korea_data_from_recommender(self) -> bool:
        """í•œêµ­ HSK ë°ì´í„°ë¥¼ ì¶”ì²œ ì‹œìŠ¤í…œì—ì„œ ë¡œë“œ"""
        if not self.korea_recommender or not hasattr(self.korea_recommender, 'integrated_df'):
            return False
        
        try:
            self.korea_data = self.korea_recommender.integrated_df.copy()
            
            # HS êµ¬ì¡° ì •ë³´ ì¶”ê°€
            self.korea_data['hs6'] = self.korea_data['HS_KEY'].str[:6]
            self.korea_data['chapter'] = self.korea_data['HS_KEY'].str[:2]
            self.korea_data['heading'] = self.korea_data['HS_KEY'].str[:4]
            
            # í•œêµ­ HS 6ìë¦¬ë³„ ì¸ë±ìŠ¤ êµ¬ì¶•
            self._build_korea_hs6_index()
            
            print(f"âœ… í•œêµ­ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(self.korea_data)}ê°œ í•­ëª©, HS 6ìë¦¬ {len(self.korea_hs6_index)}ê°œ")
            return True
            
        except Exception as e:
            print(f"âŒ í•œêµ­ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    def _build_korea_hs6_index(self):
        """í•œêµ­ ë°ì´í„°ì˜ HS 6ìë¦¬ë³„ ì¸ë±ìŠ¤ êµ¬ì¶• + HS6 ë¶„ë¥˜ ì„¤ëª… ë³´ì™„"""
        self.korea_hs6_index = {}
        
        for hs6, group in self.korea_data.groupby('hs6'):
            # ëŒ€í‘œ ì´ë¦„ ì¶”ì¶œ
            names_kr = []
            names_en = []
            combined_texts = []
            
            for _, row in group.iterrows():
                # í•œê¸€ëª… ìš°ì„ ìˆœìœ„
                name_kr = ''
                for col in ['í•œê¸€í’ˆëª©ëª…', 'ì„¸ë²ˆ10ë‹¨ìœ„í’ˆëª…', 'í‘œì¤€í’ˆëª…']:
                    if col in row and pd.notna(row[col]) and str(row[col]).strip():
                        name_kr = str(row[col]).strip()
                        break
                
                # ì˜ë¬¸ëª…
                name_en = ''
                for col in ['ì˜ë¬¸í’ˆëª©ëª…', 'í‘œì¤€í’ˆëª…ì˜ë¬¸']:
                    if col in row and pd.notna(row[col]) and str(row[col]).strip():
                        name_en = str(row[col]).strip()
                        break
                
                # í†µí•© í…ìŠ¤íŠ¸
                combined_text = ''
                if 'final_combined_text' in row and pd.notna(row['final_combined_text']):
                    combined_text = str(row['final_combined_text'])
                
                names_kr.append(name_kr)
                names_en.append(name_en)
                combined_texts.append(combined_text)
            
            self.korea_hs6_index[hs6] = {
                'count': len(group),
                'codes': group['HS_KEY'].tolist(),
                'names_kr': names_kr,
                'names_en': names_en,
                'combined_texts': combined_texts,
                'data_sources': group['data_source'].tolist() if 'data_source' in group.columns else []
            }
            
            # í•œêµ­ ë°ì´í„°ì—ì„œë„ HS6 ë¶„ë¥˜ ì„¤ëª… ì¶”ì¶œ (ë¯¸êµ­ ë°ì´í„°ì— ì—†ëŠ” ê²½ìš°)
            if hs6 not in self.hs6_descriptions:
                korea_hs6_desc = self._extract_korea_hs6_description(group)
                if korea_hs6_desc:
                    self.hs6_descriptions[hs6] = korea_hs6_desc
    
    def _extract_korea_hs6_description(self, hs6_group) -> str:
        """í•œêµ­ ë°ì´í„°ì—ì„œ HS 6ìë¦¬ ë¶„ë¥˜ ì„¤ëª… ì¶”ì¶œ"""
        non_other_names = []
        
        for _, row in hs6_group.iterrows():
            # í•œê¸€ëª… ìš°ì„  í™•ì¸
            for col in ['í•œê¸€í’ˆëª©ëª…', 'ì„¸ë²ˆ10ë‹¨ìœ„í’ˆëª…', 'í‘œì¤€í’ˆëª…']:
                if col in row and pd.notna(row[col]):
                    name = str(row[col]).strip()
                    if name and not any(word in name for word in ['ê¸°íƒ€', 'ê·¸ ë°–ì˜', 'ë”°ë¡œ ë¶„ë¥˜ë˜ì§€']):
                        if len(name) > 5:  # ì¶©ë¶„íˆ êµ¬ì²´ì ì¸ ì„¤ëª…
                            non_other_names.append(name)
                            break
        
        if non_other_names:
            # ê°€ì¥ ì ì ˆí•œ ì„¤ëª… ì„ íƒ (ê¸¸ì´ ê¸°ì¤€)
            suitable_names = [n for n in non_other_names if 10 <= len(n) <= 50]
            if suitable_names:
                return suitable_names[0]
            else:
                return non_other_names[0]
        
        # ì²« ë²ˆì§¸ í•­ëª© ì‚¬ìš©
        first_row = hs6_group.iloc[0]
        for col in ['í•œê¸€í’ˆëª©ëª…', 'ì„¸ë²ˆ10ë‹¨ìœ„í’ˆëª…', 'í‘œì¤€í’ˆëª…']:
            if col in first_row and pd.notna(first_row[col]):
                name = str(first_row[col]).strip()
                if name:
                    return name
        
        return ""
    
    def get_hs6_description(self, hs6: str) -> str:
        """HS 6ìë¦¬ ë¶„ë¥˜ ì„¤ëª… ë°˜í™˜"""
        return self.hs6_descriptions.get(hs6, f"HS {hs6} ë¶„ë¥˜")
    
    def lookup_us_hs_code(self, us_hs_code: str) -> Optional[Dict]:
        """ë¯¸êµ­ HS ì½”ë“œ ì¡°íšŒ"""
        us_hs_code = str(us_hs_code).strip().ljust(10, '0')
        
        # ì •í™•í•œ 10ìë¦¬ ë§¤ì¹­
        matching_rows = self.us_data[self.us_data['hs_code'] == us_hs_code]
        
        if matching_rows.empty:
            return None
        
        row = matching_rows.iloc[0]
        hs_components = self.hs_analyzer.get_hs_components(us_hs_code)
        
        return {
            'hs_code': us_hs_code,
            'english_name': row['english_name'],
            'korean_name': row['korean_name'],
            'combined_text': row['combined_text'],
            'hs_components': hs_components
        }
    
    def get_korea_candidates_by_hs6(self, hs6: str) -> List[Dict]:
        """HS 6ìë¦¬ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ í›„ë³´êµ° ìƒì„±"""
        if hs6 not in self.korea_hs6_index:
            return []
        
        korea_group = self.korea_hs6_index[hs6]
        candidates = []
        
        for i in range(korea_group['count']):
            candidates.append({
                'hs_code': korea_group['codes'][i],
                'name_kr': korea_group['names_kr'][i],
                'name_en': korea_group['names_en'][i],
                'combined_text': korea_group['combined_texts'][i],
                'data_source': korea_group['data_sources'][i] if korea_group['data_sources'] else ''
            })
        
        return candidates
    
    def _build_enhanced_search_query(self, us_info: Dict, additional_name: str = "") -> str:
        """HS ì²´ê³„ë¥¼ ê³ ë ¤í•œ í–¥ìƒëœ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        query_parts = []
        
        # 1ìˆœìœ„: ë¯¸êµ­ ê´€ì„¸ìœ¨í‘œì˜ í•œê¸€ëª…
        if us_info['korean_name'] and us_info['korean_name'].strip():
            query_parts.append(us_info['korean_name'].strip())
        
        # 2ìˆœìœ„: ì¶”ê°€ ìƒí’ˆëª…
        if additional_name and additional_name.strip():
            query_parts.append(additional_name.strip())
        
        # 3ìˆœìœ„: ì˜ë¬¸ëª…ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        if us_info['english_name']:
            english_keywords = self._extract_core_keywords(us_info['english_name'])
            query_parts.extend(english_keywords)
        
        # 4ìˆœìœ„: HS ì²´ê³„ ê¸°ë°˜ ì¼ë°˜ì  ìš©ì–´
        hs_chapter = us_info['hs_components']['chapter']
        chapter_keywords = self._get_chapter_keywords(hs_chapter)
        query_parts.extend(chapter_keywords)
        
        return ' '.join(query_parts)
    
    def _extract_core_keywords(self, english_name: str) -> List[str]:
        """ì˜ë¬¸ëª…ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ"""
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = {
            'of', 'and', 'or', 'the', 'a', 'an', 'in', 'on', 'at', 'to', 'for',
            'with', 'by', 'from', 'other', 'others', 'nesoi', 'not', 'elsewhere',
            'specified', 'provided', 'including', 'excluding', 'containing',
            'having', 'being', 'used', 'suitable', 'designed', 'intended'
        }
        
        # ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë§Œ ì¶”ì¶œ
        words = re.findall(r'[A-Za-z]+', english_name.lower())
        keywords = []
        
        for word in words:
            if len(word) >= 3 and word not in stopwords:
                # ê¸°ìˆ ì  ìš©ì–´ë‚˜ ì¬ì§ˆëª… ìš°ì„ 
                if any(tech in word for tech in ['digital', 'electronic', 'automatic', 'portable', 'cellular']):
                    keywords.insert(0, word)
                else:
                    keywords.append(word)
        
        return keywords[:4]
    
    def _get_chapter_keywords(self, chapter: str) -> List[str]:
        """HS ì¥(Chapter)ë³„ ê´€ë ¨ í‚¤ì›Œë“œ ë°˜í™˜"""
        chapter_map = {
            '84': ['ê¸°ê³„', 'ì—”ì§„', 'ì¥ì¹˜', 'ì„¤ë¹„'],
            '85': ['ì „ê¸°', 'ì „ì', 'í†µì‹ ', 'ìŒí–¥'],
            '87': ['ìë™ì°¨', 'ì°¨ëŸ‰', 'ìš´ì†¡'],
            '73': ['ì² ê°•', 'ê¸ˆì†', 'ì œí’ˆ'],
            '39': ['í”Œë¼ìŠ¤í‹±', 'ìˆ˜ì§€', 'í•©ì„±'],
            '90': ['ê´‘í•™', 'ì˜ë£Œ', 'ì •ë°€', 'ê¸°ê¸°'],
            '94': ['ê°€êµ¬', 'ì¡°ëª…', 'ë¨í”„'],
            '95': ['ì™„êµ¬', 'ê²Œì„', 'ìŠ¤í¬ì¸ ']
        }
        
        return chapter_map.get(chapter, [])
    
    def _rank_candidates_by_similarity(self, search_query: str, candidates: List[Dict]) -> List[Dict]:
        """í›„ë³´êµ°ì„ ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ìˆœìœ„ ë§¤ê¹€"""
        if not candidates or not self.semantic_model:
            for candidate in candidates:
                candidate['similarity_score'] = 0.5
            return candidates
        
        # í›„ë³´ë“¤ì˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        candidate_texts = []
        for candidate in candidates:
            text_parts = []
            if candidate['name_kr']:
                text_parts.append(candidate['name_kr'])
            if candidate['name_en']:
                text_parts.append(candidate['name_en'])
            if candidate['combined_text']:
                text_parts.append(candidate['combined_text'])
            
            combined_text = ' '.join(text_parts)
            candidate_texts.append(combined_text)
        
        # ì˜ë¯¸ ìœ ì‚¬ë„ ê³„ì‚°
        try:
            query_embedding = self.semantic_model.encode([search_query])
            candidate_embeddings = self.semantic_model.encode(candidate_texts)
            similarities = cosine_similarity(query_embedding, candidate_embeddings).flatten()
            
            # í›„ë³´ì— ìœ ì‚¬ë„ ì ìˆ˜ ì¶”ê°€
            for i, candidate in enumerate(candidates):
                candidate['similarity_score'] = float(similarities[i])
            
            # ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬
            ranked_candidates = sorted(candidates, key=lambda x: x['similarity_score'], reverse=True)
            return ranked_candidates
            
        except Exception as e:
            print(f"âš ï¸ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ì›ë³¸ ìˆœì„œ ìœ ì§€
            for candidate in candidates:
                candidate['similarity_score'] = 0.5
            return candidates
    
    def convert_hs_code(self, us_hs_code: str, us_product_name: str = "") -> Dict:
        """HS ì½”ë“œ ë³€í™˜ ì‹¤í–‰"""
        if not self.initialized:
            return {
                'status': 'error',
                'message': 'ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
            }
        
        # ìºì‹œ í™•ì¸
        cache_key = f"{us_hs_code}:{us_product_name}"
        if cache_key in self.conversion_cache:
            return self.conversion_cache[cache_key]
        
        # 1ë‹¨ê³„: ë¯¸êµ­ HS ì½”ë“œ ì¡°íšŒ
        us_info = self.lookup_us_hs_code(us_hs_code)
        if not us_info:
            result = {
                'status': 'error',
                'message': f"ë¯¸êµ­ HSì½”ë“œ '{us_hs_code}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                'us_hs_code': us_hs_code,
                'us_product_name': us_product_name,
                'suggestions': self._get_alternative_suggestions(us_hs_code)
            }
            return result
        
        # 2ë‹¨ê³„: HS 6ìë¦¬ ê¸°ì¤€ í•œêµ­ í›„ë³´êµ° ìƒì„±
        hs6 = us_info['hs_components']['hs6']
        korea_candidates = self.get_korea_candidates_by_hs6(hs6)
        
        if not korea_candidates:
            result = {
                'status': 'no_hs6_match',
                'message': f"HS 6ìë¦¬ '{hs6}'ì— í•´ë‹¹í•˜ëŠ” í•œêµ­ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.",
                'us_hs_code': us_hs_code,
                'us_info': us_info,
                'hs6': hs6
            }
            return result
        
        # 3ë‹¨ê³„: ìƒí’ˆëª… ê¸°ë°˜ ì„¸ë¶„ë¥˜ ë§¤ì¹­
        search_query = self._build_enhanced_search_query(us_info, us_product_name)
        best_candidates = self._rank_candidates_by_similarity(search_query, korea_candidates)
        
        # 4ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ìƒì„±
        final_result = best_candidates[0] if best_candidates else None
        
        if final_result:
            # HS êµ¬ì¡° ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°
            hs_similarity = self.hs_analyzer.calculate_hs_similarity(us_hs_code, final_result['hs_code'])
            semantic_similarity = final_result.get('similarity_score', 0.5)
            
            # ìµœì¢… ì‹ ë¢°ë„ (HS êµ¬ì¡° 50% + ì˜ë¯¸ ìœ ì‚¬ë„ 50%)
            final_confidence = (hs_similarity * 0.5) + (semantic_similarity * 0.5)
            
            result = {
                'status': 'success',
                'us_hs_code': us_hs_code,
                'us_product_name': us_product_name,
                'us_info': us_info,
                'korea_recommendation': {
                    'hs_code': final_result['hs_code'],
                    'name_kr': final_result['name_kr'],
                    'name_en': final_result.get('name_en', ''),
                    'data_source': final_result.get('data_source', ''),
                    'confidence': final_confidence
                },
                'hs_analysis': {
                    'hs6_match': True,
                    'hs_similarity': hs_similarity,
                    'semantic_similarity': semantic_similarity,
                    'total_candidates': len(korea_candidates),
                    'us_hs6': hs6,
                    'korea_hs6': final_result['hs_code'][:6]
                },
                'search_query': search_query,
                'all_candidates': best_candidates[:3]
            }
            
            # ìºì‹œ ì €ì¥
            self.conversion_cache[cache_key] = result
            return result
        
        else:
            result = {
                'status': 'no_match',
                'message': 'ì í•©í•œ í•œêµ­ HSK ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'us_hs_code': us_hs_code,
                'us_info': us_info,
                'hs6': hs6,
                'korea_candidates_count': len(korea_candidates)
            }
            return result
    
    def _get_alternative_suggestions(self, us_hs_code: str) -> List[str]:
        """ìœ ì‚¬í•œ HS ì½”ë“œ ëŒ€ì•ˆ ì œì‹œ"""
        if self.us_data is None:
            return []
        
        suggestions = []
        
        # 1. ì• 6ìë¦¬ ê¸°ì¤€ ìœ ì‚¬ ì½”ë“œ
        if len(us_hs_code) >= 6:
            hs6 = us_hs_code[:6]
            similar_6 = self.us_data[self.us_data['hs_code'].str.startswith(hs6)]
            suggestions.extend(similar_6['hs_code'].head(3).tolist())
        
        # 2. ì• 4ìë¦¬ ê¸°ì¤€ ìœ ì‚¬ ì½”ë“œ
        if len(us_hs_code) >= 4 and len(suggestions) < 3:
            hs4 = us_hs_code[:4]
            similar_4 = self.us_data[self.us_data['hs_code'].str.startswith(hs4)]
            suggestions.extend(similar_4['hs_code'].head(5-len(suggestions)).tolist())
        
        # 3. ì¥(Chapter) ê¸°ì¤€ ìœ ì‚¬ ì½”ë“œ
        if len(us_hs_code) >= 2 and len(suggestions) < 3:
            chapter = us_hs_code[:2]
            similar_chapter = self.us_data[self.us_data['chapter'] == chapter]
            suggestions.extend(similar_chapter['hs_code'].head(5-len(suggestions)).tolist())
        
        return list(set(suggestions))  # ì¤‘ë³µ ì œê±°
    
    def get_system_statistics(self) -> Dict:
        """ì‹œìŠ¤í…œ í†µê³„ ë°˜í™˜"""
        stats = {
            'system_status': {
                'initialized': self.initialized,
                'us_data_loaded': self.us_data is not None,
                'korea_data_loaded': self.korea_data is not None,
                'semantic_model_loaded': self.semantic_model is not None,
                'openai_available': self.openai_client is not None,
                'conversion_cache_size': len(self.conversion_cache)
            }
        }
        
        if self.us_data is not None:
            stats['us_data'] = {
                'total_codes': len(self.us_data),
                'unique_hs6': len(self.us_hs6_index),
                'unique_chapters': len(self.us_data['chapter'].unique()),
                'has_korean_names': (~self.us_data['korean_name'].isna()).sum(),
                'hs6_descriptions': len(self.hs6_descriptions)
            }
        
        if self.korea_data is not None:
            stats['korea_data'] = {
                'total_codes': len(self.korea_data),
                'unique_hs6': len(self.korea_hs6_index),
                'unique_chapters': len(self.korea_data['chapter'].unique())
            }
        
        # HS 6ìë¦¬ êµì§‘í•© ë¶„ì„
        if self.us_hs6_index and self.korea_hs6_index:
            us_hs6_set = set(self.us_hs6_index.keys())
            korea_hs6_set = set(self.korea_hs6_index.keys())
            
            stats['hs6_analysis'] = {
                'us_only_hs6': len(us_hs6_set - korea_hs6_set),
                'korea_only_hs6': len(korea_hs6_set - us_hs6_set),
                'common_hs6': len(us_hs6_set & korea_hs6_set),
                'coverage_rate': len(us_hs6_set & korea_hs6_set) / len(us_hs6_set) * 100 if us_hs6_set else 0
            }
        
        return stats
    
    def clear_cache(self):
        """ë³€í™˜ ìºì‹œ ì´ˆê¸°í™”"""
        cache_size = len(self.conversion_cache)
        self.conversion_cache.clear()
        return cache_size


def main():
    """ëŒ€í™”í˜• HS ì½”ë“œ ë³€í™˜ ì‹œìŠ¤í…œ"""
    print("="*80)
    print("ğŸ”„ HS Code Converter - ë¯¸êµ­â†’í•œêµ­ HSì½”ë“œ ë³€í™˜ ì‹œìŠ¤í…œ")
    print("="*80)
    
    # ë³€í™˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    us_tariff_file = r".\ê´€ì„¸ì²­_ë¯¸êµ­ ê´€ì„¸ìœ¨í‘œ_20250714.xlsx"
    
    # í•œêµ­ ì¶”ì²œ ì‹œìŠ¤í…œ ë¡œë“œ ì‹œë„
    korea_recommender = None
    try:
        from hs_recommender import HSCodeRecommender
        cache_dir = r'C:\Users\User\í†µê´€\cache\hs_code_cache'
        korea_recommender = HSCodeRecommender(cache_dir=cache_dir)
        if korea_recommender.load_data():
            print("âœ… í•œêµ­ ì¶”ì²œ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
        else:
            print("âš ï¸ í•œêµ­ ì¶”ì²œ ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨")
            korea_recommender = None
    except ImportError:
        print("âš ï¸ í•œêµ­ ì¶”ì²œ ì‹œìŠ¤í…œ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        korea_recommender = None
    
    converter = HSCodeConverter(us_tariff_file, korea_recommender)
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    print("\nğŸš€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    success, message = converter.initialize_system()
    print(f"ğŸš€ {message}")
    
    if not success:
        print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
    print_system_status(converter)
    
    # ëŒ€í™”í˜• ë³€í™˜ ì‹œì‘
    print("\n" + "="*80)
    print("ğŸ¯ ëŒ€í™”í˜• HS ì½”ë“œ ë³€í™˜ ì‹œì‘")
    print("="*80)
    print("ğŸ’¡ ì‚¬ìš©ë²•:")
    print("- ë¯¸êµ­ HS ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (4-10ìë¦¬ ìˆ«ì)")
    print("- ìƒí’ˆëª…ì€ ì„ íƒì‚¬í•­ì…ë‹ˆë‹¤ (ë” ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´ ê¶Œì¥)")
    print("- 'quit', 'exit', 'q' ì…ë ¥ì‹œ ì¢…ë£Œ")
    print("- 'status' ì…ë ¥ì‹œ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
    print("- 'cache' ì…ë ¥ì‹œ ìºì‹œ ì •ë³´ í™•ì¸")
    print("="*80)
    
    while True:
        try:
            print("\n" + "-"*50)
            
            # HS ì½”ë“œ ì…ë ¥
            us_hs_code = input("ğŸ”¢ ë¯¸êµ­ HS ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            # ì¢…ë£Œ ëª…ë ¹ì–´ í™•ì¸
            if us_hs_code.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            # íŠ¹ë³„ ëª…ë ¹ì–´ ì²˜ë¦¬
            if us_hs_code.lower() == 'status':
                print_system_status(converter)
                continue
            
            if us_hs_code.lower() == 'cache':
                print_cache_info(converter)
                continue
            
            # HS ì½”ë“œ ìœ íš¨ì„± ê²€ì‚¬
            if not us_hs_code:
                print("âŒ HS ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            
            if not re.match(r'^\d{4,10}$', us_hs_code):
                print("âŒ ì˜¬ë°”ë¥¸ HS ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (4-10ìë¦¬ ìˆ«ì)")
                print("ğŸ’¡ ì˜ˆì‹œ: 8471300000, 9507109000")
                continue
            
            # ìƒí’ˆëª… ì…ë ¥ (ì„ íƒì‚¬í•­)
            product_name = input("ğŸ“¦ ìƒí’ˆëª… (ì„ íƒì‚¬í•­, Enterë¡œ ê±´ë„ˆë›°ê¸°): ").strip()
            
            print(f"\nğŸ”„ ë³€í™˜ ì¤‘... [{us_hs_code}" + (f" - {product_name}" if product_name else "") + "]")
            print("-"*50)
            
            # ë³€í™˜ ì‹¤í–‰
            result = converter.convert_hs_code(us_hs_code, product_name)
            
            # ê²°ê³¼ ì¶œë ¥
            if result['status'] == 'success':
                print_success_result(result, converter)
            elif result['status'] == 'error':
                print_error_result(result)
            elif result['status'] == 'no_hs6_match':
                print_no_match_result(result, converter)
            else:
                print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {result.get('message', 'ì˜¤ë¥˜ ì •ë³´ ì—†ìŒ')}")
            
            # ê³„ì†í• ì§€ ë¬»ê¸°
            print("\n" + "-"*50)
            continue_choice = input("ğŸ”„ ë‹¤ë¥¸ ì½”ë“œë¥¼ ë³€í™˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Enter: ê³„ì†, q: ì¢…ë£Œ): ").strip()
            if continue_choice.lower() in ['q', 'quit', 'exit']:
                print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ì‚¬ìš©ìì— ì˜í•´ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            continue

def print_system_status(converter):
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥"""
    print("\n" + "="*50)
    print("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
    print("="*50)
    
    stats = converter.get_system_statistics()
    
    print("âœ… **ê¸°ë³¸ ìƒíƒœ**")
    print(f"- ì´ˆê¸°í™”: {'âœ… ì™„ë£Œ' if converter.initialized else 'âŒ ë¯¸ì™„ë£Œ'}")
    print(f"- ë¯¸êµ­ ë°ì´í„°: {'âœ… ë¡œë“œë¨' if converter.us_data is not None else 'âŒ ì—†ìŒ'}")
    print(f"- í•œêµ­ ë°ì´í„°: {'âœ… ë¡œë“œë¨' if converter.korea_data is not None else 'âŒ ì—†ìŒ'}")
    print(f"- ì‹œë§¨í‹± ëª¨ë¸: {'âœ… ë¡œë“œë¨' if converter.semantic_model is not None else 'âŒ ì—†ìŒ'}")
    
    if converter.us_data is not None:
        print(f"\nğŸ“Š **ë¯¸êµ­ ë°ì´í„°**")
        print(f"- ì´ ì½”ë“œ ìˆ˜: {len(converter.us_data):,}ê°œ")
        print(f"- HS 6ìë¦¬ ì¢…ë¥˜: {len(converter.us_hs6_index):,}ê°œ")
        print(f"- ì¥(Chapter) ì¢…ë¥˜: {len(converter.us_data['chapter'].unique())}ê°œ")
    
    if converter.korea_data is not None:
        print(f"\nğŸ“Š **í•œêµ­ ë°ì´í„°**")
        print(f"- ì´ ì½”ë“œ ìˆ˜: {len(converter.korea_data):,}ê°œ")
        print(f"- HS 6ìë¦¬ ì¢…ë¥˜: {len(converter.korea_hs6_index):,}ê°œ")

def print_cache_info(converter):
    """ìºì‹œ ì •ë³´ ì¶œë ¥"""
    print("\n" + "="*50)
    print("ğŸ’¾ ìºì‹œ ì •ë³´")
    print("="*50)
    
    cache_size = len(converter.conversion_cache)
    print(f"- ë³€í™˜ ìºì‹œ: {cache_size}ê°œ í•­ëª©")
    
    if cache_size > 0:
        print(f"\nğŸ“‹ **ìµœê·¼ ë³€í™˜ ë‚´ì—­** (ìµœëŒ€ 5ê°œ)")
        for i, (cache_key, result) in enumerate(list(converter.conversion_cache.items())[-5:], 1):
            us_code, product_name = cache_key.split(':', 1)
            status = result.get('status', 'unknown')
            print(f"{i}. {us_code}" + (f" ({product_name})" if product_name else "") + f" - {status}")
        
        clear_choice = input("\nğŸ—‘ï¸ ìºì‹œë¥¼ ì´ˆê¸°í™”í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip()
        if clear_choice.lower() in ['y', 'yes']:
            cleared_count = converter.clear_cache()
            print(f"âœ… ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ ({cleared_count}ê°œ í•­ëª© ì‚­ì œ)")

def is_other_item(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ê¸°íƒ€ í•­ëª© ì—¬ë¶€ í™•ì¸"""
    if not text:
        return False
    
    text_lower = str(text).lower().strip()
    
    other_keywords = [
        'ê¸°íƒ€', 'ê·¸ ë°–ì˜', 'ë”°ë¡œ ë¶„ë¥˜ë˜ì§€', 'ê¸°íƒ€ì˜',
        'other', 'others', 'nesoi', 'not elsewhere', 'not specified',
        'not elsewhere specified or included',
        'other, not elsewhere specified'
    ]
    
    return any(keyword in text_lower for keyword in other_keywords)

def enhance_product_name_with_context(korea_name, hs6_description):
    """ê¸°íƒ€ ìƒí’ˆëª…ì„ ë§¥ë½ ì •ë³´ì™€ í•¨ê»˜ í‘œì‹œ"""
    if not korea_name or not hs6_description:
        return korea_name or ""
    
    if is_other_item(korea_name):
        return f"{hs6_description} ë¶„ì•¼ì˜ ê¸°íƒ€ í•­ëª©"
    else:
        return korea_name

def get_display_width(text):
    """í…ìŠ¤íŠ¸ì˜ ì‹¤ì œ í‘œì‹œ í­ ê³„ì‚° (í•œê¸€ 2, ì˜ë¬¸/ìˆ«ì 1)"""
    if not text:
        return 0
    
    width = 0
    for char in str(text):
        # í•œê¸€, í•œì, ì¼ë³¸ì–´ ë“±ì€ í­ì´ 2
        if ord(char) > 127:
            width += 2
        else:
            width += 1
    return width

def truncate_text_to_width(text, max_width):
    """ì§€ì •ëœ í­ì— ë§ê²Œ í…ìŠ¤íŠ¸ ìë¥´ê¸°"""
    if not text:
        return ""
    
    text = str(text)
    current_width = 0
    result = ""
    
    for char in text:
        char_width = 2 if ord(char) > 127 else 1
        if current_width + char_width > max_width:
            if max_width >= 3:  # "..." ì¶”ê°€í•  ê³µê°„ì´ ìˆìœ¼ë©´
                # ê¸°ì¡´ í…ìŠ¤íŠ¸ì—ì„œ "..." ê³µê°„ í™•ë³´
                while get_display_width(result + "...") > max_width and result:
                    result = result[:-1]
                result += "..."
            break
        result += char
        current_width += char_width
    
    return result

def pad_text_to_width(text, target_width):
    """í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ í­ì— ë§ê²Œ íŒ¨ë”©"""
    if not text:
        text = ""
    
    current_width = get_display_width(text)
    padding_needed = target_width - current_width
    
    if padding_needed > 0:
        return text + " " * padding_needed
    else:
        return text

def print_candidates_table(candidates, hs6_description):
    """í›„ë³´ ëª©ë¡ì„ ì •ë ¬ëœ í…Œì´ë¸”ë¡œ ì¶œë ¥"""
    
    # í…Œì´ë¸” í­ ì„¤ì •
    rank_width = 4
    code_width = 13
    name_width = 36  # ìƒí’ˆëª… í­
    similarity_width = 8
    
    # í—¤ë” ì¶œë ¥
    print("â”Œ" + "â”€" * rank_width + "â”¬" + "â”€" * code_width + "â”¬" + "â”€" * name_width + "â”¬" + "â”€" * similarity_width + "â”")
    
    # í—¤ë” í…ìŠ¤íŠ¸
    rank_header = pad_text_to_width("ìˆœìœ„", rank_width)
    code_header = pad_text_to_width("HSK ì½”ë“œ", code_width)
    name_header = pad_text_to_width("ìƒí’ˆëª…", name_width)
    similarity_header = pad_text_to_width("ìœ ì‚¬ë„", similarity_width)
    
    print(f"â”‚{rank_header}â”‚{code_header}â”‚{name_header}â”‚{similarity_header}â”‚")
    print("â”œ" + "â”€" * rank_width + "â”¼" + "â”€" * code_width + "â”¼" + "â”€" * name_width + "â”¼" + "â”€" * similarity_width + "â”¤")
    
    # ë°ì´í„° í–‰ ì¶œë ¥
    for i, candidate in enumerate(candidates, 1):
        similarity = candidate.get('similarity_score', 0.0)
        
        # í›„ë³´ ìƒí’ˆëª…ë„ ë§¥ë½ ì •ë³´ì™€ í•¨ê»˜ í‘œì‹œ
        candidate_name = enhance_product_name_with_context(
            candidate['name_kr'], 
            hs6_description
        )
        
        # ê° ì»¬ëŸ¼ ë°ì´í„° í¬ë§·íŒ…
        rank_text = pad_text_to_width(str(i), rank_width)
        code_text = pad_text_to_width(candidate['hs_code'], code_width)
        
        # ìƒí’ˆëª…ì€ ê¸¸ì´ì— ë§ê²Œ ìë¥´ê³  íŒ¨ë”©
        name_truncated = truncate_text_to_width(candidate_name, name_width)
        name_text = pad_text_to_width(name_truncated, name_width)
        
        similarity_text = pad_text_to_width(f"{similarity:.1%}", similarity_width)
        
        print(f"â”‚{rank_text}â”‚{code_text}â”‚{name_text}â”‚{similarity_text}â”‚")
    
    # í•˜ë‹¨ ê²½ê³„
    print("â””" + "â”€" * rank_width + "â”´" + "â”€" * code_width + "â”´" + "â”€" * name_width + "â”´" + "â”€" * similarity_width + "â”˜")

def print_success_result(result, converter):
    """ì„±ê³µ ê²°ê³¼ ì¶œë ¥ (Gradio ìŠ¤íƒ€ì¼)"""
    us_info = result['us_info']
    korea_rec = result['korea_recommendation']
    hs_analysis = result['hs_analysis']
    
    # HS6 ë¶„ë¥˜ ì„¤ëª… ê°€ì ¸ì˜¤ê¸°
    hs6 = us_info['hs_components']['hs6']
    hs6_description = converter.get_hs6_description(hs6)
    
    # í•œêµ­ ìƒí’ˆëª…ì— ë§¥ë½ ì •ë³´ ì¶”ê°€ (ê¸°íƒ€ í•­ëª©ì¸ ê²½ìš°)
    enhanced_korea_name = enhance_product_name_with_context(
        korea_rec['name_kr'], 
        hs6_description
    )
    
    print("âœ… **ë³€í™˜ ì„±ê³µ!**\n")
    
    print("ğŸ“‹ **ë¯¸êµ­ HS ì½”ë“œ ì •ë³´**")
    print(f"- ì½”ë“œ: {result['us_hs_code']}")
    print(f"- ì˜ë¬¸ëª…: {us_info['english_name']}")
    print(f"- í•œê¸€ëª…: {us_info.get('korean_name', 'ì—†ìŒ')}")
    
    print(f"\nğŸ¯ **ì¶”ì²œ í•œêµ­ HSK ì½”ë“œ**")
    print(f"- ì½”ë“œ: {korea_rec['hs_code']}")
    print(f"- ìƒí’ˆëª…: {enhanced_korea_name}")
    print(f"- ì‹ ë¢°ë„: {korea_rec['confidence']:.1%}")
    print(f"- ë°ì´í„° ì¶œì²˜: {korea_rec.get('data_source', 'í†µí•©')}")
    
    print(f"\nğŸ“Š **ë¶„ì„ ì •ë³´**")
    print(f"- HS 6ìë¦¬ ë§¤ì¹­: âœ… ì™„ë£Œ ({hs_analysis['us_hs6']})")
    print(f"- êµ¬ì¡° ìœ ì‚¬ë„: {hs_analysis['hs_similarity']:.1%}")
    print(f"- ì˜ë¯¸ ìœ ì‚¬ë„: {hs_analysis['semantic_similarity']:.1%}")
    print(f"- í›„ë³´êµ° ìˆ˜: {hs_analysis['total_candidates']}ê°œ")
    
    # ê¸°íƒ€ í•­ëª©ì¸ ê²½ìš° ë§¥ë½ ì„¤ëª… ì¶”ê°€
    if is_other_item(us_info.get('english_name', '')) or is_other_item(korea_rec.get('name_kr', '')):
        print(f"\nğŸ’¡ **ë¶„ì•¼ ë§¥ë½**")
        print(f"- HS {hs6} ë¶„ë¥˜: {hs6_description}")
        print(f"- í•´ì„: ì´ëŠ” '{hs6_description} ë¶„ì•¼ì˜ ê¸°íƒ€ í•­ëª©'ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.")
    
    # ìƒìœ„ í›„ë³´ ëª©ë¡ (ê°œì„ ëœ í…Œì´ë¸”) - 3ê°œ ëª¨ë‘ í‘œì‹œ
    if 'all_candidates' in result and result['all_candidates']:
        print(f"\nğŸ¯ **ìƒìœ„ í›„ë³´ ëª©ë¡**")
        print_candidates_table(result['all_candidates'][:3], hs6_description)

def print_error_result(result):
    """ì˜¤ë¥˜ ê²°ê³¼ ì¶œë ¥"""
    print("âŒ **ì˜¤ë¥˜ ë°œìƒ**\n")
    print(f"ë©”ì‹œì§€: {result['message']}")
    
    if 'suggestions' in result and result['suggestions']:
        print(f"\nğŸ’¡ **ìœ ì‚¬í•œ ì½”ë“œ ì œì•ˆ:**")
        for suggestion in result['suggestions'][:3]:
            print(f"- {suggestion}")

def print_no_match_result(result, converter):
    """HS 6ìë¦¬ ë§¤ì¹­ ì‹¤íŒ¨ ê²°ê³¼ ì¶œë ¥"""
    print("âŒ **HS 6ìë¦¬ ë§¤ì¹­ ì‹¤íŒ¨**\n")
    print(f"ë¯¸êµ­ HS ì½”ë“œ '{result['us_hs_code']}'ì˜ HS 6ìë¦¬ '{result['hs6']}'ì— í•´ë‹¹í•˜ëŠ” í•œêµ­ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.\n")
    
    print("ğŸ“‹ **ë¯¸êµ­ ì½”ë“œ ì •ë³´**")
    print(f"- ì˜ë¬¸ëª…: {result['us_info']['english_name']}")
    print(f"- í•œê¸€ëª…: {result['us_info'].get('korean_name', 'ì—†ìŒ')}")
    
    print(f"\nğŸ’¡ **ë¶„ì•¼ ë§¥ë½**")
    hs6_description = converter.get_hs6_description(result['hs6'])
    print(f"- HS {result['hs6']} ë¶„ë¥˜: {hs6_description}")
    print(f"- ì´ ìƒí’ˆì€ {hs6_description} ë¶„ì•¼ì— ì†í•˜ì§€ë§Œ í•œêµ­ì—ì„œëŠ” ë‹¤ë¥¸ ë¶„ë¥˜ ì²´ê³„ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜")
    print(f"  í•´ë‹¹ ìƒí’ˆì´ ì·¨ê¸‰ë˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
