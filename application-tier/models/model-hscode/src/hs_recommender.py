
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any
import os

import sys
from pathlib import Path
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
project_root = Path(__file__).parent.parent
load_dotenv(project_root / ".env")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€ (model-hscode í´ë”)
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(Path(__file__).parent))

from data_processor import DataProcessor
from search_engine import SearchEngine
from cache_manager import CacheManager
from config import SYSTEM_CONFIG

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

class HSCodeRecommender:
    """HS ì½”ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤ (final_combined_text ì§€ì›)"""
    
    def __init__(self, semantic_model_name: str = None, top_k: int = None, cache_dir: str = './cache'):
        self.semantic_model_name = semantic_model_name or SYSTEM_CONFIG['semantic_model']
        self.top_k = top_k or SYSTEM_CONFIG['top_k']
        self.cache_dir = cache_dir
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.data_processor = DataProcessor(debug_mode=False)
        self.search_engine = SearchEngine(self.semantic_model_name)
        self.cache_manager = CacheManager(cache_dir)
        
        # ìƒíƒœ ë³€ìˆ˜
        self.is_initialized = False
        self.openai_client = None
        self.integrated_df = None
        
        print(f"HS ì½”ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print(f"  ì˜ë¯¸ ëª¨ë¸: {self.semantic_model_name}")
        print(f"  ìƒìœ„ ê²°ê³¼ ìˆ˜: {self.top_k}")
        print(f"  ìºì‹œ ë””ë ‰í† ë¦¬: {self.cache_dir}")
    
    def initialize_openai(self) -> bool:
        """OpenAI API ì´ˆê¸°í™”"""
        if not OPENAI_AVAILABLE:
            print("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False
        
        try:
            api_key = None
            
            # 1. í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ í™•ì¸ (ìš°ì„ ìˆœìœ„)
            env_api_key = os.getenv('OPENAI_API_KEY')
            if env_api_key:
                api_key = env_api_key.strip()
                print("í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ë¡œë“œ")
            else:
                # 2. íŒŒì¼ì—ì„œ API í‚¤ í™•ì¸ (ëŒ€ì²´)
                api_file = SYSTEM_CONFIG.get('openai_api_file', 'openai_api.txt')
                if os.path.exists(api_file):
                    with open(api_file, 'r', encoding='utf-8') as f:
                        api_key = f.read().strip()
                    print(f"íŒŒì¼ì—ì„œ OpenAI API í‚¤ ë¡œë“œ: {api_file}")
                else:
                    print(f"í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYì™€ API í‚¤ íŒŒì¼ {api_file} ëª¨ë‘ ì—†ìŠµë‹ˆë‹¤")
                    return False
            
            if not api_key:
                print("ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
                
            self.openai_client = openai.OpenAI(api_key=api_key)
            
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜¸ì¶œ
            test_response = self.openai_client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=[{"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”"}],
                max_tokens=10
            )
            
            print("OpenAI API ì´ˆê¸°í™” ì„±ê³µ")
            return True
                
        except Exception as e:
            print(f"OpenAI API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.openai_client = None
            return False
    
    def load_data(self, force_rebuild: bool = False) -> bool:
        """ë°ì´í„° ë¡œë“œ ë° ì¸ë±ìŠ¤ êµ¬ì¶• (final_combined_text ì§€ì›)"""
        try:
            # ìºì‹œ í™•ì¸
            if not force_rebuild and self.cache_manager.is_cache_valid(self.semantic_model_name):
                print("ìœ íš¨í•œ ìºì‹œ ë°œê²¬ - ìºì‹œì—ì„œ ë¡œë“œ")
                cache_data = self.cache_manager.load_cache()
                
                if cache_data:
                    self.integrated_df = cache_data['integrated_df']
                    
                    # final_combined_text ì»¬ëŸ¼ í™•ì¸
                    if 'final_combined_text' not in self.integrated_df.columns:
                        print("  âŒ ìºì‹œëœ ë°ì´í„°ì— final_combined_text ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
                        print("  ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¡œë“œí•©ë‹ˆë‹¤...")
                        force_rebuild = True
                    else:
                        # ê²€ìƒ‰ ì—”ì§„ì— ë°ì´í„° ë¡œë“œ
                        if self.search_engine.load_data(
                            self.integrated_df,
                            cache_data.get('standard_mapping', {}),
                            cache_data.get('reverse_mapping', {}),
                            cache_data.get('chapter_descriptions', {})
                        ):
                            # ì¸ë±ìŠ¤ ë³µì›
                            self.search_engine.tfidf_matrix = cache_data['tfidf_matrix']
                            self.search_engine.tfidf_vectorizer = cache_data['tfidf_vectorizer']
                            self.search_engine.semantic_embeddings = cache_data['semantic_embeddings']
                            
                            self.is_initialized = True
                            print("ìºì‹œì—ì„œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
                            return True
                        else:
                            force_rebuild = True
            
            # ìºì‹œê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ê°•ì œ ì¬êµ¬ì¶•
            if force_rebuild or not self.is_initialized:
                print("ë°ì´í„° ìƒˆë¡œ ë¡œë“œ ë° ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
                
                # 1. ë°ì´í„° ë¡œë“œ ë° í†µí•©
                if not self.data_processor.load_all_data():
                    print("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
                    return False
                
                self.integrated_df = self.data_processor.get_integrated_data()
                chapter_descriptions = self.data_processor.get_chapter_descriptions()
                
                # final_combined_text ì»¬ëŸ¼ í™•ì¸
                if 'final_combined_text' not in self.integrated_df.columns:
                    print("âŒ ë¡œë“œëœ ë°ì´í„°ì— final_combined_text ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
                    return False
                
                print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.integrated_df)}ê°œ í•­ëª©")
                
                # 2. í‘œì¤€í’ˆëª… ë§¤í•‘ êµ¬ì¶•
                standard_mapping, reverse_mapping = self._build_standard_mappings()
                
                # 3. ê²€ìƒ‰ ì—”ì§„ì— ë°ì´í„° ë¡œë“œ ë° ì¸ë±ìŠ¤ êµ¬ì¶•
                if not self.search_engine.load_data(self.integrated_df, standard_mapping, reverse_mapping, chapter_descriptions):
                    print("ê²€ìƒ‰ ì—”ì§„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
                    return False
                
                self.search_engine.build_index()
                
                # 4. ìºì‹œ ì €ì¥
                self.cache_manager.save_cache(
                    self.integrated_df,
                    self.search_engine.semantic_embeddings,
                    self.search_engine.tfidf_matrix,
                    self.search_engine.tfidf_vectorizer,
                    standard_mapping,
                    reverse_mapping,
                    chapter_descriptions,
                    self.semantic_model_name
                )
                
                self.is_initialized = True
                print("âœ… ëª¨ë“  ì´ˆê¸°í™” ì™„ë£Œ!")
            
            return True
            
        except Exception as e:
            print(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    
    def _build_standard_mappings(self) -> tuple:
        """í‘œì¤€í’ˆëª… ë§¤í•‘ êµ¬ì¶•"""
        print("í‘œì¤€í’ˆëª… ë§¤í•‘ êµ¬ì¶• ì¤‘...")
        
        standard_mapping = {}
        reverse_mapping = {}
        
        if self.integrated_df is None:
            return standard_mapping, reverse_mapping
        
        # í‘œì¤€í’ˆëª… ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
        std_columns = []
        for col in self.integrated_df.columns:
            if any(keyword in col.lower() for keyword in ['í‘œì¤€í’ˆëª…', 'standard', 'í’ˆëª…']):
                if col not in ['HS_KEY', 'final_combined_text', 'data_source']:
                    std_columns.append(col)
        
        mapping_count = 0
        
        for _, row in self.integrated_df.iterrows():
            hs_key = row.get('HS_KEY', '')
            if not hs_key:
                continue
            
            # í‘œì¤€í’ˆëª…ë“¤ ìˆ˜ì§‘
            standard_names = set()
            for col in std_columns:
                if pd.notna(row[col]):
                    name = str(row[col]).strip().lower()
                    if name and len(name) > 1:
                        standard_names.add(name)
            
            # ë§¤í•‘ êµ¬ì¶•
            for std_name in standard_names:
                if std_name not in standard_mapping:
                    standard_mapping[std_name] = []
                if hs_key not in standard_mapping[std_name]:
                    standard_mapping[std_name].append(hs_key)
                
                if hs_key not in reverse_mapping:
                    reverse_mapping[hs_key] = []
                if std_name not in reverse_mapping[hs_key]:
                    reverse_mapping[hs_key].append(std_name)
                
                mapping_count += 1
        
        print(f"  ë§¤í•‘ ì™„ë£Œ: {len(standard_mapping)}ê°œ í‘œì¤€í’ˆëª…, {mapping_count}ê°œ ë§¤í•‘")
        return standard_mapping, reverse_mapping
    
    def recommend(self, query: str, material: str = "", usage: str = "", 
                  use_llm: bool = False, final_count: int = 3) -> Dict:
        """HS ì½”ë“œ ì¶”ì²œ ì‹¤í–‰"""
        if not self.is_initialized:
            raise ValueError("ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        print(f"\n{'='*60}")
        print(f"HS ì½”ë“œ ì¶”ì²œ ì‹¤í–‰")
        print(f"{'='*60}")
        print(f"ì¿¼ë¦¬: '{query}'")
        if material:
            print(f"ì¬ì§ˆ: '{material}'")
        if usage:
            print(f"ìš©ë„: '{usage}'")
        print(f"LLM ë¶„ì„: {'ì‚¬ìš©' if use_llm else 'ë¯¸ì‚¬ìš©'}")
        
        try:
            # 1. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
            search_results = self.search_engine.search(query, material, usage)
            
            if len(search_results) == 0:
                return {
                    'query': query,
                    'material': material,
                    'usage': usage,
                    'recommendations': [],
                    'search_info': {'total_candidates': 0, 'llm_analysis': None}
                }
            
            # 2. LLM ë¶„ì„ (ì„ íƒì )
            llm_analysis = None
            if use_llm and self.openai_client:
                llm_analysis = self._analyze_with_llm(query, material, usage, search_results.head(10))
            
            # 3. ìµœì¢… ì¶”ì²œ ê²°ê³¼ ìƒì„±
            recommendations = self._format_recommendations(search_results.head(final_count * 2), llm_analysis, final_count)
            
            return {
                'query': query,
                'material': material,
                'usage': usage,
                'recommendations': recommendations[:final_count],
                'search_info': {
                    'total_candidates': len(search_results),
                    'semantic_model': self.semantic_model_name,
                    'llm_analysis': llm_analysis,
                    'expanded_query': search_results.iloc[0]['expanded_query'] if len(search_results) > 0 else query
                }
            }
            
        except Exception as e:
            print(f"ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                'query': query,
                'material': material,
                'usage': usage,
                'recommendations': [],
                'search_info': {'error': str(e), 'total_candidates': 0}
            }
    
    def _analyze_with_llm(self, query: str, material: str, usage: str, candidates: pd.DataFrame) -> Optional[Dict]:
        """LLMì„ í™œìš©í•œ í›„ë³´ ë¶„ì„"""
        try:
            # í›„ë³´ ì •ë³´ ì¤€ë¹„
            candidate_info = []
            for idx, row in candidates.head(3).iterrows():
                hs_key = row.get('HS_KEY', '')
                hs_code = row.get('HSë¶€í˜¸', hs_key)
                
                # ì´ë¦„ ì •ë³´
                name_kr = ''
                for col in ['í•œê¸€í’ˆëª©ëª…', 'ì„¸ë²ˆ10ë‹¨ìœ„í’ˆëª…', 'í‘œì¤€í’ˆëª…']:
                    if col in row and pd.notna(row[col]):
                        name_kr = str(row[col])
                        break
                
                # ì„¤ëª… ì •ë³´
                description = ''
                if 'final_combined_text' in row and pd.notna(row['final_combined_text']):
                    description = str(row['final_combined_text'])[:200]
                
                candidate_info.append({
                    'hs_code': hs_code,
                    'name_kr': name_kr,
                    'description': description,
                    'score': row.get('hybrid_score', 0)
                })
            
            # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""ë‹¤ìŒ ìƒí’ˆì— ëŒ€í•œ HS ì½”ë“œ ì¶”ì²œì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ìƒí’ˆ ì •ë³´:
- ìƒí’ˆëª…: {query}
- ì¬ì§ˆ: {material if material else 'ëª…ì‹œë˜ì§€ ì•ŠìŒ'}
- ìš©ë„: {usage if usage else 'ëª…ì‹œë˜ì§€ ì•ŠìŒ'}

ì¶”ì²œ í›„ë³´ë“¤:
"""
            
            for i, candidate in enumerate(candidate_info, 1):
                prompt += f"""
{i}. HSì½”ë“œ: {candidate['hs_code']}
   í•œê¸€ëª…: {candidate['name_kr']}
   ì„¤ëª…: {candidate['description'][:100]}...
   ì ìˆ˜: {candidate['score']:.3f}
"""
            
            prompt += """
ê° í›„ë³´ì— ëŒ€í•´ ë¶„ì„ í›„ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{
  "analysis": [
    {
      "hs_code": "ì½”ë“œ",
      "fitness_score": ì ìˆ˜(1-10),
      "reason": "ì¶”ì²œ ì´ìœ ",
      "caution": "ì£¼ì˜ì‚¬í•­"
    }
  ],
  "recommendation": "ì „ì²´ì ì¸ ì¶”ì²œ ì˜ê²¬"
}
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ HS ì½”ë“œ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.3
            )
            
            try:
                import json
                return json.loads(response.choices[0].message.content)
            except:
                return {"analysis": [], "recommendation": response.choices[0].message.content}
                
        except Exception as e:
            print(f"LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None
    
    def _format_recommendations(self, search_results: pd.DataFrame, llm_analysis: Optional[Dict], final_count: int) -> List[Dict]:
        """ì¶”ì²œ ê²°ê³¼ í¬ë§·íŒ…"""
        recommendations = []
        
        # LLM ë¶„ì„ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        llm_scores = {}
        if llm_analysis and 'analysis' in llm_analysis:
            for item in llm_analysis['analysis']:
                hs_code = item.get('hs_code', '')
                llm_scores[hs_code] = {
                    'fitness_score': item.get('fitness_score', 0),
                    'reason': item.get('reason', ''),
                    'caution': item.get('caution', '')
                }
        
        for idx, row in search_results.iterrows():
            hs_key = row.get('HS_KEY', '')
            hs_code = row.get('HSë¶€í˜¸', hs_key)
            
            # ì´ë¦„ ì •ë³´
            name_kr = self._extract_best_name(row, ['í•œê¸€í’ˆëª©ëª…', 'ì„¸ë²ˆ10ë‹¨ìœ„í’ˆëª…', 'í‘œì¤€í’ˆëª…'])
            name_en = self._extract_best_name(row, ['ì˜ë¬¸í’ˆëª©ëª…', 'í‘œì¤€í’ˆëª…ì˜ë¬¸'])
            
            # ì„¤ëª… ì •ë³´
            description = ''
            if 'final_combined_text' in row and pd.notna(row['final_combined_text']):
                description = str(row['final_combined_text'])
            
            # ì ìˆ˜ ë° ì‹ ë¢°ë„
            hybrid_score = row.get('hybrid_score', 0)
            confidence = min(hybrid_score, 1.0)
            
            # LLM ì ìˆ˜ ë°˜ì˜
            llm_info = llm_scores.get(hs_code, {})
            if llm_info.get('fitness_score'):
                llm_fitness = llm_info['fitness_score'] / 10.0
                confidence = (confidence + llm_fitness) / 2
            
            recommendation = {
                'hs_code': hs_code,
                'hs_key': hs_key,
                'name_kr': name_kr,
                'name_en': name_en,
                'description': description[:500] if description else '',
                'chapter': row.get('chapter', hs_key[:2] if hs_key else ''),
                'heading': row.get('heading', hs_key[:4] if hs_key else ''),
                'confidence': round(confidence, 4),
                'scores': {
                    'hybrid': round(hybrid_score, 4),
                    'keyword': round(row.get('keyword_score', 0), 4),
                    'semantic': round(row.get('semantic_score', 0), 4)
                },
                'data_source': row.get('data_source', ''),
                'is_standard_match': row.get('is_standard_match', False)
            }
            
            if llm_info:
                recommendation['llm_analysis'] = llm_info
            
            recommendations.append(recommendation)
            
            if len(recommendations) >= final_count:
                break
        
        return recommendations
    
    def _extract_best_name(self, row: pd.Series, column_candidates: List[str]) -> str:
        """ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ìµœì ì˜ ì´ë¦„ ì¶”ì¶œ"""
        for col in column_candidates:
            if col in row and pd.notna(row[col]):
                name = str(row[col]).strip()
                if name and len(name) > 1:
                    return name
        return ''
    
    def print_results(self, results: Dict, query: str):
        """ì¶”ì²œ ê²°ê³¼ ì¶œë ¥"""
        print(f"\n{'='*80}")
        print(f"'{query}' ê²€ìƒ‰ ê²°ê³¼")
        print(f"{'='*80}")
        
        recommendations = results.get('recommendations', [])
        
        if not recommendations:
            print("ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        for i, rec in enumerate(recommendations, 1):
            print(f"\n{i}. HS ì½”ë“œ: {rec['hs_code']}")
            print(f"   í•œê¸€ëª…: {rec['name_kr']}")
            if rec['name_en']:
                print(f"   ì˜ë¬¸ëª…: {rec['name_en']}")
            print(f"   ì‹ ë¢°ë„: {rec['confidence']:.3f}")
            print(f"   ì¥: {rec['chapter']}, í˜¸: {rec['heading']}")
            
            if rec.get('description'):
                desc = rec['description']
                if len(desc) > 150:
                    desc = desc[:150] + "..."
                print(f"   ì„¤ëª…: {desc}")
            
            # LLM ë¶„ì„ ê²°ê³¼
            if rec.get('llm_analysis'):
                llm = rec['llm_analysis']
                if llm.get('reason'):
                    print(f"   AI ë¶„ì„: {llm['reason']}")
                if llm.get('caution'):
                    print(f"   ì£¼ì˜ì‚¬í•­: {llm['caution']}")
            
            print(f"   ë°ì´í„° ì†ŒìŠ¤: {rec.get('data_source', '')}")
        
        # ê²€ìƒ‰ ì •ë³´
        search_info = results.get('search_info', {})
        print(f"\nê²€ìƒ‰ ì •ë³´:")
        print(f"  ì´ í›„ë³´: {search_info.get('total_candidates', 0)}ê°œ")
        print(f"  ì˜ë¯¸ ëª¨ë¸: {search_info.get('semantic_model', '')}")
        
        if search_info.get('llm_analysis') and search_info['llm_analysis'].get('recommendation'):
            print(f"\nì „ì²´ AI ì¶”ì²œ ì˜ê²¬:")
            print(f"  {search_info['llm_analysis']['recommendation']}")
    
    def get_statistics(self) -> Dict:
        """ì‹œìŠ¤í…œ í†µê³„ ë°˜í™˜"""
        stats = {
            'system_initialized': self.is_initialized,
            'openai_available': self.openai_client is not None,
            'semantic_model': self.semantic_model_name,
            'cache_dir': self.cache_dir
        }
        
        if self.integrated_df is not None:
            stats.update({
                'total_items': len(self.integrated_df),
                'chapters': len(self.integrated_df['chapter'].unique()) if 'chapter' in self.integrated_df.columns else 0,
                'data_sources': self.integrated_df['data_source'].value_counts().to_dict() if 'data_source' in self.integrated_df.columns else {}
            })
            
            # í‘œì¤€í’ˆëª… ì»¤ë²„ë¦¬ì§€
            if 'data_source' in self.integrated_df.columns:
                with_std = self.integrated_df['data_source'].str.contains('std', na=False).sum()
                coverage = (with_std / len(self.integrated_df)) * 100
                stats['standard_coverage'] = coverage
        
        # ìºì‹œ ì •ë³´
        cache_info = self.cache_manager.get_cache_info(self.semantic_model_name)
        stats['cache_info'] = cache_info
        
        return stats
    
    def get_cache_info(self) -> Dict:
        """ìºì‹œ ì •ë³´ ë°˜í™˜"""
        return self.cache_manager.get_cache_info(self.semantic_model_name)
    
    def clear_cache(self) -> int:
        """ìºì‹œ ì‚­ì œ"""
        return self.cache_manager.clear_cache()
    
    def copy_cache_from_colab(self, colab_cache_dir: str) -> bool:
        """ì½”ë©ì—ì„œ ìºì‹œ ë³µì‚¬"""
        return self.cache_manager.copy_from_colab(colab_cache_dir)
    
 
    
    def _parse_llm_candidates(self, llm_response: str) -> List[Dict]:
        """LLM ì‘ë‹µì—ì„œ HS ì½”ë“œ í›„ë³´ íŒŒì‹±"""
        try:
            import json
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            start = llm_response.find('{')
            end = llm_response.rfind('}') + 1
            if start != -1 and end != 0:
                json_str = llm_response[start:end]
                data = json.loads(json_str)
                return data.get('candidates', [])
        except:
            # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
            candidates = []
            lines = llm_response.split('\n')
            for line in lines:
                if any(char.isdigit() for char in line) and len([c for c in line if c.isdigit()]) >= 10:
                    # 10ìë¦¬ ìˆ«ìê°€ í¬í•¨ëœ ë¼ì¸ì—ì„œ HS ì½”ë“œ ì¶”ì¶œ ì‹œë„
                    import re
                    hs_match = re.search(r'\b(\d{10})\b', line)
                    if hs_match:
                        candidates.append({
                            'hs_code': hs_match.group(1),
                            'confidence': 7,  # ê¸°ë³¸ê°’
                            'reasoning': line.strip(),
                            'chapter': hs_match.group(1)[:2],
                            'category': 'LLM ì œì•ˆ'
                        })
            return candidates[:5]  # ìµœëŒ€ 5ê°œ
        
        return []
    

    def recommend_ultimate(self, query: str, material: str = "", usage: str = "", 
                          final_count: int = 5) -> Dict:
        """LLM í†µí•© ì¶”ì²œ ì‹œìŠ¤í…œ"""
        if not self.is_initialized:
            raise ValueError("ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        if not self.openai_client:
            print("âš ï¸ OpenAIê°€ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¶”ì²œì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return self.recommend(query, material, usage, use_llm=False, final_count=final_count)
        
        print(f"\n{'='*60}")
        print(f"ğŸ§  LLM í†µí•© ì¶”ì²œ ì‹œìŠ¤í…œ")
        print(f"{'='*60}")
        print(f"ì¿¼ë¦¬: '{query}'")
        if material:
            print(f"ì¬ì§ˆ: '{material}'")
        if usage:
            print(f"ìš©ë„: '{usage}'")
        
        try:
            # 1. LLM ì§ì ‘ í›„ë³´ ìƒì„±
            print(f"\n1. LLM ì§ì ‘ í›„ë³´ ìƒì„±...")
            llm_candidates = self._get_llm_candidates(query, material, usage)
            print(f"  LLM í›„ë³´ í†µí•©: {len(llm_candidates)}ê°œ")
            
            # 2. ê²€ìƒ‰ì—”ì§„ í›„ë³´ ìƒì„±
            print(f"\n2. ê²€ìƒ‰ì—”ì§„ í›„ë³´ ìƒì„±...")
            search_results = self.search_engine.search(query, material, usage)
            print(f"  ê²€ìƒ‰ í›„ë³´: {len(search_results)}ê°œ")
            
            # 3. LLM í›„ë³´ì™€ ê²€ìƒ‰ ê²°ê³¼ í†µí•©
            print(f"\n3. LLM í›„ë³´ì™€ ê²€ìƒ‰ ê²°ê³¼ í†µí•©...")
            integrated_results = self._integrate_llm_and_search(llm_candidates, search_results)
            print(f"  í†µí•© í›„ë³´: {len(integrated_results)}ê°œ")
            
            # 4. LLM ì¬ìˆœìœ„ ë¶„ì„
            print(f"\n4. LLM ì¬ìˆœìœ„ ë¶„ì„...")
            reranked_results = self._llm_rerank(query, material, usage, integrated_results.head(20))
            print(f"  LLM ì¬ìˆœìœ„ ë¶„ì„: {len(reranked_results)}ê°œ í›„ë³´")
            
            # 4.5. LLM ê³ ë“ì  í›„ë³´ ìš°ì„  ë°˜ì˜ (NEW!)
            print(f"\n4.5. LLM ê³ ë“ì  í›„ë³´ ìš°ì„  ë°˜ì˜...")
            final_results = self._boost_high_scoring_llm_candidates(llm_candidates, reranked_results, query, material, usage)
            print(f"  ê³ ë“ì  í›„ë³´ ë°˜ì˜ ì™„ë£Œ: {len(final_results)}ê°œ í›„ë³´")
            
            # 5. ìµœì¢… ì¶”ì²œ ê²°ê³¼ ìƒì„±
            print(f"\n5. ìµœì¢… ì¶”ì²œ ê²°ê³¼ ìƒì„±...")
            
            # ìµœì¢… ì •ë ¬ ìƒíƒœ í™•ì¸
            print(f"    ğŸ† ìµœì¢… í›„ë³´ ìƒìœ„ 10ê°œ:")
            for i, (idx, row) in enumerate(final_results.head(10).iterrows()):
                hs_code = row.get('HS_KEY') or row.get('HSë¶€í˜¸', '')
                ultimate_score = row.get('ultimate_score', 0)
                llm_rerank_score = row.get('llm_rerank_score', 0)
                match_type = row.get('match_type', '')
                print(f"    {i+1:2d}. {hs_code}: {ultimate_score:.4f} (LLMì¬ìˆœìœ„: {llm_rerank_score}, ìœ í˜•: {match_type})")
            
            recommendations = self._format_ultimate_recommendations(final_results, final_count)
            
            return {
                'query': query,
                'material': material,
                'usage': usage,
                'recommendations': recommendations,
                'search_info': {
                    'method': 'ultimate_llm_hybrid',
                    'llm_candidates': len(llm_candidates),
                    'search_candidates': len(search_results),
                    'total_candidates': len(integrated_results),
                    'semantic_model': self.semantic_model_name,
                    'llm_model': 'gpt-4.1-mini',
                }
            }
            
        except Exception as e:
            print(f"LLM í†µí•© ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ê¸°ë³¸ ì¶”ì²œ ì‹œìŠ¤í…œìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...")
            return self.recommend(query, material, usage, use_llm=True, final_count=final_count)
    
    def _get_llm_candidates(self, query: str, material: str, usage: str) -> List[Dict]:
        """LLMì´ ì§ì ‘ HS ì½”ë“œ í›„ë³´ë¥¼ ì œì•ˆ"""
        try:
            # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""ë‹¤ìŒ ìƒí’ˆì— ëŒ€í•œ HS ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ í›„ë³´ 3ê°œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”:

ìƒí’ˆ ì •ë³´:
- ìƒí’ˆëª…: {query}
- ì¬ì§ˆ: {material if material else 'ëª…ì‹œë˜ì§€ ì•ŠìŒ'}
- ìš©ë„: {usage if usage else 'ëª…ì‹œë˜ì§€ ì•ŠìŒ'}

ìš”êµ¬ì‚¬í•­:
1. í•œêµ­ ê´€ì„¸ë²•ìƒ HS ì½”ë“œ 10ìë¦¬ë¥¼ ì •í™•íˆ ì œì•ˆí•˜ì„¸ìš”
2. ê° í›„ë³´ì— ëŒ€í•´ 1-10ì  í™•ì‹ ë„ë¥¼ ë¶€ì—¬í•˜ì„¸ìš”
3. ì œì•ˆ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”

ì‘ë‹µ í˜•ì‹ (JSON):
{{
  "candidates": [
    {{
      "hs_code": "1234567890",
      "confidence": 9,
      "reason": "ì œì•ˆ ì´ìœ "
    }}
  ]
}}
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ ê´€ì„¸ë²• ë° HS ì½”ë“œ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.3
            )
            
            try:
                import json
                result = json.loads(response.choices[0].message.content)
                candidates = result.get('candidates', [])
                
                # í›„ë³´ë“¤ì„ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
                candidates.sort(key=lambda x: x.get('confidence', 0), reverse=True)
                
                # ê²€ìƒ‰ì—”ì§„ì—ì„œ í•´ë‹¹ HS ì½”ë“œë“¤ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ
                enriched_candidates = []
                for candidate in candidates[:5]:
                    hs_code = candidate.get('hs_code', '')
                    if len(hs_code) == 10:
                        # ë°ì´í„°ì—ì„œ í•´ë‹¹ HS ì½”ë“œ ì°¾ê¸°
                        matching_rows = self.integrated_df[
                            (self.integrated_df['HS_KEY'] == hs_code) |
                            (self.integrated_df.get('HSë¶€í˜¸', '') == hs_code)
                        ]
                        
                        if not matching_rows.empty:
                            row = matching_rows.iloc[0]
                            enriched_candidates.append({
                                'hs_code': hs_code,
                                'confidence': candidate.get('confidence', 0),
                                'reason': candidate.get('reason', ''),
                                'row_data': row,
                                'source': 'llm_direct'
                            })
                        else:
                            # ë°ì´í„°ì— ì—†ëŠ” ê²½ìš°ë„ í›„ë³´ë¡œ í¬í•¨ (LLM ì „ìš©)
                            enriched_candidates.append({
                                'hs_code': hs_code,
                                'confidence': candidate.get('confidence', 0),
                                'reason': candidate.get('reason', ''),
                                'row_data': None,
                                'source': 'llm_only'
                            })
                
                print(f"    âœ… LLM ì§ì ‘ ì œì•ˆ: {len(enriched_candidates)}ê°œ")
                for i, cand in enumerate(enriched_candidates, 1):
                    match_status = "âœ… ë°ì´í„° ë§¤ì¹­" if cand['row_data'] is not None else "ğŸ†• LLM ì „ìš©"
                    print(f"    {i}. {cand['hs_code']} (í™•ì‹ ë„: {cand['confidence']}) - {match_status}")
                
                return enriched_candidates
                
            except json.JSONDecodeError:
                print("    âŒ LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨")
                return []
                
        except Exception as e:
            print(f"    âŒ LLM í›„ë³´ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def _integrate_llm_and_search(self, llm_candidates: List[Dict], search_results: pd.DataFrame) -> pd.DataFrame:
        """LLM í›„ë³´ì™€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©"""
        integrated_rows = []
        used_hs_codes = set()
        
        # 1. LLM í›„ë³´ë“¤ì„ ìš°ì„  ì²˜ë¦¬
        for llm_candidate in llm_candidates:
            hs_code = llm_candidate['hs_code']
            
            if llm_candidate['row_data'] is not None:
                # ë°ì´í„°ì— ìˆëŠ” LLM í›„ë³´
                row = llm_candidate['row_data'].copy()
                
                # ê²€ìƒ‰ ê²°ê³¼ì™€ ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸
                search_match = search_results[
                    (search_results['HS_KEY'] == hs_code) |
                    (search_results.get('HSë¶€í˜¸', '') == hs_code)
                ]
                
                if not search_match.empty:
                    # LLM + ê²€ìƒ‰ ë§¤ì¹­: ê°œì„ ëœ ê· í˜• ê°€ì¤‘ì¹˜
                    search_row = search_match.iloc[0]
                    hybrid_score = search_row.get('hybrid_score', 0)
                    confidence_score = llm_candidate['confidence'] / 10.0
                    
                    # ê°œì„ ëœ ê°€ì¤‘ì¹˜ ë¡œì§: LLM í™•ì‹ ë„ì— ë”°ë¼ ë™ì  ì¡°ì •
                    if llm_candidate['confidence'] >= 8:
                        # ê³ í™•ì‹  LLM: LLM ì ìˆ˜ ë” ë†’ì€ ë¹„ì¤‘
                        llm_weight = 0.7
                        search_weight = 0.3
                    elif llm_candidate['confidence'] >= 6:
                        # ì¤‘í™•ì‹  LLM: ê· í˜• ì¡íŒ ë¹„ì¤‘
                        llm_weight = 0.5
                        search_weight = 0.5
                    else:
                        # ì €í™•ì‹  LLM: ê²€ìƒ‰ ì ìˆ˜ ë” ë†’ì€ ë¹„ì¤‘
                        llm_weight = 0.3
                        search_weight = 0.7
                    
                    ultimate_score = (hybrid_score * search_weight) + (confidence_score * llm_weight)
                    
                    row['ultimate_score'] = ultimate_score
                    row['llm_confidence'] = llm_candidate['confidence']
                    row['llm_reason'] = llm_candidate['reason']
                    row['match_type'] = 'llm_search_match'
                    row['hybrid_score'] = hybrid_score
                    
                    print(f"    âœ… LLM+ê²€ìƒ‰ ë§¤ì¹­: {hs_code} (ì ìˆ˜: {ultimate_score:.3f}, LLMê°€ì¤‘ì¹˜: {llm_weight})")
                else:
                    # LLM ì „ìš© í›„ë³´: í™•ì‹ ë„ì— ë”°ë¥¸ ë™ì  ê°€ì¤‘ì¹˜
                    confidence_score = llm_candidate['confidence'] / 10.0
                    
                    if llm_candidate['confidence'] >= 8:
                        # ê³ í™•ì‹ : ë†’ì€ ì ìˆ˜ ë¶€ì—¬
                        ultimate_score = confidence_score * 0.9
                    elif llm_candidate['confidence'] >= 6:
                        # ì¤‘í™•ì‹ : ì¤‘ê°„ ì ìˆ˜
                        ultimate_score = confidence_score * 0.75
                    else:
                        # ì €í™•ì‹ : ë‚®ì€ ì ìˆ˜
                        ultimate_score = confidence_score * 0.6
                    
                    row['ultimate_score'] = ultimate_score
                    row['llm_confidence'] = llm_candidate['confidence']
                    row['llm_reason'] = llm_candidate['reason']
                    row['match_type'] = 'llm_only_with_data'
                    row['hybrid_score'] = 0.0
                    
                    print(f"    ğŸ” LLM ë°ì´í„° í›„ë³´: {hs_code} (ì ìˆ˜: {ultimate_score:.3f})")
                
                integrated_rows.append(row)
                used_hs_codes.add(hs_code)
            else:
                # ë°ì´í„°ì— ì—†ëŠ” LLM ì „ìš© í›„ë³´
                confidence_score = llm_candidate['confidence'] / 10.0
                ultimate_score = confidence_score * 0.5
                
                # ê°€ìƒì˜ í–‰ ìƒì„±
                fake_row = pd.Series({
                    'HS_KEY': hs_code,
                    'HSë¶€í˜¸': hs_code,
                    'í•œê¸€í’ˆëª©ëª…': f"LLM ì œì•ˆ: {hs_code}",
                    'ì˜ë¬¸í’ˆëª©ëª…': f"LLM Suggested: {hs_code}",
                    'ultimate_score': ultimate_score,
                    'llm_confidence': llm_candidate['confidence'],
                    'llm_reason': llm_candidate['reason'],
                    'match_type': 'llm_only_no_data',
                    'hybrid_score': 0.0,
                    'chapter': hs_code[:2] if len(hs_code) >= 2 else '',
                    'heading': hs_code[:4] if len(hs_code) >= 4 else '',
                    'data_source': 'llm_generated',
                    'final_combined_text': f"LLMì´ ì œì•ˆí•œ HS ì½”ë“œ: {hs_code}. ì´ìœ : {llm_candidate['reason']}"
                })
                
                integrated_rows.append(fake_row)
                used_hs_codes.add(hs_code)
                print(f"    ğŸ†• LLM ì „ìš© í›„ë³´: {hs_code} (í™•ì‹ ë„: {llm_candidate['confidence']})")
        
        # 2. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ LLMì— ì—†ëŠ” ê²ƒë“¤ ì¶”ê°€
        for _, search_row in search_results.iterrows():
            hs_key = search_row.get('HS_KEY', '')
            hs_code = search_row.get('HSë¶€í˜¸', hs_key)
            
            if hs_code not in used_hs_codes:
                # ê²€ìƒ‰ ì „ìš© í›„ë³´: ë‚®ì€ ê°€ì¤‘ì¹˜
                hybrid_score = search_row.get('hybrid_score', 0)
                ultimate_score = hybrid_score * 0.8
                
                row = search_row.copy()
                row['ultimate_score'] = ultimate_score
                row['llm_confidence'] = 0
                row['llm_reason'] = ''
                row['match_type'] = 'search_only'
                
                integrated_rows.append(row)
                used_hs_codes.add(hs_code)
        
        # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ê³  ì •ë ¬
        if integrated_rows:
            integrated_df = pd.DataFrame(integrated_rows)
            integrated_df = integrated_df.sort_values('ultimate_score', ascending=False).reset_index(drop=True)
            return integrated_df
        else:
            return pd.DataFrame()
    
    def _llm_rerank(self, query: str, material: str, usage: str, candidates: pd.DataFrame) -> pd.DataFrame:
        """LLMì„ í™œìš©í•œ í›„ë³´ ì¬ìˆœìœ„ ê²°ì •"""
        if len(candidates) == 0:
            return candidates
        
        try:
            # ìƒìœ„ í›„ë³´ë“¤ ì •ë³´ ì¤€ë¹„
            candidate_info = []
            for idx, row in candidates.head(10).iterrows():
                hs_code = row.get('HS_KEY') or row.get('HSë¶€í˜¸', '')
                name_kr = row.get('í•œê¸€í’ˆëª©ëª…', '')
                description = row.get('final_combined_text', '')[:150]
                current_score = row.get('ultimate_score', 0)
                match_type = row.get('match_type', '')
                
                candidate_info.append({
                    'hs_code': hs_code,
                    'name_kr': name_kr,
                    'description': description,
                    'current_score': current_score,
                    'match_type': match_type
                })
            
            # LLM ì¬ìˆœìœ„ í”„ë¡¬í”„íŠ¸
            prompt = f"""ë‹¤ìŒ ìƒí’ˆì— ëŒ€í•œ HS ì½”ë“œ í›„ë³´ë“¤ì„ ì¬ìˆœìœ„í•˜ì—¬ í‰ê°€í•´ì£¼ì„¸ìš”:

ìƒí’ˆ ì •ë³´:
- ìƒí’ˆëª…: {query}
- ì¬ì§ˆ: {material if material else 'ëª…ì‹œë˜ì§€ ì•ŠìŒ'}
- ìš©ë„: {usage if usage else 'ëª…ì‹œë˜ì§€ ì•ŠìŒ'}

í›„ë³´ ëª©ë¡:
"""
            
            for i, cand in enumerate(candidate_info, 1):
                prompt += f"""
{i}. HSì½”ë“œ: {cand['hs_code']}
   í•œê¸€ëª…: {cand['name_kr']}
   ì„¤ëª…: {cand['description']}
   í˜„ì¬ì ìˆ˜: {cand['current_score']:.3f}
   ë§¤ì¹­ìœ í˜•: {cand['match_type']}
"""
            
            prompt += """
ê° í›„ë³´ë¥¼ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ 1-10ì  í‰ê°€í•˜ê³  ì¬ìˆœìœ„ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”:
1. ì¬ì§ˆ ì •í™•ì„±
2. ìš©ë„ ì í•©ì„±  
3. HS ì²´ê³„ìƒ ì •í™•ì„±
4. ì‹¤ë¬´ ì‚¬ìš© ë¹ˆë„

ì‘ë‹µ í˜•ì‹ (JSON):
{
  "rankings": [
    {
      "hs_code": "ì½”ë“œ",
      "rank": 1,
      "rerank_score": 9.5,
      "reason": "ì¬ìˆœìœ„ ê·¼ê±°"
    }
  ]
}
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ HS ì½”ë“œ ë¶„ë¥˜ ë° ë¬´ì—­ ì‹¤ë¬´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.2
            )
            
            try:
                import json
                llm_response_content = response.choices[0].message.content
                print(f"    ğŸ¤– LLM ì‘ë‹µ ì›ë³¸: {llm_response_content[:200]}...")
                
                result = json.loads(llm_response_content)
                rankings = result.get('rankings', [])
                print(f"    ğŸ“ íŒŒì‹±ëœ rankings ìˆ˜: {len(rankings)}")
                
                # ì¬ìˆœìœ„ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                rerank_info = {}
                for rank_item in rankings:
                    hs_code = rank_item.get('hs_code', '')
                    rerank_info[hs_code] = {
                        'llm_rank': rank_item.get('rank', 999),
                        'llm_rerank_score': rank_item.get('rerank_score', 0),
                        'llm_rerank_reason': rank_item.get('reason', '')
                    }
                
                print(f"    ğŸ” LLMì´ í‰ê°€í•œ HSì½”ë“œë“¤: {list(rerank_info.keys())}")
                
                # ì›ë³¸ ë°ì´í„°ì— ì¬ìˆœìœ„ ì •ë³´ ì¶”ê°€
                reranked_candidates = candidates.copy()
                matched_count = 0
                unmatched_count = 0
                
                for idx, row in reranked_candidates.iterrows():
                    hs_code = row.get('HS_KEY') or row.get('HSë¶€í˜¸', '')
                    
                    # 1ì°¨ ì •í™• ë§¤ì¹­
                    if hs_code in rerank_info:
                        rerank_data = rerank_info[hs_code]
                        
                        # ìµœì¢… ì ìˆ˜ ê³„ì‚° (LLM ì¬ìˆœìœ„ë¥¼ ë” ë†’ì€ ë¹„ì¤‘ìœ¼ë¡œ)
                        current_score = row.get('ultimate_score', 0)
                        llm_rerank_score = rerank_data['llm_rerank_score'] / 10.0
                        
                        # LLM ì¬ìˆœìœ„ ì ìˆ˜ê°€ ë†’ì„ ë•Œ ë” í° ì˜í–¥ë ¥ ë¶€ì—¬
                        if rerank_data['llm_rerank_score'] >= 8.0:
                            # ê³ ë“ì : LLM 80% + ê¸°ì¡´ 20%
                            final_score = (current_score * 0.2) + (llm_rerank_score * 0.8)
                        elif rerank_data['llm_rerank_score'] >= 6.0:
                            # ì¤‘ê°„ì ìˆ˜: LLM 60% + ê¸°ì¡´ 40%
                            final_score = (current_score * 0.4) + (llm_rerank_score * 0.6)
                        else:
                            # ë‚®ì€ì ìˆ˜: LLM 40% + ê¸°ì¡´ 60%
                            final_score = (current_score * 0.6) + (llm_rerank_score * 0.4)
                        
                        reranked_candidates.at[idx, 'ultimate_score'] = final_score
                        reranked_candidates.at[idx, 'llm_rank'] = rerank_data['llm_rank']
                        reranked_candidates.at[idx, 'llm_rerank_score'] = rerank_data['llm_rerank_score']
                        reranked_candidates.at[idx, 'llm_rerank_reason'] = rerank_data['llm_rerank_reason']
                        matched_count += 1
                        print(f"    âœ… ì •í™• ë§¤ì¹­: {hs_code} (ì ìˆ˜: {rerank_data['llm_rerank_score']})")
                    else:
                        # 2ì°¨ ìœ ì‚¬ ë§¤ì¹­ ì‹œë„ (ì• 8ìë¦¬, 6ìë¦¬ ë§¤ì¹­)
                        matched_similar = False
                        
                        for llm_hs_code, llm_data in rerank_info.items():
                            # 8ìë¦¬ ë§¤ì¹­ (ì„¸ë²ˆê¹Œì§€ ë™ì¼)
                            if len(hs_code) >= 8 and len(llm_hs_code) >= 8:
                                if hs_code[:8] == llm_hs_code[:8]:
                                    # ìœ ì‚¬ ë§¤ì¹­ìœ¼ë¡œ ë‚®ì€ ê°€ì¤‘ì¹˜ ì ìš©
                                    current_score = row.get('ultimate_score', 0)
                                    llm_rerank_score = llm_data['llm_rerank_score'] / 10.0
                                    final_score = (current_score * 0.8) + (llm_rerank_score * 0.2)  # ë‚®ì€ ê°€ì¤‘ì¹˜
                                    
                                    reranked_candidates.at[idx, 'ultimate_score'] = final_score
                                    reranked_candidates.at[idx, 'llm_rank'] = llm_data['llm_rank'] + 100  # ìˆœìœ„ í˜ë„í‹°
                                    reranked_candidates.at[idx, 'llm_rerank_score'] = llm_data['llm_rerank_score'] * 0.7  # ì ìˆ˜ í• ì¸
                                    reranked_candidates.at[idx, 'llm_rerank_reason'] = f"ìœ ì‚¬ë§¤ì¹­(8ìë¦¬): {llm_data['llm_rerank_reason']}"
                                    matched_count += 1
                                    matched_similar = True
                                    print(f"    ğŸ”„ ìœ ì‚¬ ë§¤ì¹­(8ìë¦¬): {hs_code} â†” {llm_hs_code} (ì ìˆ˜: {llm_data['llm_rerank_score']*0.7})")
                                    break
                        
                        # 3ì°¨ ë” ë„“ì€ ìœ ì‚¬ ë§¤ì¹­ (6ìë¦¬)
                        if not matched_similar:
                            for llm_hs_code, llm_data in rerank_info.items():
                                # 6ìë¦¬ ë§¤ì¹­ (í˜¸ê¹Œì§€ ë™ì¼)
                                if len(hs_code) >= 6 and len(llm_hs_code) >= 6:
                                    if hs_code[:6] == llm_hs_code[:6]:
                                        # ë” ë‚®ì€ ê°€ì¤‘ì¹˜ ì ìš©
                                        current_score = row.get('ultimate_score', 0)
                                        llm_rerank_score = llm_data['llm_rerank_score'] / 10.0
                                        final_score = (current_score * 0.9) + (llm_rerank_score * 0.1)  # ë” ë‚®ì€ ê°€ì¤‘ì¹˜
                                        
                                        reranked_candidates.at[idx, 'ultimate_score'] = final_score
                                        reranked_candidates.at[idx, 'llm_rank'] = llm_data['llm_rank'] + 200  # ë” í° ìˆœìœ„ í˜ë„í‹°
                                        reranked_candidates.at[idx, 'llm_rerank_score'] = llm_data['llm_rerank_score'] * 0.5  # ë” í° ì ìˆ˜ í• ì¸
                                        reranked_candidates.at[idx, 'llm_rerank_reason'] = f"ê´‘ë²”ìœ„ë§¤ì¹­(6ìë¦¬): {llm_data['llm_rerank_reason']}"
                                        matched_count += 1
                                        matched_similar = True
                                        print(f"    ğŸŒ ê´‘ë²”ìœ„ ë§¤ì¹­(6ìë¦¬): {hs_code} â†” {llm_hs_code} (ì ìˆ˜: {llm_data['llm_rerank_score']*0.5})")
                                        break
                        
                        if not matched_similar:
                            unmatched_count += 1
                            print(f"    âŒ ë§¤ì¹­ ì‹¤íŒ¨: {hs_code} (LLM ì‘ë‹µì— ì—†ìŒ)")
                
                print(f"    ğŸ“Š ë§¤ì¹­ ê²°ê³¼: ì„±ê³µ {matched_count}ê°œ, ì‹¤íŒ¨ {unmatched_count}ê°œ")
                
                # ìµœì¢… ì ìˆ˜ë¡œ ì¬ì •ë ¬
                reranked_candidates = reranked_candidates.sort_values('ultimate_score', ascending=False).reset_index(drop=True)
                
                print(f"    âœ… LLM ì¬ìˆœìœ„ ì™„ë£Œ")
                return reranked_candidates
                
            except json.JSONDecodeError as e:
                print(f"    âš ï¸ LLM ì¬ìˆœìœ„ íŒŒì‹± ì‹¤íŒ¨: {e}")
                print(f"    ğŸ“„ ì‘ë‹µ ë‚´ìš©: {response.choices[0].message.content}")
                print(f"    ğŸ”„ ì›ë³¸ ìˆœì„œ ìœ ì§€")
                return candidates
                
        except Exception as e:
            print(f"    âš ï¸ LLM ì¬ìˆœìœ„ ì‹¤íŒ¨: {e}, ì›ë³¸ ìˆœì„œ ìœ ì§€")
            return candidates
    
    def _search_hs_code_in_data(self, hs_code: str) -> pd.Series:
        """HS ì½”ë“œë¥¼ ë°ì´í„°ì—ì„œ ê²€ìƒ‰í•˜ì—¬ í•´ë‹¹ í–‰ ë°ì´í„°ë¥¼ ë°˜í™˜"""
        try:
            print(f"    ğŸ” HSì½”ë“œ ê²€ìƒ‰ ì‹œë„: {hs_code}")
            
            if not hasattr(self, 'df') or self.df is None:
                print(f"    âŒ ë°ì´í„°í”„ë ˆì„ ì—†ìŒ")
                return None
            
            print(f"    ğŸ“Š ì „ì²´ ë°ì´í„° í–‰ìˆ˜: {len(self.df)}")
            print(f"    ğŸ“‹ ì»¬ëŸ¼ ëª©ë¡: {list(self.df.columns)}")
                
            # ì •í™• ë§¤ì¹­ ì‹œë„
            exact_match = self.df[self.df['HSë¶€í˜¸'] == hs_code]
            print(f"    ğŸ¯ ì •í™• ë§¤ì¹­ (HSë¶€í˜¸ == {hs_code}): {len(exact_match)}ê°œ")
            if not exact_match.empty:
                print(f"    âœ… ì •í™• ë§¤ì¹­ ì„±ê³µ!")
                return exact_match.iloc[0]
            
            # HS_KEYë¡œ ë§¤ì¹­ ì‹œë„
            if 'HS_KEY' in self.df.columns:
                key_match = self.df[self.df['HS_KEY'] == hs_code]
                print(f"    ğŸ”‘ HS_KEY ë§¤ì¹­ (HS_KEY == {hs_code}): {len(key_match)}ê°œ")
                if not key_match.empty:
                    print(f"    âœ… HS_KEY ë§¤ì¹­ ì„±ê³µ!")
                    return key_match.iloc[0]
            
            # 8ìë¦¬ ë§¤ì¹­ ì‹œë„
            if len(hs_code) >= 8:
                partial_match = self.df[self.df['HSë¶€í˜¸'].str.startswith(hs_code[:8])]
                print(f"    ğŸ”¢ 8ìë¦¬ ë§¤ì¹­ ({hs_code[:8]}ë¡œ ì‹œì‘): {len(partial_match)}ê°œ")
                if not partial_match.empty:
                    print(f"    âœ… 8ìë¦¬ ë§¤ì¹­ ì„±ê³µ!")
                    return partial_match.iloc[0]
            
            # 6ìë¦¬ ë§¤ì¹­ ì‹œë„
            if len(hs_code) >= 6:
                broad_match = self.df[self.df['HSë¶€í˜¸'].str.startswith(hs_code[:6])]
                print(f"    ğŸŒ 6ìë¦¬ ë§¤ì¹­ ({hs_code[:6]}ë¡œ ì‹œì‘): {len(broad_match)}ê°œ")
                if not broad_match.empty:
                    print(f"    âœ… 6ìë¦¬ ë§¤ì¹­ ì„±ê³µ!")
                    return broad_match.iloc[0]
            
            # ë” ê´‘ë²”ìœ„í•œ ê²€ìƒ‰ (392ë¡œ ì‹œì‘)
            if hs_code.startswith('392'):
                prefix_match = self.df[self.df['HSë¶€í˜¸'].str.startswith('392')]
                print(f"    ğŸ” 392 ì ‘ë‘ì–´ ë§¤ì¹­: {len(prefix_match)}ê°œ")
                if not prefix_match.empty:
                    # ê°€ì¥ ìœ ì‚¬í•œ ê²ƒ ì„ íƒ (3924ë¥˜ ìš°ì„ )
                    similar_3924 = prefix_match[prefix_match['HSë¶€í˜¸'].str.startswith('3924')]
                    if not similar_3924.empty:
                        print(f"    âœ… 3924ë¥˜ ìœ ì‚¬ ë§¤ì¹­ ì„±ê³µ!")
                        return similar_3924.iloc[0]
                    else:
                        print(f"    âš ï¸ 392ë¥˜ ì²«ë²ˆì§¸ ë§¤ì¹­ ì‚¬ìš©")
                        return prefix_match.iloc[0]
                    
            print(f"    âŒ ëª¨ë“  ë§¤ì¹­ ì‹œë„ ì‹¤íŒ¨")
            return None
            
        except Exception as e:
            print(f"    âŒ HSì½”ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
        
    def _get_top_rerank_candidates(self, reranked_results: pd.DataFrame, top_n: int = 2) -> Dict[str, Dict]:
        """LLM ì¬ìˆœìœ„ ìƒìœ„ê¶Œ í›„ë³´ ì¶”ì¶œ"""
        top_candidates = {}
        
        for idx, row in reranked_results.iterrows():
            hs_code = row.get('HS_KEY') or row.get('HSë¶€í˜¸', '')
            llm_rank = row.get('llm_rank', 999)
            llm_rerank_score = row.get('llm_rerank_score', 0)
            
            # ì¬ìˆœìœ„ 1-3ìœ„ì´ë©´ì„œ 8ì  ì´ìƒì¸ í›„ë³´
            if (pd.notna(llm_rank) and llm_rank <= top_n and 
                pd.notna(llm_rerank_score) and llm_rerank_score >= 8.0):
                top_candidates[hs_code] = {
                    'rank': llm_rank,
                    'score': llm_rerank_score,
                    'reason': row.get('llm_rerank_reason', '')
                }
                print(f"    ğŸ† ì¬ìˆœìœ„ ìƒìœ„ê¶Œ: {hs_code} (ìˆœìœ„: {llm_rank}, ì ìˆ˜: {llm_rerank_score})")
        
        return top_candidates
    
    def _boost_high_scoring_llm_candidates(self, llm_candidates: List[Dict], reranked_results: pd.DataFrame, query: str = "", material: str = "", usage: str = "") -> pd.DataFrame:
        """ğŸš€ ë‹¨ìˆœí™”ëœ ì ìˆ˜ ê¸°ë°˜ ë¶€ìŠ¤íŒ…: LLM ê³ ë“ì  í›„ë³´ë“¤ì˜ ì ìˆ˜ë¥¼ ë°°ìˆ˜ë¡œ ì¦í­"""
        try:
            print(f"    ğŸ”§ ì ìˆ˜ ê¸°ë°˜ ë¶€ìŠ¤íŒ… ì‹œì‘...")
            
            # 1. ëª¨ë“  í›„ë³´ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•©
            all_candidates = reranked_results.copy()
            
            # 2. LLM ì§ì ‘ ì œì•ˆ ê³ ë“ì  í›„ë³´ ì¶”ê°€ (ê¸°ì¡´ì— ì—†ëŠ” ê²½ìš°)
            high_score_threshold = 8.0
            new_candidates = []
            
            # 2-1. LLM ì§ì ‘ ì œì•ˆ í›„ë³´ë“¤ ì²˜ë¦¬
            for llm_candidate in llm_candidates:
                confidence = llm_candidate.get('confidence', 0)
                hs_code = llm_candidate.get('hs_code', '')
                
                # ë†’ì€ í™•ì‹ ë„ í›„ë³´ì´ë©´ì„œ ê¸°ì¡´ ê²°ê³¼ì— ì—†ëŠ” ê²½ìš°
                if confidence >= high_score_threshold:
                    existing = all_candidates[
                        (all_candidates['HS_KEY'] == hs_code) |
                        (all_candidates.get('HSë¶€í˜¸', '') == hs_code)
                    ]
                    
                    if existing.empty and llm_candidate.get('row_data') is not None:
                        # ìƒˆë¡œìš´ LLM ê³ í™•ì‹  í›„ë³´ ì¶”ê°€ (ì ì ˆí•œ ì´ˆê¸° ì ìˆ˜ë¡œ ì„¤ì •)
                        new_row = llm_candidate['row_data'].copy()
                        new_row['ultimate_score'] = min(0.85, confidence / 10.0)  # ìµœëŒ€ 0.85ë¡œ ì œí•œ ì™„í™”
                        new_row['llm_confidence'] = confidence
                        new_row['llm_reason'] = llm_candidate.get('reason', '')
                        new_row['match_type'] = 'llm_high_score_new'
                        new_row['llm_rerank_score'] = confidence
                        new_row['llm_rank'] = 1
                        new_row['llm_rerank_reason'] = f"LLM ê³ í™•ì‹  ì§ì ‘ ì œì•ˆ (í™•ì‹ ë„: {confidence}/10)"
                        new_candidates.append(new_row)
                        print(f"    â• ì‹ ê·œ ê³ í™•ì‹  í›„ë³´ ì¶”ê°€: {hs_code} (í™•ì‹ ë„: {confidence}, ì ìˆ˜: {min(0.85, confidence / 10.0):.3f})")
            
            # 2-2. LLM ì¬ìˆœìœ„ì—ì„œ ëˆ„ë½ëœ ê³ ë“ì  ì½”ë“œ ì§ì ‘ ì¶”ê°€ â­ í•µì‹¬ í•´ê²°!
            if query and self.openai_client:
                try:
                    print(f"    ğŸ” LLM ì¬ìˆœìœ„ ëˆ„ë½ ê³ ë“ì  ì½”ë“œ íƒìƒ‰...")
                    
                    # LLMì—ê²Œ ì§ì ‘ ìµœê³  ì¶”ì²œ ì½”ë“œë¥¼ ìš”ì²­
                    prompt = f"""ë‹¤ìŒ ìƒí’ˆì— ëŒ€í•œ ê°€ì¥ ì í•©í•œ HS ì½”ë“œ 3ê°œë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”:

ìƒí’ˆ ì •ë³´:
- ìƒí’ˆëª…: {query}
- ì¬ì§ˆ: {material if material else 'ëª…ì‹œë˜ì§€ ì•ŠìŒ'}
- ìš©ë„: {usage if usage else 'ëª…ì‹œë˜ì§€ ì•ŠìŒ'}

ê° ì½”ë“œì— ëŒ€í•´ 1-10ì ìœ¼ë¡œ í™•ì‹ ë„ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”.

ì‘ë‹µ í˜•ì‹ (JSON):
{{
  "recommendations": [
    {{
      "hs_code": "3924100000",
      "confidence": 9.5,
      "reason": "ì¶”ì²œ ê·¼ê±°"
    }}
  ]
}}"""
                    
                    response = self.openai_client.chat.completions.create(
                        model="gpt-4.1-mini",
                        messages=[
                            {"role": "system", "content": "ë‹¹ì‹ ì€ HS ì½”ë“œ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                            {"role": "user", "content": prompt}
                        ],
                        max_tokens=800,
                        temperature=0.2
                    )
                    
                    import json
                    direct_response = json.loads(response.choices[0].message.content)
                    recommendations = direct_response.get('recommendations', [])
                    
                    for rec in recommendations:
                        hs_code = rec.get('hs_code', '')
                        confidence = rec.get('confidence', 0)
                        reason = rec.get('reason', '')
                        
                        if confidence >= 9.0:  # 9ì  ì´ìƒ ê³ í™•ì‹ ë„ë§Œ
                            # ê¸°ì¡´ í›„ë³´ì— ì—†ëŠ”ì§€ í™•ì¸
                            existing = all_candidates[
                                (all_candidates['HS_KEY'] == hs_code) |
                                (all_candidates.get('HSë¶€í˜¸', '') == hs_code)
                            ]
                            
                            if existing.empty:
                                # HS ì½”ë“œë¥¼ ì‹¤ì œ ë°ì´í„°ì—ì„œ ê²€ìƒ‰í•˜ì—¬ row_data ìƒì„±
                                hs_data = self._search_hs_code_in_data(hs_code)
                                if hs_data is not None:
                                    new_row = hs_data.copy()
                                    new_row['ultimate_score'] = min(0.9, confidence / 10.0)
                                    new_row['llm_confidence'] = confidence
                                    new_row['llm_reason'] = reason
                                    new_row['match_type'] = 'llm_rerank_missing'
                                    new_row['llm_rerank_score'] = confidence
                                    new_row['llm_rank'] = 1
                                    new_row['llm_rerank_reason'] = f"LLM ì¬ìˆœìœ„ ëˆ„ë½ ê³ ë“ì  (í™•ì‹ ë„: {confidence}/10)"
                                    new_candidates.append(new_row)
                                    print(f"    ğŸ¯ ì¬ìˆœìœ„ ëˆ„ë½ ê³ ë“ì  ì¶”ê°€: {hs_code} (í™•ì‹ ë„: {confidence}, ì ìˆ˜: {min(0.9, confidence / 10.0):.3f})")
                                else:
                                    print(f"    âŒ HSì½”ë“œ ë°ì´í„° ì—†ìŒ: {hs_code}")
                    
                except Exception as e:
                    print(f"    âš ï¸ ì¬ìˆœìœ„ ëˆ„ë½ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ìƒˆë¡œìš´ í›„ë³´ë“¤ í†µí•©
            if new_candidates:
                new_df = pd.DataFrame(new_candidates)
                all_candidates = pd.concat([all_candidates, new_df], ignore_index=True)
            
            # 3. ê· í˜• ì¡íŒ ì ìˆ˜ ê¸°ë°˜ ë¶€ìŠ¤íŒ… ì ìš©
            boosted_count = 0
            search_max_score = all_candidates[all_candidates.get('match_type', '') != 'llm_high_score_new']['ultimate_score'].max() if not all_candidates.empty else 0.8
            print(f"    ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìµœê³  ì ìˆ˜: {search_max_score:.3f}")
            
            for idx, row in all_candidates.iterrows():
                hs_code = row.get('HS_KEY') or row.get('HSë¶€í˜¸', '')
                current_score = row.get('ultimate_score', 0)
                llm_rerank_score = row.get('llm_rerank_score', 0)
                llm_confidence = row.get('llm_confidence', 0)
                match_type = row.get('match_type', '')
                
                boost_multiplier = 1.0  # ê¸°ë³¸ ë°°ìˆ˜
                boost_reason = ""
                
                # ğŸ¯ LLM ì‹ ê·œ ê³ í™•ì‹  í›„ë³´: í™•ì‹ ë„ì— ë”°ë¥¸ ì ê·¹ì  ë¶€ìŠ¤íŒ…
                if match_type in ['llm_high_score_new', 'llm_rerank_missing']:
                    confidence = row.get('llm_confidence', 0)
                    if confidence >= 9.5:
                        # 9.5ì  ì´ìƒ ìµœê³  í™•ì‹ ë„: ê²€ìƒ‰ ìµœê³ ì ì˜ 140%ë¡œ ì„¤ì • (í™•ì‹¤í•œ 1ìœ„)
                        adjusted_score = search_max_score * 1.4
                        boost_reason = f"ìµœê³ í™•ì‹ ë„ ì‹ ê·œí›„ë³´ ({current_score:.3f} â†’ {adjusted_score:.3f})"
                    elif confidence >= 9.0:
                        # 9ì  ì´ìƒ ìµœê³  í™•ì‹ ë„: ê²€ìƒ‰ ìµœê³ ì ì˜ 125%ë¡œ ì„¤ì •
                        adjusted_score = search_max_score * 1.2
                        boost_reason = f"ìµœê³ í™•ì‹ ë„ ì‹ ê·œí›„ë³´ ({current_score:.3f} â†’ {adjusted_score:.3f})"
                    elif confidence >= 8.5:
                        # 8.5ì  ì´ìƒ ê³ í™•ì‹ ë„: ê²€ìƒ‰ ìµœê³ ì ì˜ 110%ë¡œ ì„¤ì •
                        adjusted_score = search_max_score * 1.1
                        boost_reason = f"ê³ í™•ì‹ ë„ ì‹ ê·œí›„ë³´ ({current_score:.3f} â†’ {adjusted_score:.3f})"
                    else:
                        # 8.0ì  ì´ìƒ: ê²€ìƒ‰ ìµœê³ ì  ìˆ˜ì¤€ìœ¼ë¡œ ì„¤ì •
                        adjusted_score = search_max_score
                        boost_reason = f"ì‹ ê·œ LLM í›„ë³´ ê· í˜• ì¡°ì • ({current_score:.3f} â†’ {adjusted_score:.3f})"
                    
                    all_candidates.at[idx, 'ultimate_score'] = adjusted_score
                    boosted_count += 1
                    print(f"    âš–ï¸  ì ê·¹ ë¶€ìŠ¤íŒ…: {hs_code} {boost_reason}")
                
                # ğŸš€ ê¸°ì¡´ í›„ë³´ ë¶€ìŠ¤íŒ… (ì ë‹¹í•œ ê°•ë„)
                elif pd.notna(llm_rerank_score) and llm_rerank_score >= 9.0:
                    # LLM ì¬ìˆœìœ„ ìµœê³ ì  (8.5ì  ì´ìƒ)
                    boost_multiplier = 1.3  # 20% ì¦í­ìœ¼ë¡œ ê°•í™”
                    boost_reason = f"ì¬ìˆœìœ„ ìµœê³ ì ({llm_rerank_score})"
               
                elif pd.notna(llm_rerank_score) and llm_rerank_score >= 8.0:
                    # LLM ì¬ìˆœìœ„ ê³ ì  (8.0ì  ì´ìƒ)
                    boost_multiplier = 1.15  # 15% ì¦í­
                    boost_reason = f"ì¬ìˆœìœ„ ê³ ì ({llm_rerank_score})"
                    
                elif pd.notna(llm_confidence) and llm_confidence >= 8.5:
                    # LLM ì§ì ‘ ì œì•ˆ ìµœê³  í™•ì‹ ë„
                    boost_multiplier = 1.18  # 18% ì¦í­ìœ¼ë¡œ ê°•í™”
                    boost_reason = f"ì§ì ‘ ì œì•ˆ ìµœê³ í™•ì‹ ë„({llm_confidence})"
                elif pd.notna(llm_confidence) and llm_confidence >= 8.0:
                    # LLM ì§ì ‘ ì œì•ˆ ê³ í™•ì‹ ë„
                    boost_multiplier = 1.12  # 12% ì¦í­
                    boost_reason = f"ì§ì ‘ ì œì•ˆ ê³ í™•ì‹ ë„({llm_confidence})"
                
                # ë¶€ìŠ¤íŒ… ì ìš©
                if boost_multiplier > 1.0:
                    boosted_score = current_score * boost_multiplier
                    all_candidates.at[idx, 'ultimate_score'] = boosted_score
                    boosted_count += 1
                    print(f"    ğŸš€ ì ìˆ˜ ë¶€ìŠ¤íŒ…: {hs_code} ({current_score:.3f} â†’ {boosted_score:.3f}) [{boost_reason}]")
            
            # 4. ìµœì¢… ì ìˆ˜ë¡œ ì •ë ¬
            final_results = all_candidates.sort_values('ultimate_score', ascending=False).reset_index(drop=True)
            
            print(f"    âœ… ì ìˆ˜ ë¶€ìŠ¤íŒ… ì™„ë£Œ: {boosted_count}ê°œ í›„ë³´ ë¶€ìŠ¤íŒ…ë¨")
            
            return final_results
                
        except Exception as e:
            print(f"    âŒ ì ìˆ˜ ë¶€ìŠ¤íŒ… ì‹¤íŒ¨: {e}")
            return reranked_results

    
    def _format_ultimate_recommendations(self, results: pd.DataFrame, final_count: int) -> List[Dict]:
        """ ì¶”ì²œ ê²°ê³¼ í¬ë§·íŒ… (nan ë¬¸ì œ í•´ê²°)"""
        recommendations = []
        
        for idx, row in results.head(final_count * 2).iterrows():
            # ğŸ”§ nan ë¬¸ì œ í•´ê²°: ì•ˆì „í•œ HS ì½”ë“œ ì¶”ì¶œ
            hs_key = row.get('HS_KEY', '')
            hs_code = row.get('HSë¶€í˜¸', '')
            
            # nan ê°’ ì²˜ë¦¬
            if pd.isna(hs_key) or hs_key == '' or str(hs_key) == 'nan':
                hs_key = hs_code
            
            if pd.isna(hs_code) or hs_code == '' or str(hs_code) == 'nan':
                hs_code = hs_key
                
            # ë‘˜ ë‹¤ ë¹„ì–´ìˆìœ¼ë©´ LLM ì •ë³´ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            if not hs_code or str(hs_code) == 'nan':
                # LLM í›„ë³´ì—ì„œ ì›ë˜ ì½”ë“œ ì°¾ê¸°
                if hasattr(row, 'name') and 'llm_confidence' in row:
                    # ì´ê±´ LLM ìƒì„± ë°ì´í„°ì¼ ê°€ëŠ¥ì„±
                    for col in row.index:
                        if 'hs' in col.lower() and pd.notna(row[col]) and str(row[col]) != 'nan':
                            hs_code = str(row[col])
                            hs_key = hs_code
                            break
            
            # ìµœì¢… ì•ˆì „ì¥ì¹˜
            if not hs_code or str(hs_code) == 'nan':
                hs_code = f"ì•Œ ìˆ˜ ì—†ìŒ_{idx}"
                hs_key = hs_code
            
            # ì´ë¦„ ì •ë³´
            name_kr = self._extract_best_name(row, ['í•œê¸€í’ˆëª©ëª…', 'ì„¸ë²ˆ10ë‹¨ìœ„í’ˆëª…', 'í‘œì¤€í’ˆëª…'])
            name_en = self._extract_best_name(row, ['ì˜ë¬¸í’ˆëª©ëª…', 'í‘œì¤€í’ˆëª…ì˜ë¬¸'])
            
            # ì„¤ëª… ì •ë³´
            description = ''
            if 'final_combined_text' in row and pd.notna(row['final_combined_text']):
                description = str(row['final_combined_text'])
            
            # ì ìˆ˜ ì •ë³´ (nan ì²˜ë¦¬)
            ultimate_score = row.get('ultimate_score', 0)
            hybrid_score = row.get('hybrid_score', 0)
            
            # nan ê°’ë“¤ì„ 0ìœ¼ë¡œ ëŒ€ì²´
            if pd.isna(ultimate_score):
                ultimate_score = 0
            if pd.isna(hybrid_score):
                hybrid_score = 0
                
            confidence = min(max(ultimate_score, 0), 1.0)  # 0-1 ë²”ìœ„ë¡œ ì œí•œ
            
            # ì¥/í˜¸ ì •ë³´ (nan ì²˜ë¦¬)
            chapter = str(row.get('chapter', ''))
            if chapter == 'nan' or pd.isna(row.get('chapter')):
                chapter = hs_key[:2] if len(str(hs_key)) >= 2 else ''
                
            heading = str(row.get('heading', ''))
            if heading == 'nan' or pd.isna(row.get('heading')):
                heading = hs_key[:4] if len(str(hs_key)) >= 4 else ''
            
            recommendation = {
                'hs_code': str(hs_code),
                'hs_key': str(hs_key),
                'name_kr': name_kr,
                'name_en': name_en,
                'description': description[:500] if description else '',
                'chapter': chapter,
                'heading': heading,
                'confidence': round(confidence, 4),
                'scores': {
                    'ultimate': round(ultimate_score, 4),
                    'hybrid': round(hybrid_score, 4),
                    'keyword': round(row.get('keyword_score', 0) if pd.notna(row.get('keyword_score', 0)) else 0, 4),
                    'semantic': round(row.get('semantic_score', 0) if pd.notna(row.get('semantic_score', 0)) else 0, 4)
                },
                'data_source': str(row.get('data_source', '')),
                'match_type': str(row.get('match_type', '')),
                'is_standard_match': bool(row.get('is_standard_match', False))
            }
            
            # LLM ì •ë³´ ì¶”ê°€ (nan ì²˜ë¦¬)
            llm_info = {}
            
            # 1. LLM ì§ì ‘ ì œì•ˆ ì •ë³´ (í•­ìƒ í¬í•¨ ê°€ëŠ¥)
            llm_confidence = row.get('llm_confidence', 0)
            if pd.notna(llm_confidence) and llm_confidence > 0:
                llm_info['llm_direct'] = {
                    'confidence': int(llm_confidence),
                    'reason': str(row.get('llm_reason', ''))
                }
                print(f"    ğŸ“ {hs_code} LLM ì§ì ‘ ì œì•ˆ ì •ë³´ ì¶”ê°€ (í™•ì‹ ë„: {llm_confidence})")
            
            # 2. LLM ì¬ìˆœìœ„ ì •ë³´ (ë§¤ì¹­ ì„±ê³µì‹œë§Œ)
            llm_rerank_score = row.get('llm_rerank_score', 0)
            print(f"    ğŸ” {hs_code} llm_rerank_score: {llm_rerank_score} (type: {type(llm_rerank_score)})")
            
            if pd.notna(llm_rerank_score) and llm_rerank_score > 0:
                llm_info['llm_rerank'] = {
                    'score': float(llm_rerank_score),
                    'rank': int(row.get('llm_rank', 999)) if pd.notna(row.get('llm_rank')) else 999,
                    'reason': str(row.get('llm_rerank_reason', ''))
                }
                print(f"    âœ… {hs_code} LLM ì¬ìˆœìœ„ ì •ë³´ ì¶”ê°€ë¨!")
            else:
                print(f"    âš ï¸ {hs_code} LLM ì¬ìˆœìœ„ ì •ë³´ ì—†ìŒ (score={llm_rerank_score})")
            
            # 3. ë§¤ì¹­ ì‹¤íŒ¨í•œ ê²½ìš°ë¥¼ ìœ„í•œ ê°œì„ ëœ í´ë°± ì²˜ë¦¬
            if not llm_info:
                # LLM ì •ë³´ê°€ ì „í˜€ ì—†ëŠ” ê²½ìš°, êµ¬ì²´ì ì¸ ë¶„ì„ ì •ë³´ ì œê³µ
                match_type = row.get('match_type', '')
                data_source = row.get('data_source', '')
                
                # ë§¤ì¹­ ìœ í˜•ë³„ êµ¬ì²´ì ì¸ ì„¤ëª… ìƒì„±
                analysis_reason = self._generate_detailed_analysis_reason(
                    hs_code, match_type, data_source, confidence, row
                )
                
                llm_info['enhanced_search'] = {
                    'confidence': min(max(confidence * 10, 1), 10),  # 0-1 -> 1-10 ë³€í™˜
                    'reason': analysis_reason,
                    'analysis_type': self._get_analysis_type_label(match_type),
                    'data_quality': self._assess_data_quality(row)
                }
                print(f"    ğŸ”„ {hs_code} ê°œì„ ëœ í´ë°± ì •ë³´ ì¶”ê°€ ({self._get_analysis_type_label(match_type)})")
            
            if llm_info:
                recommendation['llm_analysis'] = llm_info
                print(f"    âœ… {hs_code} llm_analysis ìµœì¢… í¬í•¨!")
            else:
                print(f"    âŒ {hs_code} llm_analysis ìµœì¢… ì œì™¸")
            
            recommendations.append(recommendation)
            
            if len(recommendations) >= final_count:
                break
        
        return recommendations
    
    def print_results(self, results: Dict, query: str):
            """ì¶”ì²œ ê²°ê³¼ ì¶œë ¥ (LLM í†µí•© ì •ë³´ í¬í•¨)"""
            print(f"\n{'='*80}")
            print(f"'{query}' ê²€ìƒ‰ ê²°ê³¼")
            print(f"{'='*80}")
            
            recommendations = results.get('recommendations', [])
            
            if not recommendations:
                print("ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            for i, rec in enumerate(recommendations, 1):
                print(f"\n{i}. HS ì½”ë“œ: {rec['hs_code']}")
                print(f"   í•œê¸€ëª…: {rec['name_kr']}")
                if rec['name_en']:
                    print(f"   ì˜ë¬¸ëª…: {rec['name_en']}")
                print(f"   ì‹ ë¢°ë„: {rec['confidence']:.3f}")
                print(f"   ì¥: {rec['chapter']}, í˜¸: {rec['heading']}")
                
                if rec.get('description'):
                    desc = rec['description']
                    if len(desc) > 150:
                        desc = desc[:150] + "..."
                    print(f"   ì„¤ëª…: {desc}")
                
                # LLM ë¶„ì„ ê²°ê³¼ 
                if rec.get('llm_analysis'):
                    llm = rec['llm_analysis']
                    
                    # LLM ì§ì ‘ ì œì•ˆ ì •ë³´
                    if 'llm_direct' in llm:
                        direct = llm['llm_direct']
                        print(f"   ğŸ§  LLM ë¶„ì„:")
                        print(f"     âœ¨ LLM ì§ì ‘ ì œì•ˆ (í™•ì‹ ë„: {direct['confidence']}/10)")
                        print(f"     ğŸ“ ì œì•ˆ ì´ìœ : {direct['reason']}")
                    
                    # LLM ì¬ìˆœìœ„ ì •ë³´
                    if 'llm_rerank' in llm:
                        rerank = llm['llm_rerank']
                        print(f"     ğŸ”„ì¬ìˆœìœ„ ì ìˆ˜: {rerank['score']}/10")
                        print(f"     ğŸ“Š ì¬ìˆœìœ„ ê·¼ê±°: {rerank['reason']}")
                        print(f"     ğŸ“ LLM ìˆœìœ„: {rerank['rank']}ìœ„")
                
                # ê¸°ì¡´ LLM ë¶„ì„ (í˜¸í™˜ì„±)
                elif rec.get('llm_analysis'):
                    llm = rec['llm_analysis']
                    if llm.get('reason'):
                        print(f"   AI ë¶„ì„: {llm['reason']}")
                    if llm.get('caution'):
                        print(f"   ì£¼ì˜ì‚¬í•­: {llm['caution']}")
                
                # ë§¤ì¹­ íƒ€ì… í‘œì‹œ
                match_type = rec.get('match_type', '')
                if match_type == 'llm_search_match':
                    print(f"   ğŸ¯ ë§¤ì¹­: LLM + ê²€ìƒ‰ì—”ì§„ ì¼ì¹˜")
                elif match_type == 'llm_only_with_data':
                    print(f"   ğŸ” ë§¤ì¹­: LLM ì „ìš© (ë°ì´í„° ìˆìŒ)")
                elif match_type == 'llm_only_no_data':
                    print(f"   ğŸ†• ë§¤ì¹­: LLM ì „ìš© (ì‹ ê·œ ì œì•ˆ)")
                elif match_type == 'search_only':
                    print(f"   ğŸ” ë§¤ì¹­: ê²€ìƒ‰ì—”ì§„ ì „ìš©")
                
                # ì ìˆ˜ ì •ë³´ (ultimate ì ìˆ˜ í¬í•¨)
                scores = rec['scores']
                if 'ultimate' in scores:
                    print(f"   ì ìˆ˜: U={scores['ultimate']:.3f}, H={scores['hybrid']:.3f}, "
                        f"K={scores['keyword']:.3f}, S={scores['semantic']:.3f}")
                else:
                    print(f"   ì ìˆ˜: H={scores['hybrid']:.3f}, K={scores['keyword']:.3f}, S={scores['semantic']:.3f}")
                
                print(f"   ë°ì´í„° ì†ŒìŠ¤: {rec.get('data_source', '')}")
            
            # ê²€ìƒ‰ ì •ë³´
            search_info = results.get('search_info', {})
            print(f"\nê²€ìƒ‰ ì •ë³´:")
            print(f"  ì´ í›„ë³´: {search_info.get('total_candidates', 0)}ê°œ")
            
            method = search_info.get('method', '')
            if method == 'ultimate_llm_hybrid':
                print(f"  ğŸ§  ë°©ë²•: LLM í†µí•© ì¶”ì²œ")
                print(f"  LLM ëª¨ë¸: {search_info.get('llm_model', '')}")
            else:
                print(f"  ì˜ë¯¸ ëª¨ë¸: {search_info.get('semantic_model', '')}")
            
            if search_info.get('llm_analysis') and search_info['llm_analysis'].get('recommendation'):
                print(f"\nì „ì²´ AI ì¶”ì²œ ì˜ê²¬:")
                print(f"  {search_info['llm_analysis']['recommendation']}")
    
    def _generate_detailed_analysis_reason(self, hs_code: str, match_type: str, data_source: str, 
                                         confidence: float, row: pd.Series) -> str:
        """ë§¤ì¹­ ìœ í˜•ë³„ êµ¬ì²´ì ì¸ ë¶„ì„ ì„¤ëª… ìƒì„±"""
        try:
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            name_kr = self._extract_best_name(row, ['í•œê¸€í’ˆëª©ëª…', 'ì„¸ë²ˆ10ë‹¨ìœ„í’ˆëª…', 'í‘œì¤€í’ˆëª…'])
            chapter = hs_code[:2] if len(hs_code) >= 2 else ''
            heading = hs_code[:4] if len(hs_code) >= 4 else ''
            
            # ë§¤ì¹­ ìœ í˜•ë³„ êµ¬ì²´ì ì¸ ì„¤ëª…
            if 'hybrid' in match_type:
                return f"í‚¤ì›Œë“œ ë§¤ì¹­ê³¼ ì˜ë¯¸ ë¶„ì„ì„ ê²°í•©í•˜ì—¬ ì°¾ì€ ê²°ê³¼ì…ë‹ˆë‹¤. " \
                       f"'{name_kr}' (ì œ{chapter}ë¥˜, í˜¸ {heading})ëŠ” ê²€ìƒ‰ì–´ì™€ ë†’ì€ ê´€ë ¨ì„±ì„ ë³´ì…ë‹ˆë‹¤. " \
                       f"ì‹ ë¢°ë„: {confidence:.1%}"
            
            elif 'semantic' in match_type:
                return f"ì˜ë¯¸ ë¶„ì„(AI ì„ë² ë”©)ì„ í†µí•´ ì°¾ì€ ìœ ì‚¬ í•­ëª©ì…ë‹ˆë‹¤. " \
                       f"ê²€ìƒ‰ì–´ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ì—°ê´€ëœ '{name_kr}' í•­ëª©ìœ¼ë¡œ, " \
                       f"ì œ{chapter}ë¥˜ì— ë¶„ë¥˜ë©ë‹ˆë‹¤. ì˜ë¯¸ ìœ ì‚¬ë„: {confidence:.1%}"
            
            elif 'keyword' in match_type:
                return f"í‚¤ì›Œë“œ ë§¤ì¹­ì„ í†µí•´ ì°¾ì€ ì§ì ‘ ì—°ê´€ í•­ëª©ì…ë‹ˆë‹¤. " \
                       f"'{name_kr}'ëŠ” ê²€ìƒ‰ì–´ì™€ ì§ì ‘ì ì¸ í‚¤ì›Œë“œ ì¼ì¹˜ë¥¼ ë³´ì´ë©°, " \
                       f"HSì½”ë“œ ì²´ê³„ìƒ ì œ{chapter}ë¥˜ì— í•´ë‹¹í•©ë‹ˆë‹¤. í‚¤ì›Œë“œ ì ìˆ˜: {confidence:.1%}"
            
            elif 'standard' in match_type:
                return f"í‘œì¤€ í’ˆëª… ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì€ ê³µì‹ ë¶„ë¥˜ì…ë‹ˆë‹¤. " \
                       f"'{name_kr}'ëŠ” ê´€ì„¸ì²­ í‘œì¤€ í’ˆëª…ìœ¼ë¡œ ë“±ë¡ëœ í•­ëª©ì´ë©°, " \
                       f"HSì½”ë“œ {hs_code} (ì œ{chapter}ë¥˜)ë¡œ ì •í™•íˆ ë¶„ë¥˜ë©ë‹ˆë‹¤."
            
            else:
                # ê¸°ë³¸ ì„¤ëª…
                keyword_score = row.get('keyword_score', 0)
                semantic_score = row.get('semantic_score', 0)
                
                analysis_parts = []
                if keyword_score and pd.notna(keyword_score) and keyword_score > 0:
                    analysis_parts.append(f"í‚¤ì›Œë“œ ìœ ì‚¬ë„ {keyword_score:.1%}")
                if semantic_score and pd.notna(semantic_score) and semantic_score > 0:
                    analysis_parts.append(f"ì˜ë¯¸ ìœ ì‚¬ë„ {semantic_score:.1%}")
                
                score_info = ", ".join(analysis_parts) if analysis_parts else f"ì „ì²´ ì‹ ë¢°ë„ {confidence:.1%}"
                
                return f"ê²€ìƒ‰ì—”ì§„ ë¶„ì„ ê²°ê³¼ '{name_kr}' í•­ëª©ì„ ì¶”ì²œí•©ë‹ˆë‹¤. " \
                       f"HSì½”ë“œ {hs_code} (ì œ{chapter}ë¥˜, í˜¸ {heading})ë¡œ ë¶„ë¥˜ë˜ë©°, " \
                       f"{score_info}ë¡œ ê²€ìƒ‰ì–´ì™€ ê´€ë ¨ì„±ì´ ìˆìŠµë‹ˆë‹¤."
                       
        except Exception as e:
            return f"ê²€ìƒ‰ì—”ì§„ ë¶„ì„ì„ í†µí•´ ì¶”ì²œëœ í•­ëª©ì…ë‹ˆë‹¤ (HSì½”ë“œ: {hs_code})"
    
    def _get_analysis_type_label(self, match_type: str) -> str:
        """ë§¤ì¹­ ìœ í˜•ë³„ ë¼ë²¨ ë°˜í™˜"""
        type_labels = {
            'llm_search_match': 'AI+ê²€ìƒ‰ í†µí•©',
            'llm_only_with_data': 'AI ì§ì ‘ ì œì•ˆ',
            'llm_only': 'AI ì „ìš©',
            'llm_high_score_boost': 'AI ê³ í™•ì‹ ',
            'llm_high_score_only': 'AI ê³ í™•ì‹  ì „ìš©',
            'llm_high_score_existing': 'AI ê³ í™•ì‹  ê¸°ì¡´',
            'search_only': 'ê²€ìƒ‰ì—”ì§„ ê¸°ë°˜',
            'hybrid_search': 'í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰',
            'semantic_search': 'ì˜ë¯¸ ë¶„ì„',
            'keyword_search': 'í‚¤ì›Œë“œ ë§¤ì¹­',
            'standard_match': 'í‘œì¤€ í’ˆëª…'
        }
        return type_labels.get(match_type, 'í†µí•© ë¶„ì„')
    
    def _assess_data_quality(self, row: pd.Series) -> str:
        """ë°ì´í„° í’ˆì§ˆ í‰ê°€"""
        try:
            # ë°ì´í„° ì™„ì„±ë„ í™•ì¸
            name_kr = row.get('í•œê¸€í’ˆëª©ëª…', '')
            name_en = row.get('ì˜ë¬¸í’ˆëª©ëª…', '')
            description = row.get('final_combined_text', '')
            data_source = row.get('data_source', '')
            
            quality_score = 0
            if name_kr and pd.notna(name_kr) and len(str(name_kr)) > 1:
                quality_score += 25
            if name_en and pd.notna(name_en) and len(str(name_en)) > 1:
                quality_score += 25  
            if description and pd.notna(description) and len(str(description)) > 10:
                quality_score += 25
            if data_source and 'standard' in data_source:
                quality_score += 25
            
            if quality_score >= 75:
                return 'ë†’ìŒ'
            elif quality_score >= 50:
                return 'ë³´í†µ'
            else:
                return 'ê¸°ë³¸'
                
        except Exception:
            return 'ê¸°ë³¸'
