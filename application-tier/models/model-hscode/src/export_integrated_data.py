import pandas as pd
import os
from datetime import datetime


class CorrectedDataProcessor:
    def __init__(self):
        self.hs_file = "C:/Users/User/í†µê´€/ê´€ì„¸ì²­_HSë¶€í˜¸_2025.csv"
        self.std_file = "C:/Users/User/í†µê´€/ê´€ì„¸ì²­_í‘œì¤€í’ˆëª…_20250101.xlsx"
        self.hsk_file = "C:/Users/User/í†µê´€/ê´€ì„¸ì²­_HSKë³„ ì‹ ì„±ì§ˆë³„_ì„±ì§ˆë³„ ë¶„ë¥˜_20250101.xlsx"
        
        # í•µì‹¬: HSK ë°ì´í„°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ì •
        self.hsk_data = None  # ì¤‘ì‹¬ ë°ì´í„°
        self.hs_data = None   # ë³´ì¡° ë°ì´í„°
        self.standard_data = None  # ë³´ì¡° ë°ì´í„°
        self.integrated_df = None
        
    def load_hsk_data_as_main(self):
        """ğŸ¯ ì¤‘ì‹¬ ë°ì´í„°: ê´€ì„¸ì²­_HSKë³„ ë¡œë”© (15ê°œ í•„ë“œë§Œ)"""
        print("1. ì¤‘ì‹¬ ë°ì´í„° ë¡œë”©: ê´€ì„¸ì²­_HSKë³„ ì‹ ì„±ì§ˆë³„...")
        
        try:
            self.hsk_data = pd.read_excel(self.hsk_file, sheet_name=0)
            print(f"   ì›ë³¸: {len(self.hsk_data):,}ê°œ")
            print(f"   ì»¬ëŸ¼ ìˆ˜: {len(self.hsk_data.columns)}ê°œ")
            
            # ğŸ” ë§¤í•‘ í‚¤ ìƒì„± (HS10ë‹¨ìœ„ë¶€í˜¸ â†’ HS_KEY)
            hs_col = None
            for col in self.hsk_data.columns:
                if 'HS10ë‹¨ìœ„ë¶€í˜¸' in col or 'HS10ìë¦¬' in col:
                    hs_col = col
                    break
            
            if not hs_col:
                print("   âŒ HS10ë‹¨ìœ„ë¶€í˜¸ ì»¬ëŸ¼ ì—†ìŒ")
                return False
            
            self.hsk_data['HS_KEY'] = self.hsk_data[hs_col].astype(str).str.zfill(10)
            print(f"   âœ… HS_KEY ìƒì„±: {hs_col} â†’ HS_KEY")
            print(f"      ìƒ˜í”Œ: {self.hsk_data[hs_col].iloc[0]} â†’ {self.hsk_data['HS_KEY'].iloc[0]}")
            
            # ğŸ“„ ì •ì˜ëœ 15ê°œ ê²€ìƒ‰ ë²¡í„° í•„ë“œë§Œ ì¶”ì¶œ
            defined_fields = [
                # ì„¸ë²ˆ ë¶„ë¥˜ (4ê°œ)
                'ì„¸ë²ˆ2ë‹¨ìœ„í’ˆëª…', 'ì„¸ë²ˆ4ë‹¨ìœ„í’ˆëª…', 'ì„¸ë²ˆ6ë‹¨ìœ„í’ˆëª…', 'ì„¸ë²ˆ10ë‹¨ìœ„í’ˆëª…',
                # ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ (5ê°œ)
                'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ëŒ€ë¶„ë¥˜ëª…', 'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì¤‘ë¶„ë¥˜ëª…', 
                'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì†Œë¶„ë¥˜ëª…', 'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì„¸ë¶„ë¥˜ëª…', 
                'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì„¸ì„¸ë¶„ë¥˜ëª…',
                # í˜„í–‰ ìˆ˜ì… ì„±ì§ˆë³„ ë¶„ë¥˜ (4ê°œ)
                'ê´€ì„¸ì²­ í˜„í–‰ ìˆ˜ì… ì„±ì§ˆë³„ ë¶„ë¥˜í˜„í–‰ìˆ˜ì…1ë‹¨ìœ„ë¶„ë¥˜',
                'ê´€ì„¸ì²­ í˜„í–‰ ìˆ˜ì… ì„±ì§ˆë³„ ë¶„ë¥˜í˜„í–‰ìˆ˜ì…3ë‹¨ìœ„ë¶„ë¥˜',
                'ê´€ì„¸ì²­ í˜„í–‰ ìˆ˜ì… ì„±ì§ˆë³„ ë¶„ë¥˜í˜„í–‰ìˆ˜ì…ì†Œë¶„ë¥˜',
                'ê´€ì„¸ì²­ í˜„í–‰ ìˆ˜ì… ì„±ì§ˆë³„ ë¶„ë¥˜í˜„í–‰ìˆ˜ì…ì„¸ë¶„ë¥˜',
                # í˜„í–‰ ìˆ˜ì¶œ ì„±ì§ˆë³„ ë¶„ë¥˜ (2ê°œ)
                'ê´€ì„¸ì²­ í˜„í–‰ ìˆ˜ì¶œ ì„±ì§ˆë³„ ë¶„ë¥˜í˜„í–‰ìˆ˜ì¶œì†Œë¶„ë¥˜',
                'ê´€ì„¸ì²­ í˜„í–‰ ìˆ˜ì¶œ ì„±ì§ˆë³„ ë¶„ë¥˜í˜„í–‰ìˆ˜ì¶œì„¸ë¶„ë¥˜'
            ]
            
            print(f"\n   ğŸ“‹ ì •ì˜ëœ 15ê°œ í•„ë“œ ë§¤ì¹­ ì¤‘...")
            
            # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í•„ë“œ ì°¾ê¸° (ìœ ì—°í•œ ë§¤ì¹­)
            extracted_fields = []
            field_mapping = {}
            
            for target_field in defined_fields:
                found_col = None
                # ì •í™•í•œ ë§¤ì¹­ ë¨¼ì €
                if target_field in self.hsk_data.columns:
                    found_col = target_field
                else:
                    # í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­
                    for col in self.hsk_data.columns:
                        if self._match_hsk_field(target_field, col):
                            found_col = col
                            break
                
                if found_col:
                    extracted_fields.append(found_col)
                    field_mapping[target_field] = found_col
                    print(f"   âœ… {target_field}")
                    print(f"      â†’ {found_col}")
                else:
                    print(f"   âŒ {target_field}: ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            print(f"\n   ğŸ“Š ì¶”ì¶œ ê²°ê³¼: {len(extracted_fields)}/15ê°œ í•„ë“œ")
            
            # ğŸ¯ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (HS_KEY + ì¶”ì¶œëœ í•„ë“œë§Œ)
            keep_columns = ['HS_KEY'] + extracted_fields
            print(f"   ğŸ¯ ìµœì¢… ì„ íƒ ì»¬ëŸ¼: {len(keep_columns)}ê°œ")
            
            # ì›ë³¸ ë°ì´í„°ë¥¼ í•„ìš”í•œ ì»¬ëŸ¼ë§Œìœ¼ë¡œ ì œí•œ
            self.hsk_data = self.hsk_data[keep_columns].copy()
            
            print(f"   ğŸ“ ìµœì¢… ë°ì´í„° í¬ê¸°: {self.hsk_data.shape}")
            print(f"   ğŸ—‚ï¸ ìµœì¢… ì»¬ëŸ¼: {list(self.hsk_data.columns)}")
            
            # combined_text ìƒì„± (ë‚˜ì¤‘ì— ì œê±°ë  ì˜ˆì •)
            self._create_hsk_combined_text(extracted_fields, field_mapping)
            
            self.hsk_data['data_source'] = 'hsk_main'
            print(f"   âœ… ì¤‘ì‹¬ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(self.hsk_data):,}ê°œ")
            return True
            
        except Exception as e:
            print(f"   âŒ HSK ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def _match_hsk_field(self, target_field, actual_col):
        """HSK í•„ë“œëª… ìœ ì—°í•œ ë§¤ì¹­"""
        # ì„¸ë²ˆ ë¶„ë¥˜
        if 'ì„¸ë²ˆ' in target_field and 'í’ˆëª…' in target_field:
            if 'ì„¸ë²ˆ' in actual_col and 'í’ˆëª…' in actual_col:
                # ë‹¨ìœ„ ë§¤ì¹­ í™•ì¸
                if '2ë‹¨ìœ„' in target_field:
                    return '2ë‹¨ìœ„' in actual_col
                elif '4ë‹¨ìœ„' in target_field:
                    return '4ë‹¨ìœ„' in actual_col
                elif '6ë‹¨ìœ„' in target_field:
                    return '6ë‹¨ìœ„' in actual_col
                elif '10ë‹¨ìœ„' in target_field:
                    return '10ë‹¨ìœ„' in actual_col
            return False
        
        # ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜
        elif 'ì‹ ì„±ì§ˆë³„' in target_field:
            if 'ì‹ ì„±ì§ˆë³„' in actual_col:
                if 'ëŒ€ë¶„ë¥˜ëª…' in target_field:
                    return 'ëŒ€ë¶„ë¥˜ëª…' in actual_col
                elif 'ì¤‘ë¶„ë¥˜ëª…' in target_field:
                    return 'ì¤‘ë¶„ë¥˜ëª…' in actual_col
                elif 'ì†Œë¶„ë¥˜ëª…' in target_field:
                    return 'ì†Œë¶„ë¥˜ëª…' in actual_col
                elif 'ì„¸ë¶„ë¥˜ëª…' in target_field:
                    return 'ì„¸ë¶„ë¥˜ëª…' in actual_col and 'ì„¸ì„¸ë¶„ë¥˜ëª…' not in actual_col
                elif 'ì„¸ì„¸ë¶„ë¥˜ëª…' in target_field:
                    return 'ì„¸ì„¸ë¶„ë¥˜ëª…' in actual_col
            return False
        
        # í˜„í–‰ ì„±ì§ˆë³„ ë¶„ë¥˜
        elif 'í˜„í–‰' in target_field:
            if 'í˜„í–‰' in actual_col:
                if 'ìˆ˜ì…' in target_field:
                    return 'ìˆ˜ì…' in actual_col
                elif 'ìˆ˜ì¶œ' in target_field:
                    return 'ìˆ˜ì¶œ' in actual_col
            return False
        
        return False
    
    def _create_hsk_combined_text(self, extracted_fields, field_mapping):
        """HSK combined_text ìƒì„± (ì„ì‹œ, ë‚˜ì¤‘ì— ì œê±°ë¨)"""
        print("   ğŸ”¤ HSK ì„ì‹œ combined_text ìƒì„±...")
        
        # ê°€ì¤‘ì¹˜ ì„¤ì • (ì¤‘ìš”ë„ì— ë”°ë¼)
        field_weights = {
            'ì„¸ë²ˆ10ë‹¨ìœ„í’ˆëª…': 4,
            'ì„¸ë²ˆ6ë‹¨ìœ„í’ˆëª…': 3,
            'ì„¸ë²ˆ4ë‹¨ìœ„í’ˆëª…': 2,
            'ì„¸ë²ˆ2ë‹¨ìœ„í’ˆëª…': 2,
            'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì„¸ì„¸ë¶„ë¥˜ëª…': 3,
            'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì„¸ë¶„ë¥˜ëª…': 2,
            'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì†Œë¶„ë¥˜ëª…': 2,
            'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì¤‘ë¶„ë¥˜ëª…': 1,
            'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ëŒ€ë¶„ë¥˜ëª…': 1,
        }
        
        combined_texts = []
        
        for _, row in self.hsk_data.iterrows():
            text_parts = []
            
            for field in extracted_fields:
                if pd.notna(row[field]):
                    field_value = str(row[field]).strip()
                    if field_value:
                        # ì›ë˜ ì •ì˜ í•„ë“œ ì°¾ê¸°
                        original_field = None
                        for orig, mapped in field_mapping.items():
                            if mapped == field:
                                original_field = orig
                                break
                        
                        weight = field_weights.get(original_field, 1)
                        for _ in range(weight):
                            text_parts.append(field_value)
            
            combined_text = ' '.join(text_parts) if text_parts else ''
            combined_texts.append(combined_text)
        
        self.hsk_data['combined_text'] = combined_texts
        self.hsk_data['combined_text'] = (
            self.hsk_data['combined_text']
            .str.replace(r'\s+', ' ', regex=True)
            .str.strip()
        )
        
        # ë¹ˆ í…ìŠ¤íŠ¸ í™•ì¸
        empty_count = (self.hsk_data['combined_text'] == '').sum()
        print(f"      í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ, ë¹ˆ í…ìŠ¤íŠ¸: {empty_count}ê°œ")
    
    def load_hs_data_as_supplement(self):
        """ğŸ”— ë³´ì¡° ë°ì´í„°: ê´€ì„¸ì²­_HSë¶€í˜¸ ë¡œë”© (5ê°œ í•„ë“œë§Œ)"""
        print("\n2. ë³´ì¡° ë°ì´í„° ë¡œë”©: ê´€ì„¸ì²­_HSë¶€í˜¸...")
        
        try:
            self.hs_data = pd.read_csv(self.hs_file, encoding='utf-8')
            print(f"   ì›ë³¸: {len(self.hs_data):,}ê°œ")
            
            # HS_KEY ìƒì„± (HSë¶€í˜¸ â†’ HS_KEY)
            if 'HSë¶€í˜¸' not in self.hs_data.columns:
                print("   âŒ HSë¶€í˜¸ ì»¬ëŸ¼ ì—†ìŒ")
                return False
            
            self.hs_data['HS_KEY'] = self.hs_data['HSë¶€í˜¸'].astype(str).str.zfill(10)
            print(f"   âœ… HS_KEY ìƒì„±: HSë¶€í˜¸ â†’ HS_KEY")
            
            # ğŸ“„ ì •ì˜ëœ 5ê°œ ê²€ìƒ‰ ë²¡í„° í•„ë“œë§Œ ì¶”ì¶œ
            defined_fields = [
                'í•œê¸€í’ˆëª©ëª…', 'ì˜ë¬¸í’ˆëª©ëª…', 'HSë¶€í˜¸ë‚´ìš©', 
                'í•œêµ­í‘œì¤€ë¬´ì—­ë¶„ë¥˜ëª…', 'ì„±ì§ˆí†µí•©ë¶„ë¥˜ì½”ë“œëª…'
            ]
            
            print(f"   ğŸ“‹ ì •ì˜ëœ 5ê°œ í•„ë“œ í™•ì¸ ì¤‘...")
            
            extracted_fields = []
            for field in defined_fields:
                if field in self.hs_data.columns:
                    extracted_fields.append(field)
                    print(f"   âœ… {field}")
                else:
                    print(f"   âŒ {field}: ì—†ìŒ")
            
            # ğŸ¯ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            keep_columns = ['HS_KEY'] + extracted_fields
            self.hs_data = self.hs_data[keep_columns].copy()
            
            print(f"   ğŸ¯ ìµœì¢… ì»¬ëŸ¼: {list(self.hs_data.columns)}")
            print(f"   ğŸ“Š ì¶”ì¶œëœ í•„ë“œ: {len(extracted_fields)}/5ê°œ")
            print(f"   ğŸ“ ë°ì´í„° í¬ê¸°: {self.hs_data.shape}")
            
            print(f"   âœ… ë³´ì¡° ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(self.hs_data):,}ê°œ")
            return True
            
        except Exception as e:
            print(f"   âŒ HS ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def load_standard_data_as_supplement(self):
        """ğŸ”— ë³´ì¡° ë°ì´í„°: ê´€ì„¸ì²­_í‘œì¤€í’ˆëª… ë¡œë”© (3ê°œ í•„ë“œë§Œ)"""
        print("\n3. ë³´ì¡° ë°ì´í„° ë¡œë”©: ê´€ì„¸ì²­_í‘œì¤€í’ˆëª…...")
        
        try:
            self.standard_data = pd.read_excel(self.std_file)
            print(f"   ì›ë³¸: {len(self.standard_data):,}ê°œ")
            print(f"   ì»¬ëŸ¼ ìƒ˜í”Œ: {list(self.standard_data.columns)[:5]}...")
            
            # HS_KEY ìƒì„± (HSì½”ë“œ â†’ HS_KEY)
            hs_col = None
            for col in self.standard_data.columns:
                if 'HS' in col and ('ì½”ë“œ' in col or 'ë¶€í˜¸' in col):
                    hs_col = col
                    break
            
            if not hs_col:
                print("   âŒ HSì½”ë“œ ì»¬ëŸ¼ ì—†ìŒ")
                return False
            
            self.standard_data['HS_KEY'] = self.standard_data[hs_col].astype(str).str.zfill(10)
            print(f"   âœ… HS_KEY ìƒì„±: {hs_col} â†’ HS_KEY")
            
            # ğŸ“„ ì •ì˜ëœ 3ê°œ ê²€ìƒ‰ ë²¡í„° í•„ë“œë§Œ ì¶”ì¶œ
            defined_fields = ['í‘œì¤€í’ˆëª…', 'í‘œì¤€í’ˆëª…ì˜ë¬¸', 'ì„¸ë¶€ë¶„ë¥˜']
            
            print(f"   ğŸ“‹ ì •ì˜ëœ 3ê°œ í•„ë“œ í™•ì¸ ì¤‘...")
            
            field_mapping = {}
            extracted_fields = []
            
            for target_field in defined_fields:
                found_col = None
                for col in self.standard_data.columns:
                    if target_field in col or (target_field == 'í‘œì¤€í’ˆëª…' and 'í’ˆëª…' in col and 'HS' not in col and 'ì˜ë¬¸' not in col):
                        found_col = col
                        break
                
                if found_col:
                    extracted_fields.append(found_col)
                    field_mapping[target_field] = found_col
                    print(f"   âœ… {target_field}")
                    print(f"      â†’ {found_col}")
                else:
                    print(f"   âŒ {target_field}: ì—†ìŒ")
            
            if not field_mapping.get('í‘œì¤€í’ˆëª…'):
                print("   âŒ í•µì‹¬ ì»¬ëŸ¼ 'í‘œì¤€í’ˆëª…'ì´ ì—†ì–´ ê±´ë„ˆëœ€")
                return False
            
            # ğŸ¯ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            keep_columns = ['HS_KEY'] + extracted_fields
            self.standard_data = self.standard_data[keep_columns].copy()
            
            print(f"   ğŸ¯ ìµœì¢… ì»¬ëŸ¼: {list(self.standard_data.columns)}")
            print(f"   ğŸ“Š ì¶”ì¶œëœ í•„ë“œ: {len(extracted_fields)}/3ê°œ")
            
            # ë¹ˆ í‘œì¤€í’ˆëª… ì œê±°
            if field_mapping.get('í‘œì¤€í’ˆëª…'):
                std_col = field_mapping['í‘œì¤€í’ˆëª…']
                before_clean = len(self.standard_data)
                self.standard_data = self.standard_data[
                    self.standard_data[std_col].notna() & 
                    (self.standard_data[std_col].str.strip() != '')
                ]
                print(f"   ğŸ§¹ ë¹ˆ í‘œì¤€í’ˆëª… ì œê±°: {before_clean:,} â†’ {len(self.standard_data):,}ê°œ")
            
            print(f"   ğŸ“ ìµœì¢… ë°ì´í„° í¬ê¸°: {self.standard_data.shape}")
            print(f"   âœ… ë³´ì¡° ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(self.standard_data):,}ê°œ")
            return True
            
        except Exception as e:
            print(f"   âŒ í‘œì¤€í’ˆëª… ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def integrate_all_data(self):
        """ğŸ¯ HSKë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ë¥¸ ë°ì´í„° LEFT JOIN (single combined_text)"""
        print("\n4. ë°ì´í„° í†µí•©: HSK ì¤‘ì‹¬ LEFT JOIN...")
        
        if self.hsk_data is None:
            print("   âŒ ì¤‘ì‹¬ ë°ì´í„°(HSK)ê°€ ì—†ìŒ")
            return False
        
        # HSK ë°ì´í„°ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‹œì‘
        print("   ğŸ¯ HSK ë°ì´í„°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ì •")
        self.integrated_df = self.hsk_data.copy()
        
        # HSKì˜ combined_textë¥¼ final_combined_textë¡œ ì‹œì‘
        self.integrated_df['final_combined_text'] = self.integrated_df['combined_text']
        print(f"      ê¸°ë³¸: {len(self.integrated_df):,}ê°œ")
        
        # HS ë°ì´í„° LEFT JOIN
        if self.hs_data is not None:
            print("   ğŸ”— HS ë°ì´í„° LEFT JOIN...")
            
            # HS ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ í•„ë“œë§Œ ê°€ì ¸ì˜¤ê¸°
            hs_text_fields = [col for col in self.hs_data.columns 
                             if col != 'HS_KEY']
            
            hs_to_merge = self.hs_data[['HS_KEY'] + hs_text_fields]
            
            before_merge = len(self.integrated_df)
            self.integrated_df = pd.merge(
                self.integrated_df,
                hs_to_merge,
                on='HS_KEY',
                how='left'
            )
            
            print(f"      ë³‘í•© í›„: {before_merge:,} â†’ {len(self.integrated_df):,}ê°œ")
            
            # HS í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì§ì ‘ final_combined_textì— ì¶”ê°€
            hs_text_addition = self._create_hs_text_for_integration(hs_text_fields)
            
            has_hs_text = hs_text_addition != ''
            if has_hs_text.any():
                self.integrated_df.loc[has_hs_text, 'final_combined_text'] = (
                    self.integrated_df.loc[has_hs_text, 'final_combined_text'] + ' ' + 
                    hs_text_addition[has_hs_text]
                ).str.strip()
                
                self.integrated_df.loc[has_hs_text, 'data_source'] = 'hsk_with_hs'
                print(f"      âœ… HS ì •ë³´ ì¶”ê°€: {has_hs_text.sum():,}ê°œ")
        else:
            print("   âš ï¸ HS ë°ì´í„° ì—†ìŒ - ê±´ë„ˆëœ€")
        
        # í‘œì¤€í’ˆëª… ë°ì´í„° LEFT JOIN
        if self.standard_data is not None:
            print("   ğŸ”— í‘œì¤€í’ˆëª… ë°ì´í„° LEFT JOIN...")
            
            # í‘œì¤€í’ˆëª… ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ í•„ë“œë§Œ ê°€ì ¸ì˜¤ê¸°
            std_text_fields = [col for col in self.standard_data.columns 
                              if col != 'HS_KEY']
            
            std_to_merge = self.standard_data[['HS_KEY'] + std_text_fields]
            
            before_merge = len(self.integrated_df)
            self.integrated_df = pd.merge(
                self.integrated_df,
                std_to_merge,
                on='HS_KEY',
                how='left'
            )
            
            print(f"      ë³‘í•© í›„: {before_merge:,} â†’ {len(self.integrated_df):,}ê°œ")
            
            # í‘œì¤€í’ˆëª… í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì§ì ‘ final_combined_textì— ì¶”ê°€
            std_text_addition = self._create_std_text_for_integration(std_text_fields)
            
            has_std_text = std_text_addition != ''
            if has_std_text.any():
                self.integrated_df.loc[has_std_text, 'final_combined_text'] = (
                    self.integrated_df.loc[has_std_text, 'final_combined_text'] + ' ' + 
                    std_text_addition[has_std_text]
                ).str.strip()
                
                # ë°ì´í„° ì†ŒìŠ¤ ì—…ë°ì´íŠ¸
                current_source = self.integrated_df.loc[has_std_text, 'data_source']
                self.integrated_df.loc[has_std_text, 'data_source'] = current_source + '_with_std'
                
                print(f"      âœ… í‘œì¤€í’ˆëª… ì •ë³´ ì¶”ê°€: {has_std_text.sum():,}ê°œ")
        else:
            print("   âš ï¸ í‘œì¤€í’ˆëª… ë°ì´í„° ì—†ìŒ - ê±´ë„ˆëœ€")
        
        # ğŸ—‘ï¸ ì¤‘ê°„ combined_text ì œê±° (final_combined_textë§Œ ë‚¨ê¹€)
        if 'combined_text' in self.integrated_df.columns:
            self.integrated_df = self.integrated_df.drop(columns=['combined_text'])
            print("   ğŸ—‘ï¸ ì¤‘ê°„ combined_text ì œê±°ë¨")
        
        # ìµœì¢… í…ìŠ¤íŠ¸ ì •ë¦¬
        self.integrated_df['final_combined_text'] = (
            self.integrated_df['final_combined_text']
            .str.replace(r'\s+', ' ', regex=True)
            .str.strip()
        )
        
        # ë¹ˆ í…ìŠ¤íŠ¸ í™•ì¸
        empty_count = (self.integrated_df['final_combined_text'].str.len() == 0).sum()
        avg_length = self.integrated_df['final_combined_text'].str.len().mean()
        
        print(f"   âœ… í†µí•© ì™„ë£Œ: {len(self.integrated_df):,}ê°œ")
        print(f"   ğŸ¯ ìµœì¢… í…ìŠ¤íŠ¸ ì»¬ëŸ¼: final_combined_textë§Œ ìœ ì§€")
        print(f"   ğŸ“ í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´: {avg_length:.1f}ì")
        print(f"   ğŸ” ë¹ˆ í…ìŠ¤íŠ¸: {empty_count}ê°œ")
        
        return True
    
    def _create_hs_text_for_integration(self, hs_fields):
        """HS í•„ë“œë“¤ë¡œ í…ìŠ¤íŠ¸ ìƒì„± (í†µí•©ìš©)"""
        field_weights = {
            'í•œê¸€í’ˆëª©ëª…': 3,
            'ì˜ë¬¸í’ˆëª©ëª…': 2, 
            'HSë¶€í˜¸ë‚´ìš©': 2,
            'í•œêµ­í‘œì¤€ë¬´ì—­ë¶„ë¥˜ëª…': 1,
            'ì„±ì§ˆí†µí•©ë¶„ë¥˜ì½”ë“œëª…': 1
        }
        
        hs_texts = []
        for _, row in self.integrated_df.iterrows():
            text_parts = []
            
            for field in hs_fields:
                if field in row and pd.notna(row[field]):
                    field_value = str(row[field]).strip()
                    if field_value:
                        weight = field_weights.get(field, 1)
                        for _ in range(weight):
                            text_parts.append(field_value)
            
            hs_text = ' '.join(text_parts) if text_parts else ''
            hs_texts.append(hs_text)
        
        return pd.Series(hs_texts)
    
    def _create_std_text_for_integration(self, std_fields):
        """í‘œì¤€í’ˆëª… í•„ë“œë“¤ë¡œ í…ìŠ¤íŠ¸ ìƒì„± (í†µí•©ìš©)"""
        # í•„ë“œëª…ì—ì„œ ì‹¤ì œ íƒ€ì… ì¶”ì¶œí•˜ì—¬ ê°€ì¤‘ì¹˜ ì„¤ì •
        field_weights = {}
        for field in std_fields:
            if 'í‘œì¤€í’ˆëª…' in field and 'ì˜ë¬¸' not in field:
                field_weights[field] = 3
            elif 'ì˜ë¬¸' in field:
                field_weights[field] = 2
            else:
                field_weights[field] = 1
        
        std_texts = []
        for _, row in self.integrated_df.iterrows():
            text_parts = []
            
            for field in std_fields:
                if field in row and pd.notna(row[field]):
                    field_value = str(row[field]).strip()
                    if field_value:
                        weight = field_weights.get(field, 1)
                        for _ in range(weight):
                            text_parts.append(field_value)
            
            std_text = ' '.join(text_parts) if text_parts else ''
            std_texts.append(std_text)
        
        return pd.Series(std_texts)
    
    def run_corrected_integration(self):
        """ğŸ”§ ìˆ˜ì •ëœ í†µí•© í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸ”§ ìˆ˜ì •ëœ ë°ì´í„° í†µí•© í”„ë¡œì„¸ìŠ¤")
        print("="*70)
        print("ğŸ¯ ì¤‘ì‹¬ ë°ì´í„°: ê´€ì„¸ì²­_HSKë³„ (15ê°œ í•„ë“œ)")
        print("ğŸ”— ë³´ì¡° ë°ì´í„°: ê´€ì„¸ì²­_HSë¶€í˜¸ (5ê°œ í•„ë“œ) + ê´€ì„¸ì²­_í‘œì¤€í’ˆëª… (3ê°œ í•„ë“œ)")
        print("ğŸ” ë§¤í•‘ í‚¤: HS_KEY (10ìë¦¬)")
        print("ğŸ“„ ê²°ê³¼: final_combined_text ë‹¨ì¼ í…ìŠ¤íŠ¸ ì»¬ëŸ¼")
        print("="*70)
        
        # 1. ì¤‘ì‹¬ ë°ì´í„° ë¡œë“œ (í•„ìˆ˜)
        if not self.load_hsk_data_as_main():
            print("âŒ ì¤‘ì‹¬ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            return None
        
        # 2. ë³´ì¡° ë°ì´í„° ë¡œë“œ (ì„ íƒì )
        hs_success = self.load_hs_data_as_supplement()
        std_success = self.load_standard_data_as_supplement()
        
        # 3. í†µí•©
        if not self.integrate_all_data():
            print("âŒ í†µí•© ì‹¤íŒ¨")
            return None
        
        # 4. ìµœì¢… ê²°ê³¼ ì •ë¦¬
        print("\n" + "="*70)
        print("ğŸ‰ ìˆ˜ì •ëœ í†µí•© ì™„ë£Œ!")
        
        # ë°ì´í„° ì†ŒìŠ¤ë³„ ë¶„í¬
        source_dist = self.integrated_df['data_source'].value_counts()
        print("\nğŸ“Š ë°ì´í„° ì†ŒìŠ¤ë³„ ë¶„í¬:")
        for source, count in source_dist.items():
            pct = count / len(self.integrated_df) * 100
            print(f"   {source}: {count:,}ê°œ ({pct:.1f}%)")
        
        print(f"\nğŸ“Š ìµœì¢… í†µê³„:")
        print(f"   ì´ ë ˆì½”ë“œ: {len(self.integrated_df):,}ê°œ")
        print(f"   ì´ ì»¬ëŸ¼: {len(self.integrated_df.columns)}ê°œ")
        print(f"   ê³ ìœ  HS_KEY: {self.integrated_df['HS_KEY'].nunique():,}ê°œ")
        print("="*70)
        
        return self.integrated_df
    
    def show_final_structure(self):
        """ìµœì¢… ë°ì´í„° êµ¬ì¡° í‘œì‹œ"""
        if self.integrated_df is None:
            print("í†µí•© ë°ì´í„° ì—†ìŒ")
            return
        
        print("\nğŸ“‹ ìµœì¢… ë°ì´í„° êµ¬ì¡°:")
        print("="*50)
        
        # í•µì‹¬ ì»¬ëŸ¼
        core_cols = ['HS_KEY', 'final_combined_text', 'data_source']
        print("ğŸ¯ í•µì‹¬ ì»¬ëŸ¼:")
        for col in core_cols:
            if col in self.integrated_df.columns:
                print(f"   âœ… {col}")
        
        # HSK ê´€ë ¨ ì»¬ëŸ¼
        hsk_cols = [col for col in self.integrated_df.columns 
                   if col not in core_cols and not col.startswith(('hs_', 'std_'))]
        
        if hsk_cols:
            print(f"\nğŸ¯ HSK í•„ë“œ ({len(hsk_cols)}ê°œ):")
            for col in hsk_cols:
                print(f"   - {col}")
        
        # HS ê´€ë ¨ ì»¬ëŸ¼
        hs_cols = [col for col in self.integrated_df.columns if 'í•œê¸€í’ˆëª©ëª…' in col or 'ì˜ë¬¸í’ˆëª©ëª…' in col or 'HSë¶€í˜¸ë‚´ìš©' in col or 'í•œêµ­í‘œì¤€ë¬´ì—­ë¶„ë¥˜ëª…' in col or 'ì„±ì§ˆí†µí•©ë¶„ë¥˜ì½”ë“œëª…' in col]
        if hs_cols:
            print(f"\nğŸ”— HS í•„ë“œ ({len(hs_cols)}ê°œ):")
            for col in hs_cols:
                print(f"   - {col}")
        
        # í‘œì¤€í’ˆëª… ê´€ë ¨ ì»¬ëŸ¼
        std_cols = [col for col in self.integrated_df.columns if 'í‘œì¤€í’ˆëª…' in col or 'ì„¸ë¶€ë¶„ë¥˜' in col]
        if std_cols:
            print(f"\nğŸ”— í‘œì¤€í’ˆëª… í•„ë“œ ({len(std_cols)}ê°œ):")
            for col in std_cols:
                print(f"   - {col}")
        
        print(f"\nğŸ“Š ì „ì²´ ì»¬ëŸ¼ ìˆ˜: {len(self.integrated_df.columns)}ê°œ")
        print(f"ğŸ“Š ì „ì²´ ë ˆì½”ë“œ ìˆ˜: {len(self.integrated_df):,}ê°œ")
        
    def get_sample_data(self, n=5):
        """ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ"""
        if self.integrated_df is None:
            return None
        
        sample_cols = ['HS_KEY', 'final_combined_text', 'data_source']
        return self.integrated_df[sample_cols].head(n)


class DataExporter:
    """ë°ì´í„° ë‚´ë³´ë‚´ê¸° í´ë˜ìŠ¤"""
    
    def __init__(self, output_dir="./output"):
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)
    
    def export_integrated_data(self, integrated_df, processor):
        """í†µí•©ëœ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
        if integrated_df is None:
            print("âŒ ë‚´ë³´ë‚¼ ë°ì´í„° ì—†ìŒ")
            return False
        
        print(f"\nğŸ“¤ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ({self.output_dir})")
        print("="*50)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ë©”ì¸ Excel íŒŒì¼ (ëª¨ë“  ì‹œíŠ¸ í¬í•¨)
        excel_path = os.path.join(self.output_dir, f"integrated_hs_data_{timestamp}.xlsx")
        
        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            # ì „ì²´ ë°ì´í„° ì‹œíŠ¸
            integrated_df.to_excel(writer, sheet_name='í†µí•©ë°ì´í„°_ì „ì²´', index=False)
            
            # ë°ì´í„° ì†ŒìŠ¤ë³„ ì‹œíŠ¸
            for source in integrated_df['data_source'].unique():
                source_data = integrated_df[integrated_df['data_source'] == source]
                sheet_name = f"{source}"[:31]  # Excel ì‹œíŠ¸ëª… ê¸¸ì´ ì œí•œ
                source_data.to_excel(writer, sheet_name=sheet_name, index=False)
            
            # ìƒ˜í”Œ ì‹œíŠ¸ (ê° ì†ŒìŠ¤ë³„ ìƒìœ„ 50ê°œ)
            for source in integrated_df['data_source'].unique():
                source_sample = integrated_df[integrated_df['data_source'] == source].head(50)
                sheet_name = f"ìƒ˜í”Œ_{source}"[:31]
                source_sample.to_excel(writer, sheet_name=sheet_name, index=False)
            
            # í†µê³„ ì‹œíŠ¸
            stats_rows = [
                ['í•­ëª©', 'ê°’'],
                ['ì „ì²´ ë ˆì½”ë“œ ìˆ˜', f"{len(integrated_df):,}"],
                ['ê³ ìœ  HS_KEY ìˆ˜', f"{integrated_df['HS_KEY'].nunique():,}"],
                ['ì „ì²´ ì»¬ëŸ¼ ìˆ˜', len(integrated_df.columns)],
                ['í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´', f"{integrated_df['final_combined_text'].str.len().mean():.1f}ì"],
                ['ë¹ˆ í…ìŠ¤íŠ¸ ìˆ˜', (integrated_df['final_combined_text'].str.len() == 0).sum()],
                [''],
                ['ë°ì´í„° ì†ŒìŠ¤ë³„ ë¶„í¬', ''],
            ]
            
            for source, count in integrated_df['data_source'].value_counts().items():
                pct = count / len(integrated_df) * 100
                stats_rows.append([f"  {source}", f"{count:,} ({pct:.1f}%)"])
            
            stats_df = pd.DataFrame(stats_rows)
            stats_df.to_excel(writer, sheet_name='í†µê³„ì •ë³´', index=False, header=False)
        
        print(f"ğŸ“„ Excel íŒŒì¼: {excel_path}")
        
        # 2. ë¨¸ì‹ ëŸ¬ë‹ìš© CSV íŒŒì¼ (í•µì‹¬ ì»¬ëŸ¼ë§Œ)
        csv_path = os.path.join(self.output_dir, f"ml_ready_data_{timestamp}.csv")
        ml_columns = ['HS_KEY', 'final_combined_text', 'data_source']
        
        integrated_df[ml_columns].to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ¤– MLìš© CSV: {csv_path}")
        
        # 3. êµ¬ì¡° ì •ë³´ íŒŒì¼
        structure_path = os.path.join(self.output_dir, f"data_structure_{timestamp}.txt")
        with open(structure_path, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("HS ì½”ë“œ í†µí•© ë°ì´í„° êµ¬ì¡° ì •ë³´\n")
            f.write("="*70 + "\n\n")
            
            f.write(f"ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ì´ ë ˆì½”ë“œ: {len(integrated_df):,}ê°œ\n")
            f.write(f"ì´ ì»¬ëŸ¼: {len(integrated_df.columns)}ê°œ\n")
            f.write(f"ê³ ìœ  HS_KEY: {integrated_df['HS_KEY'].nunique():,}ê°œ\n\n")
            
            f.write("ë°ì´í„° ì†ŒìŠ¤ë³„ ë¶„í¬:\n")
            for source, count in integrated_df['data_source'].value_counts().items():
                pct = count / len(integrated_df) * 100
                f.write(f"  {source}: {count:,}ê°œ ({pct:.1f}%)\n")
            
            f.write(f"\nì „ì²´ ì»¬ëŸ¼ ëª©ë¡:\n")
            for i, col in enumerate(integrated_df.columns, 1):
                f.write(f"  {i:2d}. {col}\n")
        
        print(f"ğŸ“‹ êµ¬ì¡° ì •ë³´: {structure_path}")
        
        print(f"\nâœ… ë‚´ë³´ë‚´ê¸° ì™„ë£Œ! ì´ {len(integrated_df):,}ê°œ ë ˆì½”ë“œ")
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.output_dir}")
        
        return True


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ­ HS ì½”ë“œ ë°ì´í„° í†µí•© ë„êµ¬ v2.0")
    print("ğŸ¯ HSKë³„ ì‹ ì„±ì§ˆë³„ ë°ì´í„° ì¤‘ì‹¬ í†µí•©")
    print("ğŸ“„ ì •ì˜ëœ 23ê°œ í•„ë“œ ì •í™• ì¶”ì¶œ")
    print("ğŸ” HS_KEY ë§¤í•‘ í‚¤ ê¸°ë°˜ í†µí•©")
    print("="*70)
    
    # ì‹¤í–‰ ì˜µì…˜
    print("\nì‹¤í–‰ ì˜µì…˜:")
    print("1. ë°ì´í„° í†µí•©ë§Œ ì‹¤í–‰ (ë¯¸ë¦¬ë³´ê¸°)")
    print("2. ë°ì´í„° í†µí•© + íŒŒì¼ ë‚´ë³´ë‚´ê¸°")
    
    choice = input("ì„ íƒ (1 ë˜ëŠ” 2, ê¸°ë³¸: 1): ").strip()
    
    # ë°ì´í„° í†µí•© ì‹¤í–‰
    processor = CorrectedDataProcessor()
    integrated_df = processor.run_corrected_integration()
    
    if integrated_df is not None:
        # êµ¬ì¡° ì •ë³´ í‘œì‹œ
        processor.show_final_structure()
        
        # ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ
        print(f"\nğŸ“ ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 3ê°œ):")
        sample_data = processor.get_sample_data(3)
        if sample_data is not None:
            print(sample_data.to_string(max_colwidth=50))
        
        # íŒŒì¼ ë‚´ë³´ë‚´ê¸° (ì˜µì…˜ 2 ì„ íƒì‹œ)
        if choice == "2":
            output_dir = input(f"\nğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ./output): ").strip()
            if not output_dir:
                output_dir = "./output"
            
            exporter = DataExporter(output_dir)
            success = exporter.export_integrated_data(integrated_df, processor)
            
            if success:
                print(f"\nğŸ‰ ì™„ë£Œ! ëª¨ë“  íŒŒì¼ì´ '{output_dir}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                print("\nâŒ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨!")
        else:
            print(f"\nâœ… í†µí•© ì™„ë£Œ! ì´ {len(integrated_df):,}ê°œ ë ˆì½”ë“œ")
            save_choice = input("íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            if save_choice == 'y':
                exporter = DataExporter()
                exporter.export_integrated_data(integrated_df, processor)
    
    else:
        print("âŒ í†µí•© ì‹¤íŒ¨!")


if __name__ == "__main__":
    main()
