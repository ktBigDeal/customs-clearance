# data_processor.py - ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ë‹´ë‹¹ (ë³‘í•© í™•ì¸ ê¸°ëŠ¥ ì¶”ê°€)

import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Optional, Tuple
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from config import (
    FILE_PATHS, HS_CODE_COLUMNS, STANDARD_NAME_COLUMNS, 
    HSK_CLASSIFICATION_COLUMNS
)


class DataProcessor:
    """ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ë‹´ë‹¹ í´ë˜ìŠ¤ (HSK ì¤‘ì‹¬, 23ê°œ í•„ë“œ ì •í™• ì¶”ì¶œ)"""
    
    def __init__(self, debug_mode=True):  # [DEBUG] ë””ë²„ê·¸ ëª¨ë“œ ì¶”ê°€
        # [TARGET] HSK ë°ì´í„°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ì •
        self.hsk_classification_data = None  # ì¤‘ì‹¬ ë°ì´í„°
        self.hs_data = None                  # ë³´ì¡° ë°ì´í„°
        self.standard_data = None            # ë³´ì¡° ë°ì´í„°
        self.integrated_df = None
        self.chapter_descriptions = {}
        self.debug_mode = debug_mode  # [DEBUG] ë””ë²„ê·¸ ëª¨ë“œ í”Œë˜ê·¸
        
    def _show_merge_debug_info(self, stage, before_df, after_df, merge_key='HS_KEY'):
        """[DEBUG] ë³‘í•© ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥"""
        if not self.debug_mode:
            return
            
        print(f"\n[DEBUG] [{stage}] ë³‘í•© ë””ë²„ê·¸ ì •ë³´:")
        print("="*50)
        
        # ê¸°ë³¸ ì •ë³´
        print(f"ë³‘í•© ì „ ë ˆì½”ë“œ: {len(before_df):,}ê°œ")
        print(f"ë³‘í•© í›„ ë ˆì½”ë“œ: {len(after_df):,}ê°œ")
        
        # ì»¬ëŸ¼ ë³€í™”
        before_cols = set(before_df.columns)
        after_cols = set(after_df.columns)
        new_cols = after_cols - before_cols
        
        if new_cols:
            print(f"ì¶”ê°€ëœ ì»¬ëŸ¼: {list(new_cols)}")
        
        # ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 3ê°œ)
        print(f"\n[INFO] ë³‘í•© í›„ ìƒ˜í”Œ ë°ì´í„°:")
        display_cols = [merge_key, 'final_combined_text', 'data_source']
        if 'final_combined_text' not in after_df.columns:
            display_cols = [c for c in display_cols if c in after_df.columns]
            display_cols.append('combined_text' if 'combined_text' in after_df.columns else after_df.columns[-1])
        
        sample_data = after_df[display_cols].head(3)
        for idx, row in sample_data.iterrows():
            print(f"\n[{idx}]")
            for col in display_cols:
                value = str(row[col])
                if len(value) > 100:
                    value = value[:100] + "..."
                print(f"  {col}: {value}")
        
        print("="*50)
    
    def _show_data_source_distribution(self, df):
        """[DEBUG] ë°ì´í„° ì†ŒìŠ¤ë³„ ë¶„í¬ ìƒì„¸ ì¶œë ¥"""
        if not self.debug_mode:
            return
            
        print(f"\n[INFO] ë°ì´í„° ì†ŒìŠ¤ë³„ ìƒì„¸ ë¶„í¬:")
        print("-"*40)
        
        if 'data_source' in df.columns:
            source_dist = df['data_source'].value_counts()
            total = len(df)
            
            for source, count in source_dist.items():
                pct = count / total * 100
                print(f"  {source}: {count:,}ê°œ ({pct:.1f}%)")
                
                # ê° ì†ŒìŠ¤ë³„ ìƒ˜í”Œ HS_KEY ë³´ê¸°
                sample_keys = df[df['data_source'] == source]['HS_KEY'].head(3).tolist()
                print(f"    ìƒ˜í”Œ HS_KEY: {sample_keys}")
        
        print("-"*40)
    
    def load_hsk_classification_data(self) -> bool:
        """[TARGET] ì¤‘ì‹¬ ë°ì´í„°: HSK ë¶„ë¥˜ ë°ì´í„° ë¡œë“œ (15ê°œ í•„ë“œë§Œ)"""
        print("ì¤‘ì‹¬ ë°ì´í„° ë¡œë”©: HSK ë¶„ë¥˜ ë°ì´í„°...")
        
        try:
            if not os.path.exists(FILE_PATHS['hsk_classification']):
                print(f"HSK ë¶„ë¥˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FILE_PATHS['hsk_classification']}")
                return False
            
            # ë°ì´í„° ë¡œë“œ
            self.hsk_classification_data = pd.read_excel(
                FILE_PATHS['hsk_classification'], 
                sheet_name=0
            )
            print(f"  ì›ë³¸ ë°ì´í„°: {len(self.hsk_classification_data)}ê°œ í•­ëª©")
            print(f"  ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(self.hsk_classification_data.columns)[:10]}...")
            
            # ğŸ” HS_KEY ë§¤í•‘ í‚¤ ìƒì„± (HS10ë‹¨ìœ„ë¶€í˜¸ â†’ HS_KEY)
            hs_col = None
            hs_candidates = HSK_CLASSIFICATION_COLUMNS['hs_code_candidates']
            
            for candidate in hs_candidates:
                for col in self.hsk_classification_data.columns:
                    if candidate in col:
                        hs_col = col
                        break
                if hs_col:
                    break
            
            if not hs_col:
                print("  HS ì½”ë“œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            # HS_KEY ìƒì„± (10ìë¦¬ í‘œì¤€í™”)
            self.hsk_classification_data['HS_KEY'] = (
                self.hsk_classification_data[hs_col].astype(str).str.zfill(10)
            )
            print(f"  [OK] HS_KEY ìƒì„±: {hs_col} â†’ HS_KEY")
            
            # [DEBUG] ë””ë²„ê·¸: HS_KEY ìƒì„± í™•ì¸
            if self.debug_mode:
                print(f"\n[DEBUG] HS_KEY ìƒì„± ìƒ˜í”Œ:")
                sample_keys = self.hsk_classification_data[['HS_KEY', hs_col]].head(3)
                for idx, row in sample_keys.iterrows():
                    print(f"  {row[hs_col]} â†’ {row['HS_KEY']}")
            
            # ğŸ“„ ì •ì˜ëœ 15ê°œ ê²€ìƒ‰ ë²¡í„° í•„ë“œë§Œ ì¶”ì¶œ
            defined_fields = [
                # ì„¸ë²ˆ ë¶„ë¥˜ (4ê°œ)
                'ì„¸ë²ˆ2ë‹¨ìœ„í’ˆëª…', 'ì„¸ë²ˆ4ë‹¨ìœ„í’ˆëª…', 'ì„¸ë²ˆ6ë‹¨ìœ„í’ˆëª…', 'ì„¸ë²ˆ10ë‹¨ìœ„í’ˆëª…',
                # ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ (5ê°œ)
                'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ëŒ€ë¶„ë¥˜ëª…', 'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì¤‘ë¶„ë¥˜ëª…', 
                'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì†Œë¶„ë¥˜ëª…', 'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì„¸ë¶„ë¥˜ëª…', 
                'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì„¸ì„¸ë¶„ë¥˜ëª…',
                # í˜„í–‰ ìˆ˜ì… ì„±ì§ˆë³„ ë¶„ë¥˜ (4ê°œ)
                'ê´€ì„¸ì²­ í˜„í–‰ ìˆ˜ì… ì„±ì§ˆë³„ ë¶„ë¥˜í˜„í–‰ìˆ˜ì…1ë‹¨ìœ„ë¶„ë¥˜',
                'ê´€ì„¸ì²­ í˜„í–‰ ìˆ˜ì… ì„±ì§ˆë³„ ë¶„ë¥˜í˜„í–‰ìˆ˜ì…3ë‹¨ìœ„ë¶„ë¥˜',
                'ê´€ì„¸ì²­ í˜„í–‰ ìˆ˜ì… ì„±ì§ˆë³„ ë¶„ë¥˜í˜„í–‰ìˆ˜ì…ì†Œë¶„ë¥˜',
                'ê´€ì„¸ì²­ í˜„í–‰ ìˆ˜ì… ì„±ì§ˆë³„ ë¶„ë¥˜í˜„í–‰ìˆ˜ì…ì„¸ë¶„ë¥˜',
                # í˜„í–‰ ìˆ˜ì¶œ ì„±ì§ˆë³„ ë¶„ë¥˜ (2ê°œ)
                'ê´€ì„¸ì²­ í˜„í–‰ ìˆ˜ì¶œ ì„±ì§ˆë³„ ë¶„ë¥˜í˜„í–‰ìˆ˜ì¶œì†Œë¶„ë¥˜',
                'ê´€ì„¸ì²­ í˜„í–‰ ìˆ˜ì¶œ ì„±ì§ˆë³„ ë¶„ë¥˜í˜„í–‰ìˆ˜ì¶œì„¸ë¶„ë¥˜'
            ]
            
            # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í•„ë“œ ì°¾ê¸°
            extracted_fields = []
            field_mapping = {}
            
            for target_field in defined_fields:
                found_col = self._find_matching_column(target_field, self.hsk_classification_data.columns)
                
                if found_col:
                    extracted_fields.append(found_col)
                    field_mapping[target_field] = found_col
                    print(f"  [OK] {target_field}: {found_col}")
                else:
                    print(f"  [ERROR] {target_field}: ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            print(f"  [INFO] ì¶”ì¶œëœ í•„ë“œ: {len(extracted_fields)}/15ê°œ")
            
            # [TARGET] í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (HS_KEY + ì¶”ì¶œëœ í•„ë“œë§Œ)
            keep_columns = ['HS_KEY'] + extracted_fields
            before_df = self.hsk_classification_data.copy()
            self.hsk_classification_data = self.hsk_classification_data[keep_columns].copy()
            
            # [DEBUG] ë””ë²„ê·¸: ì»¬ëŸ¼ ì„ íƒ ê²°ê³¼
            if self.debug_mode:
                print(f"\n[DEBUG] ì»¬ëŸ¼ ì„ íƒ ê²°ê³¼:")
                print(f"  ì„ íƒ ì „: {len(before_df.columns)}ê°œ ì»¬ëŸ¼")
                print(f"  ì„ íƒ í›„: {len(self.hsk_classification_data.columns)}ê°œ ì»¬ëŸ¼")
                print(f"  ìµœì¢… ì»¬ëŸ¼: {list(self.hsk_classification_data.columns)}")
            
            # ì±•í„° ì„¤ëª… ì¶”ì¶œ
            self._extract_chapter_descriptions(extracted_fields, field_mapping)
            
            # combined_text ìƒì„± (ì„ì‹œ)
            self._create_hsk_combined_text(extracted_fields, field_mapping)
            
            print(f"  ì „ì²˜ë¦¬ ì™„ë£Œ: {len(self.hsk_classification_data)}ê°œ í•­ëª©")
            return True
            
        except Exception as e:
            print(f"HSK ë¶„ë¥˜ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def load_hs_code_data(self) -> bool:
        """ğŸ”— ë³´ì¡° ë°ì´í„°: HS ì½”ë“œ ë°ì´í„° ë¡œë“œ (5ê°œ í•„ë“œë§Œ)"""
        print("\në³´ì¡° ë°ì´í„° ë¡œë”©: HS ì½”ë“œ ë°ì´í„°...")
        
        try:
            if not os.path.exists(FILE_PATHS['hs_codes']):
                print(f"HS ì½”ë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FILE_PATHS['hs_codes']}")
                return False
            
            # ë°ì´í„° ë¡œë“œ
            self.hs_data = pd.read_csv(FILE_PATHS['hs_codes'], encoding='utf-8')
            print(f"  ì›ë³¸ ë°ì´í„°: {len(self.hs_data)}ê°œ í•­ëª©")
            
            # HS_KEY ìƒì„± (HSë¶€í˜¸ â†’ HS_KEY)
            if 'HSë¶€í˜¸' not in self.hs_data.columns:
                print("  [ERROR] HSë¶€í˜¸ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            self.hs_data['HS_KEY'] = self.hs_data['HSë¶€í˜¸'].astype(str).str.zfill(10)
            
            # [DEBUG] ë””ë²„ê·¸: HS_KEY ìƒì„± í™•ì¸
            if self.debug_mode:
                print(f"\n[DEBUG] HS ë°ì´í„° HS_KEY ìƒì„± ìƒ˜í”Œ:")
                sample_keys = self.hs_data[['HS_KEY', 'HSë¶€í˜¸']].head(3)
                for idx, row in sample_keys.iterrows():
                    print(f"  {row['HSë¶€í˜¸']} â†’ {row['HS_KEY']}")
            
            # ğŸ“„ ì •ì˜ëœ 5ê°œ ê²€ìƒ‰ ë²¡í„° í•„ë“œë§Œ ì¶”ì¶œ
            defined_fields = [
                'í•œê¸€í’ˆëª©ëª…', 'ì˜ë¬¸í’ˆëª©ëª…', 'HSë¶€í˜¸ë‚´ìš©', 
                'í•œêµ­í‘œì¤€ë¬´ì—­ë¶„ë¥˜ëª…', 'ì„±ì§ˆí†µí•©ë¶„ë¥˜ì½”ë“œëª…'
            ]
            
            # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í•„ë“œ í™•ì¸
            extracted_fields = []
            for field in defined_fields:
                if field in self.hs_data.columns:
                    extracted_fields.append(field)
                    print(f"  [OK] {field}")
                else:
                    print(f"  [ERROR] {field}: ì—†ìŒ")
            
            # [TARGET] í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            keep_columns = ['HS_KEY'] + extracted_fields
            
            # ìœ íš¨ê¸°ê°„ í•„í„°ë§ (ì„ íƒì )
            if all(col in self.hs_data.columns for col in ['ì ìš©ì‹œì‘ì¼ì', 'ì ìš©ì¢…ë£Œì¼ì']):
                current_date = int(datetime.now().strftime('%Y%m%d'))
                initial_count = len(self.hs_data)
                
                self.hs_data = self.hs_data[
                    (self.hs_data['ì ìš©ì‹œì‘ì¼ì'] <= current_date) & 
                    (self.hs_data['ì ìš©ì¢…ë£Œì¼ì'] >= current_date)
                ]
                print(f"  ìœ íš¨ê¸°ê°„ í•„í„°ë§: {initial_count} -> {len(self.hs_data)}ê°œ")
            
            self.hs_data = self.hs_data[keep_columns].copy()
            
            # [DEBUG] ë””ë²„ê·¸: HS ë°ì´í„° ìµœì¢… ìƒíƒœ
            if self.debug_mode:
                print(f"\n[DEBUG] HS ë°ì´í„° ìµœì¢… ìƒíƒœ:")
                print(f"  ìµœì¢… ë ˆì½”ë“œ: {len(self.hs_data):,}ê°œ")
                print(f"  ìµœì¢… ì»¬ëŸ¼: {list(self.hs_data.columns)}")
                print(f"  ìƒ˜í”Œ ë°ì´í„°:")
                sample = self.hs_data.head(2)
                for idx, row in sample.iterrows():
                    print(f"    HS_KEY: {row['HS_KEY']}")
                    for col in extracted_fields:
                        if col in row:
                            value = str(row[col])[:50] + "..." if len(str(row[col])) > 50 else str(row[col])
                            print(f"    {col}: {value}")
                    print()
            
            print(f"  [INFO] ì¶”ì¶œëœ í•„ë“œ: {len(extracted_fields)}/5ê°œ")
            print(f"  ì „ì²˜ë¦¬ ì™„ë£Œ: {len(self.hs_data)}ê°œ í•­ëª©")
            return True
            
        except Exception as e:
            print(f"HS ì½”ë“œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def load_standard_name_data(self) -> bool:
        """ğŸ”— ë³´ì¡° ë°ì´í„°: í‘œì¤€í’ˆëª… ë°ì´í„° ë¡œë“œ (3ê°œ í•„ë“œë§Œ)"""
        print("\në³´ì¡° ë°ì´í„° ë¡œë”©: í‘œì¤€í’ˆëª… ë°ì´í„°...")
        
        try:
            if not os.path.exists(FILE_PATHS['standard_names']):
                print(f"í‘œì¤€í’ˆëª… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FILE_PATHS['standard_names']}")
                return False
            
            # ë°ì´í„° ë¡œë“œ
            self.standard_data = pd.read_excel(FILE_PATHS['standard_names'])
            print(f"  ì›ë³¸ ë°ì´í„°: {len(self.standard_data)}ê°œ í•­ëª©")
            
            # HS_KEY ìƒì„± (HSì½”ë“œ â†’ HS_KEY)
            hs_col = None
            for col in self.standard_data.columns:
                if 'HS' in col and ('ì½”ë“œ' in col or 'ë¶€í˜¸' in col):
                    hs_col = col
                    break
            
            if not hs_col:
                print("  [ERROR] HSì½”ë“œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            self.standard_data['HS_KEY'] = self.standard_data[hs_col].astype(str).str.zfill(10)
            
            # [DEBUG] ë””ë²„ê·¸: í‘œì¤€í’ˆëª… ë°ì´í„° HS_KEY ìƒì„± í™•ì¸
            if self.debug_mode:
                print(f"\n[DEBUG] í‘œì¤€í’ˆëª… ë°ì´í„° HS_KEY ìƒì„± ìƒ˜í”Œ:")
                sample_keys = self.standard_data[['HS_KEY', hs_col]].head(3)
                for idx, row in sample_keys.iterrows():
                    print(f"  {row[hs_col]} â†’ {row['HS_KEY']}")
            
            # ğŸ“„ ì •ì˜ëœ 3ê°œ ê²€ìƒ‰ ë²¡í„° í•„ë“œë§Œ ì¶”ì¶œ
            defined_fields = ['í‘œì¤€í’ˆëª…', 'í‘œì¤€í’ˆëª…ì˜ë¬¸', 'ì„¸ë¶€ë¶„ë¥˜']
            
            # ìœ ì—°í•œ ì»¬ëŸ¼ ë§¤í•‘
            field_mapping = {}
            extracted_fields = []
            
            for target_field in defined_fields:
                found_col = None
                for col in self.standard_data.columns:
                    if target_field in col or (target_field == 'í‘œì¤€í’ˆëª…' and 'í’ˆëª…' in col and 'HS' not in col and 'ì˜ë¬¸' not in col):
                        found_col = col
                        break
                
                if found_col:
                    extracted_fields.append(found_col)
                    field_mapping[target_field] = found_col
                    print(f"  [OK] {target_field}: {found_col}")
                else:
                    print(f"  [ERROR] {target_field}: ì—†ìŒ")
            
            if not field_mapping.get('í‘œì¤€í’ˆëª…'):
                print("  í•µì‹¬ ì»¬ëŸ¼ 'í‘œì¤€í’ˆëª…'ì´ ì—†ì–´ ê±´ë„ˆëœ€")
                return False
            
            # [TARGET] í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            keep_columns = ['HS_KEY'] + extracted_fields
            self.standard_data = self.standard_data[keep_columns].copy()
            
            # ë¹ˆ í‘œì¤€í’ˆëª… ì œê±°
            std_col = field_mapping['í‘œì¤€í’ˆëª…']
            initial_count = len(self.standard_data)
            self.standard_data = self.standard_data[
                self.standard_data[std_col].notna() & 
                (self.standard_data[std_col].str.strip() != '')
            ]
            print(f"  ë¹ˆ í‘œì¤€í’ˆëª… ì œê±°: {initial_count} -> {len(self.standard_data)}ê°œ")
            
            # [DEBUG] ë””ë²„ê·¸: í‘œì¤€í’ˆëª… ë°ì´í„° ìµœì¢… ìƒíƒœ
            if self.debug_mode:
                print(f"\n[DEBUG] í‘œì¤€í’ˆëª… ë°ì´í„° ìµœì¢… ìƒíƒœ:")
                print(f"  ìµœì¢… ë ˆì½”ë“œ: {len(self.standard_data):,}ê°œ")
                print(f"  ìµœì¢… ì»¬ëŸ¼: {list(self.standard_data.columns)}")
                print(f"  ìƒ˜í”Œ ë°ì´í„°:")
                sample = self.standard_data.head(2)
                for idx, row in sample.iterrows():
                    print(f"    HS_KEY: {row['HS_KEY']}")
                    for col in extracted_fields:
                        if col in row:
                            value = str(row[col])[:50] + "..." if len(str(row[col])) > 50 else str(row[col])
                            print(f"    {col}: {value}")
                    print()
            
            print(f"  [INFO] ì¶”ì¶œëœ í•„ë“œ: {len(extracted_fields)}/3ê°œ")
            print(f"  ì „ì²˜ë¦¬ ì™„ë£Œ: {len(self.standard_data)}ê°œ í•­ëª©")
            return True
            
        except Exception as e:
            print(f"í‘œì¤€í’ˆëª… ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def integrate_data(self) -> bool:
        """[TARGET] HSKë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ëª¨ë“  ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ final_combined_text ìƒì„±"""
        print("\n" + "="*60)
        print("ë°ì´í„° í†µí•© í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (HSK ì¤‘ì‹¬)")
        print("="*60)
        
        if self.hsk_classification_data is None:
            print("ì¤‘ì‹¬ ë°ì´í„°(HSK)ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # 1ë‹¨ê³„: HSK ë°ì´í„°ë¥¼ ê¸°ë³¸ í‹€ë¡œ ì‹œì‘
        print("1ë‹¨ê³„: HSK ë°ì´í„°ë¥¼ ê¸°ë³¸ í‹€ë¡œ ì„¤ì •")
        self.integrated_df = self.hsk_classification_data.copy()
        
        # HSKì˜ combined_textë¥¼ final_combined_textë¡œ ì‹œì‘
        self.integrated_df['final_combined_text'] = self.integrated_df['combined_text']
        self.integrated_df['data_source'] = 'hsk_main'
        print(f"  ê¸°ë³¸ ë°ì´í„°: {len(self.integrated_df)}ê°œ í•­ëª©")
        
        # [DEBUG] 1ë‹¨ê³„ ë””ë²„ê·¸
        if self.debug_mode:
            print(f"\n[DEBUG] 1ë‹¨ê³„ í›„ ë°ì´í„° ìƒíƒœ:")
            print(f"  ë ˆì½”ë“œ ìˆ˜: {len(self.integrated_df):,}ê°œ")
            print(f"  ì»¬ëŸ¼ ìˆ˜: {len(self.integrated_df.columns)}ê°œ")
            print(f"  HS_KEY ìƒ˜í”Œ: {self.integrated_df['HS_KEY'].head(3).tolist()}")
        
        # 2ë‹¨ê³„: HS ì½”ë“œ ë°ì´í„° Left Join
        if self.hs_data is not None:
            print("\n2ë‹¨ê³„: HS ì½”ë“œ ë°ì´í„° Left Join")
            
            # HS ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ í•„ë“œë§Œ ê°€ì ¸ì˜¤ê¸°
            hs_text_fields = [col for col in self.hs_data.columns if col != 'HS_KEY']
            hs_to_merge = self.hs_data[['HS_KEY'] + hs_text_fields]
            
            print(f"  ë³‘í•©í•  HS ë°ì´í„°: {len(hs_to_merge)}ê°œ")
            print(f"  HS í…ìŠ¤íŠ¸ í•„ë“œ: {hs_text_fields}")
            
            # [DEBUG] ë³‘í•© ì „ í‚¤ ë§¤ì¹­ í™•ì¸
            if self.debug_mode:
                common_keys = set(self.integrated_df['HS_KEY']) & set(hs_to_merge['HS_KEY'])
                print(f"\n[DEBUG] HS ë°ì´í„° ë³‘í•© ì „ í‚¤ ë§¤ì¹­:")
                print(f"  HSK ë°ì´í„° ê³ ìœ  HS_KEY: {self.integrated_df['HS_KEY'].nunique():,}ê°œ")
                print(f"  HS ë°ì´í„° ê³ ìœ  HS_KEY: {hs_to_merge['HS_KEY'].nunique():,}ê°œ")
                print(f"  ê³µí†µ HS_KEY: {len(common_keys):,}ê°œ")
                print(f"  ë§¤ì¹­ë¥ : {len(common_keys) / len(self.integrated_df) * 100:.1f}%")
            
            # Left Join ìˆ˜í–‰
            before_merge = self.integrated_df.copy()
            self.integrated_df = pd.merge(
                self.integrated_df,
                hs_to_merge,
                on='HS_KEY',
                how='left'
            )
            
            # [DEBUG] 2ë‹¨ê³„ ë³‘í•© ë””ë²„ê·¸
            self._show_merge_debug_info("HS ë°ì´í„° ë³‘í•©", before_merge, self.integrated_df)
            
            # HS í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ final_combined_textì— ì¶”ê°€
            hs_text_addition = self._create_hs_text_for_integration(hs_text_fields)
            
            has_hs_text = hs_text_addition != ''
            if has_hs_text.any():
                self.integrated_df.loc[has_hs_text, 'final_combined_text'] = (
                    self.integrated_df.loc[has_hs_text, 'final_combined_text'] + ' ' + 
                    hs_text_addition[has_hs_text]
                ).str.strip()
                
                self.integrated_df.loc[has_hs_text, 'data_source'] = 'hsk_with_hs'
                print(f"  - {has_hs_text.sum()}ê°œ í•­ëª©ì— HS ì •ë³´ ì¶”ê°€")
            
            # [DEBUG] 2ë‹¨ê³„ í›„ ë°ì´í„° ì†ŒìŠ¤ ë¶„í¬
            self._show_data_source_distribution(self.integrated_df)
        
        # 3ë‹¨ê³„: í‘œì¤€í’ˆëª… ë°ì´í„° Left Join
        if self.standard_data is not None:
            print("\n3ë‹¨ê³„: í‘œì¤€í’ˆëª… ë°ì´í„° Left Join")
            
            # í‘œì¤€í’ˆëª… ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ í•„ë“œë§Œ ê°€ì ¸ì˜¤ê¸°
            std_text_fields = [col for col in self.standard_data.columns if col != 'HS_KEY']
            std_to_merge = self.standard_data[['HS_KEY'] + std_text_fields]
            
            print(f"  ë³‘í•©í•  í‘œì¤€í’ˆëª… ë°ì´í„°: {len(std_to_merge)}ê°œ")
            print(f"  í‘œì¤€í’ˆëª… í…ìŠ¤íŠ¸ í•„ë“œ: {std_text_fields}")
            
            # [DEBUG] ë³‘í•© ì „ í‚¤ ë§¤ì¹­ í™•ì¸
            if self.debug_mode:
                common_keys = set(self.integrated_df['HS_KEY']) & set(std_to_merge['HS_KEY'])
                print(f"\n[DEBUG] í‘œì¤€í’ˆëª… ë°ì´í„° ë³‘í•© ì „ í‚¤ ë§¤ì¹­:")
                print(f"  í˜„ì¬ í†µí•© ë°ì´í„° ê³ ìœ  HS_KEY: {self.integrated_df['HS_KEY'].nunique():,}ê°œ")
                print(f"  í‘œì¤€í’ˆëª… ë°ì´í„° ê³ ìœ  HS_KEY: {std_to_merge['HS_KEY'].nunique():,}ê°œ")
                print(f"  ê³µí†µ HS_KEY: {len(common_keys):,}ê°œ")
                print(f"  ë§¤ì¹­ë¥ : {len(common_keys) / len(self.integrated_df) * 100:.1f}%")
            
            # Left Join ìˆ˜í–‰
            before_merge = self.integrated_df.copy()
            self.integrated_df = pd.merge(
                self.integrated_df,
                std_to_merge,
                on='HS_KEY',
                how='left'
            )
            
            # [DEBUG] 3ë‹¨ê³„ ë³‘í•© ë””ë²„ê·¸
            self._show_merge_debug_info("í‘œì¤€í’ˆëª… ë°ì´í„° ë³‘í•©", before_merge, self.integrated_df)
            
            # í‘œì¤€í’ˆëª… í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ final_combined_textì— ì¶”ê°€
            std_text_addition = self._create_std_text_for_integration(std_text_fields)
            
            has_std_text = std_text_addition != ''
            if has_std_text.any():
                self.integrated_df.loc[has_std_text, 'final_combined_text'] = (
                    self.integrated_df.loc[has_std_text, 'final_combined_text'] + ' ' + 
                    std_text_addition[has_std_text]
                ).str.strip()
                
                # ë°ì´í„° ì†ŒìŠ¤ ì—…ë°ì´íŠ¸
                current_source = self.integrated_df.loc[has_std_text, 'data_source']
                self.integrated_df.loc[has_std_text, 'data_source'] = current_source + '_with_std'
                
                print(f"  - {has_std_text.sum()}ê°œ í•­ëª©ì— í‘œì¤€í’ˆëª… ì •ë³´ ì¶”ê°€")
            
            # [DEBUG] 3ë‹¨ê³„ í›„ ë°ì´í„° ì†ŒìŠ¤ ë¶„í¬
            self._show_data_source_distribution(self.integrated_df)
        
        # 4ë‹¨ê³„: ìµœì¢… ë°ì´í„° ì •ë¦¬
        print("\n4ë‹¨ê³„: ìµœì¢… ë°ì´í„° ì •ë¦¬")
        
        # [CLEANUP] ì¤‘ê°„ combined_text ì œê±° (final_combined_textë§Œ ë‚¨ê¹€)
        if 'combined_text' in self.integrated_df.columns:
            self.integrated_df = self.integrated_df.drop(columns=['combined_text'])
            print("  - ì¤‘ê°„ combined_text ì œê±°ë¨")
        
        # final_combined_text ì •ë¦¬
        self.integrated_df['final_combined_text'] = (
            self.integrated_df['final_combined_text']
            .fillna('')
            .str.strip()
            .str.replace(r'\s+', ' ', regex=True)
        )
        
        # ë¹ˆ í…ìŠ¤íŠ¸ë¥¼ HS_KEY ë˜ëŠ” ì±•í„° ì„¤ëª…ìœ¼ë¡œ ëŒ€ì²´
        empty_mask = (
            (self.integrated_df['final_combined_text'] == '') | 
            (self.integrated_df['final_combined_text'].isna())
        )
        
        if empty_mask.any():
            print(f"  - ë¹ˆ í…ìŠ¤íŠ¸ {empty_mask.sum()}ê°œë¥¼ ë³´ì™„ ì¤‘...")
            
            for idx in self.integrated_df[empty_mask].index:
                hs_key = self.integrated_df.loc[idx, 'HS_KEY']
                chapter = hs_key[:2] if len(hs_key) >= 2 else '00'
                
                if chapter in self.chapter_descriptions:
                    desc = self.chapter_descriptions[chapter]
                    self.integrated_df.loc[idx, 'final_combined_text'] = f"{desc} {hs_key}"
                else:
                    self.integrated_df.loc[idx, 'final_combined_text'] = hs_key
        
        # ê³„ì¸µ ì •ë³´ ì¶”ê°€
        self.integrated_df['chapter'] = self.integrated_df['HS_KEY'].str[:2]
        self.integrated_df['heading'] = self.integrated_df['HS_KEY'].str[:4]
        self.integrated_df['subheading'] = self.integrated_df['HS_KEY'].str[:6]
        
        # [DEBUG] ìµœì¢… ê²°ê³¼ ë””ë²„ê·¸
        if self.debug_mode:
            print(f"\n[DEBUG] ìµœì¢… í†µí•© ê²°ê³¼:")
            print(f"  ìµœì¢… ë ˆì½”ë“œ: {len(self.integrated_df):,}ê°œ")
            print(f"  ìµœì¢… ì»¬ëŸ¼: {len(self.integrated_df.columns)}ê°œ")
            print(f"  ì»¬ëŸ¼ ëª©ë¡: {list(self.integrated_df.columns)}")
            
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„í¬
            text_lengths = self.integrated_df['final_combined_text'].str.len()
            print(f"\n  ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„í¬:")
            print(f"    í‰ê· : {text_lengths.mean():.1f}ì")
            print(f"    ìµœì†Œ: {text_lengths.min()}ì")
            print(f"    ìµœëŒ€: {text_lengths.max()}ì")
            print(f"    ë¹ˆ í…ìŠ¤íŠ¸: {(text_lengths == 0).sum()}ê°œ")
            
            # ìµœì¢… ìƒ˜í”Œ ë°ì´í„°
            print(f"\n  [INFO] ìµœì¢… í†µí•© ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 3ê°œ):")
            sample_cols = ['HS_KEY', 'final_combined_text', 'data_source', 'chapter']
            sample = self.integrated_df[sample_cols].head(3)
            
            for idx, row in sample.iterrows():
                print(f"\n  [{idx}]")
                print(f"    HS_KEY: {row['HS_KEY']}")
                print(f"    Chapter: {row['chapter']}")
                print(f"    Data Source: {row['data_source']}")
                text = str(row['final_combined_text'])
                if len(text) > 150:
                    text = text[:150] + "..."
                print(f"    Final Text: {text}")
        
        # ìµœì¢… í†µê³„
        print(f"\ní†µí•© ì™„ë£Œ: {len(self.integrated_df)}ê°œ í•­ëª©")
        
        # ë°ì´í„° ì†ŒìŠ¤ë³„ í†µê³„
        source_stats = self.integrated_df['data_source'].value_counts()
        print("\në°ì´í„° ì†ŒìŠ¤ë³„ ë¶„í¬:")
        for source, count in source_stats.items():
            print(f"  - {source}: {count:,}ê°œ")
        
        # í…ìŠ¤íŠ¸ í’ˆì§ˆ í†µê³„
        text_lengths = self.integrated_df['final_combined_text'].str.len()
        print(f"\ní…ìŠ¤íŠ¸ í’ˆì§ˆ:")
        print(f"  - í‰ê·  ê¸¸ì´: {text_lengths.mean():.1f}ì")
        print(f"  - ë¹ˆ í…ìŠ¤íŠ¸: {(text_lengths == 0).sum()}ê°œ")
        
        print("="*60)
        return True

   
    
    def _find_matching_column(self, target_field, available_columns):
        """í•„ë“œëª… ìœ ì—°í•œ ë§¤ì¹­"""
        # ì •í™•í•œ ë§¤ì¹­ ë¨¼ì €
        if target_field in available_columns:
            return target_field
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­
        for col in available_columns:
            if self._match_hsk_field(target_field, col):
                return col
        
        return None
    
    def _match_hsk_field(self, target_field, actual_col):
        """HSK í•„ë“œëª… ìœ ì—°í•œ ë§¤ì¹­"""
        # ì„¸ë²ˆ ë¶„ë¥˜
        if 'ì„¸ë²ˆ' in target_field and 'í’ˆëª…' in target_field:
            if 'ì„¸ë²ˆ' in actual_col and 'í’ˆëª…' in actual_col:
                if '2ë‹¨ìœ„' in target_field:
                    return '2ë‹¨ìœ„' in actual_col
                elif '4ë‹¨ìœ„' in target_field:
                    return '4ë‹¨ìœ„' in actual_col
                elif '6ë‹¨ìœ„' in target_field:
                    return '6ë‹¨ìœ„' in actual_col
                elif '10ë‹¨ìœ„' in target_field:
                    return '10ë‹¨ìœ„' in actual_col
            return False
        
        # ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜
        elif 'ì‹ ì„±ì§ˆë³„' in target_field:
            if 'ì‹ ì„±ì§ˆë³„' in actual_col:
                if 'ëŒ€ë¶„ë¥˜ëª…' in target_field:
                    return 'ëŒ€ë¶„ë¥˜ëª…' in actual_col
                elif 'ì¤‘ë¶„ë¥˜ëª…' in target_field:
                    return 'ì¤‘ë¶„ë¥˜ëª…' in actual_col
                elif 'ì†Œë¶„ë¥˜ëª…' in target_field:
                    return 'ì†Œë¶„ë¥˜ëª…' in actual_col
                elif 'ì„¸ë¶„ë¥˜ëª…' in target_field:
                    return 'ì„¸ë¶„ë¥˜ëª…' in actual_col and 'ì„¸ì„¸ë¶„ë¥˜ëª…' not in actual_col
                elif 'ì„¸ì„¸ë¶„ë¥˜ëª…' in target_field:
                    return 'ì„¸ì„¸ë¶„ë¥˜ëª…' in actual_col
            return False
        
        # í˜„í–‰ ì„±ì§ˆë³„ ë¶„ë¥˜
        elif 'í˜„í–‰' in target_field:
            if 'í˜„í–‰' in actual_col:
                if 'ìˆ˜ì…' in target_field:
                    return 'ìˆ˜ì…' in actual_col
                elif 'ìˆ˜ì¶œ' in target_field:
                    return 'ìˆ˜ì¶œ' in actual_col
            return False
        
        return False
    
    def _extract_chapter_descriptions(self, extracted_fields, field_mapping):
        """ì±•í„° ì„¤ëª… ì¶”ì¶œ (ì„¸ë²ˆ2ë‹¨ìœ„í’ˆëª…)"""
        chapter_field = None
        for target, actual in field_mapping.items():
            if 'ì„¸ë²ˆ2ë‹¨ìœ„í’ˆëª…' in target:
                chapter_field = actual
                break
        
        if chapter_field:
            chapter_mapping = {}
            for _, row in self.hsk_classification_data.iterrows():
                if pd.notna(row['HS_KEY']) and pd.notna(row[chapter_field]):
                    chapter = row['HS_KEY'][:2]
                    desc = row[chapter_field]
                    if chapter not in chapter_mapping:
                        chapter_mapping[chapter] = desc
            
            self.chapter_descriptions = chapter_mapping
            print(f"  ì±•í„° ì„¤ëª… ì¶”ì¶œ: {len(self.chapter_descriptions)}ê°œ")
    
    def _create_hsk_combined_text(self, extracted_fields, field_mapping):
        """HSK ë¶„ë¥˜ ë°ì´í„°ì˜ í†µí•© í…ìŠ¤íŠ¸ ìƒì„± (ì„ì‹œ)"""
        print("  HSK ë¶„ë¥˜ í†µí•© í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
        
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        field_weights = {
            'ì„¸ë²ˆ10ë‹¨ìœ„í’ˆëª…': 4,
            'ì„¸ë²ˆ6ë‹¨ìœ„í’ˆëª…': 3,
            'ì„¸ë²ˆ4ë‹¨ìœ„í’ˆëª…': 2,
            'ì„¸ë²ˆ2ë‹¨ìœ„í’ˆëª…': 2,
            'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì„¸ì„¸ë¶„ë¥˜ëª…': 3,
            'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì„¸ë¶„ë¥˜ëª…': 2,
            'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì†Œë¶„ë¥˜ëª…': 2,
            'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ì¤‘ë¶„ë¥˜ëª…': 1,
            'ê´€ì„¸ì²­ ì‹ ì„±ì§ˆë³„ ë¶„ë¥˜ëŒ€ë¶„ë¥˜ëª…': 1,
        }
        
        combined_texts = []
        
        for _, row in self.hsk_classification_data.iterrows():
            text_parts = []
            
            for field in extracted_fields:
                if pd.notna(row[field]):
                    field_value = str(row[field]).strip()
                    if field_value:
                        # ì›ë˜ ì •ì˜ í•„ë“œ ì°¾ê¸°
                        original_field = None
                        for orig, mapped in field_mapping.items():
                            if mapped == field:
                                original_field = orig
                                break
                        
                        weight = field_weights.get(original_field, 1)
                        for _ in range(weight):
                            text_parts.append(field_value)
            
            combined_text = ' '.join(text_parts) if text_parts else ''
            combined_texts.append(combined_text)
        
        self.hsk_classification_data['combined_text'] = combined_texts
        
        # ê³µë°± ì •ë¦¬
        self.hsk_classification_data['combined_text'] = (
            self.hsk_classification_data['combined_text']
            .str.replace(r'\s+', ' ', regex=True)
            .str.strip()
        )
    
    def _create_hs_text_for_integration(self, hs_fields):
        """HS í•„ë“œë“¤ë¡œ í…ìŠ¤íŠ¸ ìƒì„± (í†µí•©ìš©)"""
        field_weights = {
            'í•œê¸€í’ˆëª©ëª…': 3,
            'ì˜ë¬¸í’ˆëª©ëª…': 2, 
            'HSë¶€í˜¸ë‚´ìš©': 2,
            'í•œêµ­í‘œì¤€ë¬´ì—­ë¶„ë¥˜ëª…': 1,
            'ì„±ì§ˆí†µí•©ë¶„ë¥˜ì½”ë“œëª…': 1
        }
        
        hs_texts = []
        for _, row in self.integrated_df.iterrows():
            text_parts = []
            
            for field in hs_fields:
                if field in row and pd.notna(row[field]):
                    field_value = str(row[field]).strip()
                    if field_value:
                        weight = field_weights.get(field, 1)
                        for _ in range(weight):
                            text_parts.append(field_value)
            
            hs_text = ' '.join(text_parts) if text_parts else ''
            hs_texts.append(hs_text)
        
        return pd.Series(hs_texts)
    
    def _create_std_text_for_integration(self, std_fields):
        """í‘œì¤€í’ˆëª… í•„ë“œë“¤ë¡œ í…ìŠ¤íŠ¸ ìƒì„± (í†µí•©ìš©)"""
        field_weights = {}
        for field in std_fields:
            if 'í‘œì¤€í’ˆëª…' in field and 'ì˜ë¬¸' not in field:
                field_weights[field] = 3
            elif 'ì˜ë¬¸' in field:
                field_weights[field] = 2
            else:
                field_weights[field] = 1
        
        std_texts = []
        for _, row in self.integrated_df.iterrows():
            text_parts = []
            
            for field in std_fields:
                if field in row and pd.notna(row[field]):
                    field_value = str(row[field]).strip()
                    if field_value:
                        weight = field_weights.get(field, 1)
                        for _ in range(weight):
                            text_parts.append(field_value)
            
            std_text = ' '.join(text_parts) if text_parts else ''
            std_texts.append(std_text)
        
        return pd.Series(std_texts)
    
    def get_integrated_data(self) -> Optional[pd.DataFrame]:
        """í†µí•©ëœ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜"""
        return self.integrated_df
    
    def get_chapter_descriptions(self) -> Dict[str, str]:
        """ì±•í„° ì„¤ëª… ë”•ì…”ë„ˆë¦¬ ë°˜í™˜"""
        return self.chapter_descriptions
    
    def load_all_data(self) -> bool:
        """ëª¨ë“  ë°ì´í„° ë¡œë“œ ë° í†µí•© (HSK ì¤‘ì‹¬)"""
        print("="*80)
        print("HS ì½”ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ - ë°ì´í„° ë¡œë”© ì‹œì‘ (HSK ì¤‘ì‹¬, ë””ë²„ê·¸ ëª¨ë“œ)")
        print("="*80)
        
        # 1. HSK ë¶„ë¥˜ ë°ì´í„° ë¡œë“œ (í•„ìˆ˜, ì¤‘ì‹¬ ë°ì´í„°)
        if not self.load_hsk_classification_data():
            print("ì¤‘ì‹¬ ë°ì´í„°(HSK) ë¡œë“œ ì‹¤íŒ¨ - í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
            return False
        
        # 2. HS ì½”ë“œ ë°ì´í„° ë¡œë“œ (ì„ íƒì , ë³´ì¡° ë°ì´í„°)
        hs_success = self.load_hs_code_data()
        if hs_success:
            print("âœ“ HS ì½”ë“œ ë°ì´í„° ë¡œë“œ ì„±ê³µ")
        else:
            print("[WARNING] HS ì½”ë“œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ (ì„ íƒì  ë°ì´í„°)")
        
        # 3. í‘œì¤€í’ˆëª… ë°ì´í„° ë¡œë“œ (ì„ íƒì , ë³´ì¡° ë°ì´í„°)
        std_success = self.load_standard_name_data()
        if std_success:
            print("âœ“ í‘œì¤€í’ˆëª… ë°ì´í„° ë¡œë“œ ì„±ê³µ")
        else:
            print("[WARNING] í‘œì¤€í’ˆëª… ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ (ì„ íƒì  ë°ì´í„°)")
        
        # 4. ë°ì´í„° í†µí•©
        if not self.integrate_data():
            print("ë°ì´í„° í†µí•© ì‹¤íŒ¨")
            return False
        
        print("="*80)
        print("ë°ì´í„° ë¡œë”© ë° í†µí•© ì™„ë£Œ! (HSK ì¤‘ì‹¬, 23ê°œ í•„ë“œ)")
        print("="*80)
        
        return True
    
    def get_statistics(self) -> Dict:
        """ë°ì´í„° í†µê³„ ë°˜í™˜"""
        if self.integrated_df is None:
            return {}
        
        stats = {
            'total_items': len(self.integrated_df),
            'unique_hs_keys': self.integrated_df['HS_KEY'].nunique(),
            'chapters': len(self.integrated_df['chapter'].unique()),
            'data_sources': self.integrated_df['data_source'].value_counts().to_dict()
        }
        
        # í…ìŠ¤íŠ¸ í’ˆì§ˆ í†µê³„
        if 'final_combined_text' in self.integrated_df.columns:
            text_lengths = self.integrated_df['final_combined_text'].str.len()
            stats['text_quality'] = {
                'avg_length': text_lengths.mean(),
                'min_length': text_lengths.min(),
                'max_length': text_lengths.max(),
                'empty_texts': (text_lengths == 0).sum()
            }
        
        # ì±•í„° ì„¤ëª… í†µê³„
        stats['chapter_descriptions'] = len(self.chapter_descriptions)
        
        # ì±•í„°ë³„ ë¶„í¬
        if 'chapter' in self.integrated_df.columns:
            chapter_dist = self.integrated_df['chapter'].value_counts().head(10)
            stats['top_chapters'] = chapter_dist.to_dict()
        
        return stats

    def set_debug_mode(self, debug_mode: bool):
        """ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •"""
        self.debug_mode = debug_mode


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ­ HS ì½”ë“œ ë°ì´í„° ì²˜ë¦¬ê¸° ì‹¤í–‰")
    print("="*60)
    
    # ë””ë²„ê·¸ ëª¨ë“œë¡œ ë°ì´í„° ì²˜ë¦¬ê¸° ìƒì„±
    processor = DataProcessor(debug_mode=True)
    
    print("ğŸ“‹ ë°ì´í„° ë¡œë”© ë° í†µí•© ì‹œì‘...")
    success = processor.load_all_data()
    
    if success:
        print("[OK] ë°ì´í„° ì²˜ë¦¬ ì„±ê³µ!")
        
        # í†µê³„ ì •ë³´ ì¶œë ¥
        stats = processor.get_statistics()
        print(f"\n[INFO] ìµœì¢… í†µê³„:")
        print(f"   ì´ ë ˆì½”ë“œ: {stats.get('total_items', 0):,}ê°œ")
        print(f"   ê³ ìœ  HS_KEY: {stats.get('unique_hs_keys', 0):,}ê°œ")
        print(f"   ì±•í„° ìˆ˜: {stats.get('chapters', 0)}ê°œ")
        
        # ìƒ˜í”Œ ë°ì´í„° ë³´ê¸°
        integrated_df = processor.get_integrated_data()
        if integrated_df is not None:
            print(f"\n[INFO] ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 3ê°œ):")
            sample_cols = ['HS_KEY', 'final_combined_text', 'data_source']
            sample = integrated_df[sample_cols].head(3)
            
            for idx, row in sample.iterrows():
                print(f"\n[{idx}]")
                print(f"  HS_KEY: {row['HS_KEY']}")
                print(f"  Data Source: {row['data_source']}")
                text = str(row['final_combined_text'])
                if len(text) > 100:
                    text = text[:100] + "..."
                print(f"  Combined Text: {text}")
        
        # ì €ì¥í• ì§€ ë¬¼ì–´ë³´ê¸°
        save_choice = input("\n[SAVE] ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if save_choice == 'y':
            try:
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_path = f"integrated_hs_data_{timestamp}.xlsx"
                
                integrated_df.to_excel(output_path, index=False)
                print(f"[OK] ì €ì¥ ì™„ë£Œ: {output_path}")
            except Exception as e:
                print(f"[ERROR] ì €ì¥ ì‹¤íŒ¨: {e}")
    else:
        print("[ERROR] ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨!")


if __name__ == "__main__":
    main()